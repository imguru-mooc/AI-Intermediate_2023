{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "\n",
    "\n",
    "class DeepConvNet:\n",
    "    \"\"\"정확도 99% 이상의 고정밀 합성곱 신경망\n",
    "\n",
    "    네트워크 구성은 아래와 같음\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        affine - relu - dropout - affine - dropout - softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n",
    "                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 hidden_size=50, output_size=10):\n",
    "        # 가중치 초기화===========\n",
    "        # 각 층의 뉴런 하나당 앞 층의 몇 개 뉴런과 연결되는가（TODO: 자동 계산되게 바꿀 것）\n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "        wight_init_scales = np.sqrt(2.0 / pre_node_nums)  # ReLU를 사용할 때의 권장 초깃값\n",
    "        \n",
    "        self.params = {}\n",
    "        pre_channel_num = input_dim[0]\n",
    "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "            self.params['W' + str(idx+1)] = wight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
    "            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n",
    "            pre_channel_num = conv_param['filter_num']\n",
    "        self.params['W7'] = wight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "        self.params['b7'] = np.zeros(hidden_size)\n",
    "        self.params['W8'] = wight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b8'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성===========\n",
    "        self.layers = []\n",
    "        self.layers.append(Convolution(self.params['W1'], self.params['b1'], \n",
    "                           conv_param_1['stride'], conv_param_1['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W2'], self.params['b2'], \n",
    "                           conv_param_2['stride'], conv_param_2['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W3'], self.params['b3'], \n",
    "                           conv_param_3['stride'], conv_param_3['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W4'], self.params['b4'],\n",
    "                           conv_param_4['stride'], conv_param_4['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W5'], self.params['b5'],\n",
    "                           conv_param_5['stride'], conv_param_5['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W6'], self.params['b6'],\n",
    "                           conv_param_6['stride'], conv_param_6['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x, train_flg=False):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, train_flg)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x, train_flg=True)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx, train_flg=False)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        tmp_layers = self.layers.copy()\n",
    "        tmp_layers.reverse()\n",
    "        for layer in tmp_layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n",
    "            grads['b' + str(i+1)] = self.layers[layer_idx].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
    "            self.layers[layer_idx].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3209546073298877\n",
      "=== epoch:1, train acc:0.176, test acc:0.187 ===\n",
      "train loss:2.402639357879208\n",
      "train loss:2.2799379224797267\n",
      "train loss:2.2808486668829557\n",
      "train loss:2.2721298288621528\n",
      "train loss:2.255336987507969\n",
      "train loss:2.286202111245256\n",
      "train loss:2.2888819540224326\n",
      "train loss:2.2343980037658855\n",
      "train loss:2.2679451958072816\n",
      "train loss:2.2528494258869927\n",
      "train loss:2.245147117946139\n",
      "train loss:2.246317363310013\n",
      "train loss:2.236777098137173\n",
      "train loss:2.245997074374474\n",
      "train loss:2.156292726976549\n",
      "train loss:2.225294380063191\n",
      "train loss:2.1802798442882905\n",
      "train loss:2.169758616781231\n",
      "train loss:2.2682559876262904\n",
      "train loss:2.2382977327475975\n",
      "train loss:2.0987033563796156\n",
      "train loss:2.0696572938159012\n",
      "train loss:2.140746788857936\n",
      "train loss:2.1311160704644956\n",
      "train loss:2.1260607771736257\n",
      "train loss:2.1932786267349225\n",
      "train loss:2.096724555135687\n",
      "train loss:2.0806409763266425\n",
      "train loss:2.245197720439289\n",
      "train loss:2.1113640288788487\n",
      "train loss:1.959900419231036\n",
      "train loss:2.0253829286460086\n",
      "train loss:2.0869067548827425\n",
      "train loss:2.0670188334961224\n",
      "train loss:2.036714315426122\n",
      "train loss:2.090770852087842\n",
      "train loss:2.0208056815133073\n",
      "train loss:1.9945457535917837\n",
      "train loss:1.987704511232376\n",
      "train loss:1.9434920846129469\n",
      "train loss:1.9736704912736938\n",
      "train loss:1.8365209264760765\n",
      "train loss:1.8137670147651366\n",
      "train loss:1.8716755104345435\n",
      "train loss:1.896442061296972\n",
      "train loss:1.938181018245637\n",
      "train loss:1.793296973267156\n",
      "train loss:1.7916091083739365\n",
      "train loss:1.7877523184973108\n",
      "train loss:1.9728931123714606\n",
      "train loss:1.9688282247948425\n",
      "train loss:1.9908894057505466\n",
      "train loss:1.606037799468581\n",
      "train loss:1.8955582484427498\n",
      "train loss:2.004368541667945\n",
      "train loss:1.701199899343641\n",
      "train loss:1.767789430182488\n",
      "train loss:1.8322594244501147\n",
      "train loss:1.7547751047948086\n",
      "train loss:1.943724188250733\n",
      "train loss:1.7472979668010742\n",
      "train loss:1.799236177904764\n",
      "train loss:1.82533932015506\n",
      "train loss:1.8447824287947048\n",
      "train loss:1.7920549247013622\n",
      "train loss:1.8054574201944869\n",
      "train loss:1.5985037192772455\n",
      "train loss:1.6536593023358237\n",
      "train loss:1.7571887627250071\n",
      "train loss:1.5937634882022322\n",
      "train loss:1.8223088597623864\n",
      "train loss:1.7262716789565349\n",
      "train loss:1.5512857368082444\n",
      "train loss:1.7101230537769863\n",
      "train loss:1.6152332710401274\n",
      "train loss:1.725956825404117\n",
      "train loss:1.78829500248844\n",
      "train loss:1.6218411617890183\n",
      "train loss:1.72196132398775\n",
      "train loss:1.4753673422602729\n",
      "train loss:1.4725422940417783\n",
      "train loss:1.6160728435360427\n",
      "train loss:1.5315206913511588\n",
      "train loss:1.785236279934968\n",
      "train loss:1.6235047018894313\n",
      "train loss:1.642671351187435\n",
      "train loss:1.6149410257740857\n",
      "train loss:1.4065783834110968\n",
      "train loss:1.6226334069898332\n",
      "train loss:1.466362255725543\n",
      "train loss:1.5879910099439585\n",
      "train loss:1.5640869719670065\n",
      "train loss:1.6389406852840307\n",
      "train loss:1.797601342492779\n",
      "train loss:1.5449527240519914\n",
      "train loss:1.5480871077385785\n",
      "train loss:1.5699335344643481\n",
      "train loss:1.5858615688414917\n",
      "train loss:1.632471824588326\n",
      "train loss:1.5231332925091448\n",
      "train loss:1.4665163052823207\n",
      "train loss:1.6026235542187441\n",
      "train loss:1.4254397109302304\n",
      "train loss:1.5918238221530607\n",
      "train loss:1.5694313999968454\n",
      "train loss:1.478942054442012\n",
      "train loss:1.573774821596527\n",
      "train loss:1.6152882787008018\n",
      "train loss:1.7391605479119767\n",
      "train loss:1.5197126240224323\n",
      "train loss:1.5107651756920897\n",
      "train loss:1.3246510246932528\n",
      "train loss:1.4515250525428989\n",
      "train loss:1.4918949225013862\n",
      "train loss:1.5296812014931513\n",
      "train loss:1.5164946245694937\n",
      "train loss:1.640370318302806\n",
      "train loss:1.5610776876721157\n",
      "train loss:1.3639478914325533\n",
      "train loss:1.6150769657779542\n",
      "train loss:1.3636918058784366\n",
      "train loss:1.5525959258162023\n",
      "train loss:1.585045333971773\n",
      "train loss:1.5234028754129911\n",
      "train loss:1.388582909997462\n",
      "train loss:1.4515362999704828\n",
      "train loss:1.4047102254833082\n",
      "train loss:1.5179768412207018\n",
      "train loss:1.3985646394850075\n",
      "train loss:1.2945308964037454\n",
      "train loss:1.4356465505189577\n",
      "train loss:1.662740507702379\n",
      "train loss:1.3909595589779542\n",
      "train loss:1.3295984184061327\n",
      "train loss:1.615451328003887\n",
      "train loss:1.4418010129401557\n",
      "train loss:1.3327411794802555\n",
      "train loss:1.4279788488580698\n",
      "train loss:1.660044255337689\n",
      "train loss:1.3401046395953933\n",
      "train loss:1.4318935158518464\n",
      "train loss:1.3108512493593332\n",
      "train loss:1.1297075730200994\n",
      "train loss:1.3970911140771176\n",
      "train loss:1.4202835156380047\n",
      "train loss:1.5913744875180493\n",
      "train loss:1.4947955726175124\n",
      "train loss:1.3298808967846318\n",
      "train loss:1.424836877787591\n",
      "train loss:1.5056370494851858\n",
      "train loss:1.248159257186886\n",
      "train loss:1.3970685629721045\n",
      "train loss:1.2927598122474413\n",
      "train loss:1.2810570362268925\n",
      "train loss:1.2748453645787157\n",
      "train loss:1.3262311383140348\n",
      "train loss:1.3998584931876659\n",
      "train loss:1.383638199124848\n",
      "train loss:1.21617217443702\n",
      "train loss:1.3619755406605776\n",
      "train loss:1.273543086487638\n",
      "train loss:1.4203564203513404\n",
      "train loss:1.3958469515217324\n",
      "train loss:1.3415517330707964\n",
      "train loss:1.4273818158478826\n",
      "train loss:1.5453712405983442\n",
      "train loss:1.4022026376006962\n",
      "train loss:1.4430959757833133\n",
      "train loss:1.396545704357851\n",
      "train loss:1.1552617447677604\n",
      "train loss:1.4547273279144646\n",
      "train loss:1.2285405614747238\n",
      "train loss:1.3594860789386618\n",
      "train loss:1.4415887041559257\n",
      "train loss:1.2033290574104596\n",
      "train loss:1.2296099715454267\n",
      "train loss:1.3280890113235273\n",
      "train loss:1.1754385496671853\n",
      "train loss:1.515296345836106\n",
      "train loss:1.3063902446409719\n",
      "train loss:1.309184822717463\n",
      "train loss:1.3564886967463194\n",
      "train loss:1.408452298299474\n",
      "train loss:1.110316392030536\n",
      "train loss:1.2931077586442763\n",
      "train loss:1.3979313404456122\n",
      "train loss:1.377764962155338\n",
      "train loss:1.434148904168332\n",
      "train loss:1.379546136167674\n",
      "train loss:1.3616703936646695\n",
      "train loss:1.4643729503557634\n",
      "train loss:1.2077312050309759\n",
      "train loss:1.323227134758371\n",
      "train loss:1.175443152962542\n",
      "train loss:1.247413126788093\n",
      "train loss:1.2620359426311867\n",
      "train loss:1.223856460417169\n",
      "train loss:1.3943816294687936\n",
      "train loss:1.3454566653592144\n",
      "train loss:1.2425210113760705\n",
      "train loss:1.2385655149625203\n",
      "train loss:1.3480660446530828\n",
      "train loss:1.2714236327559492\n",
      "train loss:1.08973990238475\n",
      "train loss:1.3462295486333553\n",
      "train loss:1.3882581781679164\n",
      "train loss:1.164937013209723\n",
      "train loss:1.2432364348860165\n",
      "train loss:1.2715522490913065\n",
      "train loss:1.1363622516804208\n",
      "train loss:1.1786978359651243\n",
      "train loss:1.293462073834326\n",
      "train loss:1.2484036074524638\n",
      "train loss:1.393723387993878\n",
      "train loss:1.33768882213856\n",
      "train loss:1.052391243359274\n",
      "train loss:1.3522748220012721\n",
      "train loss:1.1946666986359766\n",
      "train loss:1.149574963380151\n",
      "train loss:1.3219297130946015\n",
      "train loss:1.6009844520840755\n",
      "train loss:1.199432109616059\n",
      "train loss:1.237625303537881\n",
      "train loss:1.3267285923680086\n",
      "train loss:1.4228695441276171\n",
      "train loss:1.3943202929633387\n",
      "train loss:1.3529317588370193\n",
      "train loss:1.3602462563976914\n",
      "train loss:1.3461730338169966\n",
      "train loss:1.2215127997131958\n",
      "train loss:1.2890313105567826\n",
      "train loss:1.3154600935139233\n",
      "train loss:1.3637164734325182\n",
      "train loss:1.2455011272901346\n",
      "train loss:1.1907991796779234\n",
      "train loss:1.3023201322578744\n",
      "train loss:1.2577484243455954\n",
      "train loss:1.1233404511763154\n",
      "train loss:1.1524842648215092\n",
      "train loss:1.3177610048360164\n",
      "train loss:1.3191603876440905\n",
      "train loss:1.1868297821375764\n",
      "train loss:1.365220944546125\n",
      "train loss:1.1051979674674728\n",
      "train loss:1.243487160413091\n",
      "train loss:1.224955109962404\n",
      "train loss:1.243249385125446\n",
      "train loss:1.3226525990073434\n",
      "train loss:1.3373070923373322\n",
      "train loss:1.2671226025388602\n",
      "train loss:1.0985078824725631\n",
      "train loss:1.262511748581615\n",
      "train loss:1.0938474073301354\n",
      "train loss:1.3265926474752396\n",
      "train loss:1.2764529221618728\n",
      "train loss:1.225103646078309\n",
      "train loss:1.282616071437309\n",
      "train loss:1.0581554203155588\n",
      "train loss:1.4201332790170291\n",
      "train loss:1.1912998490064448\n",
      "train loss:1.242240860622316\n",
      "train loss:1.2782063043757355\n",
      "train loss:1.1878316787360028\n",
      "train loss:1.1419426103945058\n",
      "train loss:1.218174269330221\n",
      "train loss:1.2584248516748229\n",
      "train loss:1.0675626833903582\n",
      "train loss:1.1027300037406835\n",
      "train loss:1.202184269147989\n",
      "train loss:1.2110716835696003\n",
      "train loss:1.2914130392235494\n",
      "train loss:1.3753731499506592\n",
      "train loss:1.051575135667685\n",
      "train loss:1.114300858960082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.1120459848417676\n",
      "train loss:1.2631715085048345\n",
      "train loss:1.2600226468959352\n",
      "train loss:1.253232179874941\n",
      "train loss:1.176889464367606\n",
      "train loss:1.1589622485123539\n",
      "train loss:1.340385472156272\n",
      "train loss:1.1689687950993581\n",
      "train loss:1.0472635631106129\n",
      "train loss:1.0421406112791756\n",
      "train loss:1.2459160154014781\n",
      "train loss:1.2255574337347332\n",
      "train loss:1.4338522237615754\n",
      "train loss:1.2430837620694493\n",
      "train loss:1.2735088777550314\n",
      "train loss:1.1616030856495663\n",
      "train loss:1.3353657036210018\n",
      "train loss:1.071079075131267\n",
      "train loss:1.2346143523411142\n",
      "train loss:1.0844269310573775\n",
      "train loss:1.0422414732585477\n",
      "train loss:1.2837404023595715\n",
      "train loss:1.120263334335923\n",
      "train loss:1.1457785134107124\n",
      "train loss:1.1893026592307279\n",
      "train loss:1.2658943855495866\n",
      "train loss:1.230524438507672\n",
      "train loss:1.1583201330582116\n",
      "train loss:1.2285803476080246\n",
      "train loss:1.0453786706336\n",
      "train loss:1.2624829409531193\n",
      "train loss:1.336405619720742\n",
      "train loss:1.2208762533769708\n",
      "train loss:0.9130341766440699\n",
      "train loss:0.8888773602608897\n",
      "train loss:1.0875860245175248\n",
      "train loss:1.2801696581950839\n",
      "train loss:1.1115655385695982\n",
      "train loss:1.0414278187793244\n",
      "train loss:1.23257925641032\n",
      "train loss:1.0881367036443121\n",
      "train loss:1.2625936093247\n",
      "train loss:1.15311469916529\n",
      "train loss:1.1792528297490847\n",
      "train loss:1.1699882226181704\n",
      "train loss:1.0629864127852207\n",
      "train loss:1.105419484782709\n",
      "train loss:1.2199109124688607\n",
      "train loss:1.124775736795926\n",
      "train loss:1.1615418882444268\n",
      "train loss:1.1039355211731006\n",
      "train loss:1.2819982422861305\n",
      "train loss:1.175784486989819\n",
      "train loss:1.1415417274426536\n",
      "train loss:1.0265219630558893\n",
      "train loss:1.2603991632033473\n",
      "train loss:1.2891234658766064\n",
      "train loss:1.1595573840146154\n",
      "train loss:1.4124145306275284\n",
      "train loss:1.1011193863656472\n",
      "train loss:1.253285758740498\n",
      "train loss:1.0633415051684592\n",
      "train loss:1.1314008872018346\n",
      "train loss:1.0362000660528645\n",
      "train loss:1.0473477005837446\n",
      "train loss:1.215790937338757\n",
      "train loss:1.1015005171479355\n",
      "train loss:1.1307361359359056\n",
      "train loss:1.0949105854036911\n",
      "train loss:1.0895216660559726\n",
      "train loss:1.3007208198965186\n",
      "train loss:1.027280550793478\n",
      "train loss:1.1505043700863558\n",
      "train loss:1.1409083443030137\n",
      "train loss:0.9847622622014258\n",
      "train loss:1.0318513599662682\n",
      "train loss:1.177839094589308\n",
      "train loss:1.2501257635877343\n",
      "train loss:1.3568450637613427\n",
      "train loss:1.1973467030337455\n",
      "train loss:1.1019397357423495\n",
      "train loss:1.1286058057989998\n",
      "train loss:1.2606847218136092\n",
      "train loss:1.219605055815717\n",
      "train loss:1.256970074125915\n",
      "train loss:1.2502073244892253\n",
      "train loss:1.185619940432031\n",
      "train loss:1.3349445492798113\n",
      "train loss:1.1270142903062932\n",
      "train loss:1.1577771252987439\n",
      "train loss:1.1873701912835641\n",
      "train loss:1.1455452310287413\n",
      "train loss:1.1852560754842008\n",
      "train loss:1.0477423798171122\n",
      "train loss:1.0667588379212467\n",
      "train loss:1.127167727446432\n",
      "train loss:1.2289665177351636\n",
      "train loss:1.2519400741691038\n",
      "train loss:1.299775218354323\n",
      "train loss:1.0608213368517267\n",
      "train loss:0.9958321292622381\n",
      "train loss:1.1346170575836978\n",
      "train loss:1.0119119991577077\n",
      "train loss:1.124218349103542\n",
      "train loss:1.2191197833039995\n",
      "train loss:1.1919915982770997\n",
      "train loss:1.1207254526776311\n",
      "train loss:1.2243663378543976\n",
      "train loss:1.0456919592209755\n",
      "train loss:1.2097666282871804\n",
      "train loss:1.149859452894865\n",
      "train loss:1.0002819996956525\n",
      "train loss:1.14405571763306\n",
      "train loss:1.0871196934324343\n",
      "train loss:1.039444583417864\n",
      "train loss:1.1877628739454569\n",
      "train loss:1.1467566619507494\n",
      "train loss:1.1641568531048396\n",
      "train loss:1.136262531663801\n",
      "train loss:1.2495430518981037\n",
      "train loss:1.0711043553644661\n",
      "train loss:1.3011772989319519\n",
      "train loss:1.0302257213990509\n",
      "train loss:1.1623042982438032\n",
      "train loss:1.198425038718115\n",
      "train loss:1.1876878861125213\n",
      "train loss:1.1303818703835296\n",
      "train loss:1.041268092879064\n",
      "train loss:1.1497042509722586\n",
      "train loss:1.1093336640408342\n",
      "train loss:1.0382118603619646\n",
      "train loss:1.18098608941267\n",
      "train loss:1.233341394057028\n",
      "train loss:1.130027466178661\n",
      "train loss:0.95073882035634\n",
      "train loss:0.9258354030819602\n",
      "train loss:1.0228444173896534\n",
      "train loss:1.0232635498804548\n",
      "train loss:1.2452255304371205\n",
      "train loss:1.1372365158805149\n",
      "train loss:1.0537309384902944\n",
      "train loss:1.0448906245952845\n",
      "train loss:1.1710667781658326\n",
      "train loss:1.1063460747950151\n",
      "train loss:1.1011362940002918\n",
      "train loss:1.116182249558961\n",
      "train loss:1.2077773185059275\n",
      "train loss:1.1244576024016721\n",
      "train loss:1.1926438489772684\n",
      "train loss:1.1115500544310277\n",
      "train loss:1.156190540404439\n",
      "train loss:0.941245903966498\n",
      "train loss:1.1401834114530862\n",
      "train loss:0.92050178034854\n",
      "train loss:1.1321786905410798\n",
      "train loss:1.1640379506912992\n",
      "train loss:1.1697130518624752\n",
      "train loss:1.1870276060602898\n",
      "train loss:1.13406974220197\n",
      "train loss:1.1914324685019164\n",
      "train loss:1.0193856541487971\n",
      "train loss:1.3195170824385611\n",
      "train loss:0.8890673128273653\n",
      "train loss:1.0122165425171226\n",
      "train loss:1.1094307625374795\n",
      "train loss:0.9873096124344082\n",
      "train loss:0.9537438873122897\n",
      "train loss:0.9696059550911074\n",
      "train loss:0.971861670721837\n",
      "train loss:1.1363582762329185\n",
      "train loss:1.0445504896659545\n",
      "train loss:0.8642847042498982\n",
      "train loss:1.0337507381467546\n",
      "train loss:1.050041704558314\n",
      "train loss:1.1010877492262874\n",
      "train loss:1.020278665529256\n",
      "train loss:1.080301794899239\n",
      "train loss:0.981957754807215\n",
      "train loss:1.1334126591819815\n",
      "train loss:1.0012829597935196\n",
      "train loss:1.3287477109504156\n",
      "train loss:1.1291478728394606\n",
      "train loss:1.0596105462482688\n",
      "train loss:1.1329175726089518\n",
      "train loss:1.237037121009817\n",
      "train loss:1.0483666972681174\n",
      "train loss:1.0931023539401423\n",
      "train loss:0.9988204753578916\n",
      "train loss:1.068535816770849\n",
      "train loss:1.098297454402625\n",
      "train loss:1.0764308264851503\n",
      "train loss:1.001788859138177\n",
      "train loss:1.4214111787366905\n",
      "train loss:0.9299550575138614\n",
      "train loss:1.1083086291193016\n",
      "train loss:1.0510832066206017\n",
      "train loss:1.218616731189824\n",
      "train loss:0.9840117603267546\n",
      "train loss:0.939305484856355\n",
      "train loss:1.042912865852637\n",
      "train loss:1.0590249544561927\n",
      "train loss:1.0244095168155036\n",
      "train loss:0.9533592031331487\n",
      "train loss:1.0879498095997333\n",
      "train loss:1.1963554098080829\n",
      "train loss:1.3549419795904438\n",
      "train loss:0.9773775469905247\n",
      "train loss:0.8983530600366305\n",
      "train loss:1.1265294280491935\n",
      "train loss:1.1768860728930266\n",
      "train loss:0.982892253340528\n",
      "train loss:1.0605969750121154\n",
      "train loss:1.2007501804460932\n",
      "train loss:1.1160579408982785\n",
      "train loss:1.0773902861466764\n",
      "train loss:1.0783326979615726\n",
      "train loss:0.9113060665542259\n",
      "train loss:1.2106992245519554\n",
      "train loss:1.1113289626226437\n",
      "train loss:1.0198168089480488\n",
      "train loss:0.9586231999081258\n",
      "train loss:1.0498586034530224\n",
      "train loss:1.257390833003256\n",
      "train loss:1.2773158398574354\n",
      "train loss:1.0210948032861493\n",
      "train loss:1.1035263564541005\n",
      "train loss:1.0986098037836842\n",
      "train loss:0.9070149581154391\n",
      "train loss:1.2060750344669369\n",
      "train loss:0.9088398843538785\n",
      "train loss:1.1457899706168568\n",
      "train loss:1.1592776828654434\n",
      "train loss:1.187296232959292\n",
      "train loss:1.1971087633981494\n",
      "train loss:1.133261768317761\n",
      "train loss:1.062417490908128\n",
      "train loss:1.1499610929420503\n",
      "train loss:1.2607055866937378\n",
      "train loss:1.0162943575489185\n",
      "train loss:0.9908949287410007\n",
      "train loss:1.0594463323186498\n",
      "train loss:1.11993484554326\n",
      "train loss:1.2358202701413785\n",
      "train loss:1.0722908180876018\n",
      "train loss:0.965282396067311\n",
      "train loss:0.8476457309413634\n",
      "train loss:1.004425523453732\n",
      "train loss:1.032008751221838\n",
      "train loss:1.047624902981645\n",
      "train loss:1.0909545023540994\n",
      "train loss:0.9691990878543741\n",
      "train loss:0.8552793298851359\n",
      "train loss:1.3139734044618288\n",
      "train loss:0.9042760441316109\n",
      "train loss:1.3672422176208001\n",
      "train loss:1.0884304675584862\n",
      "train loss:1.0293395698992782\n",
      "train loss:1.1820548557265271\n",
      "train loss:1.1109073592709477\n",
      "train loss:1.0578780241058616\n",
      "train loss:1.0053600666957407\n",
      "train loss:1.1275456123306844\n",
      "train loss:1.0214434187550017\n",
      "train loss:1.0972143402527716\n",
      "train loss:1.1284492659097705\n",
      "train loss:1.02741354890451\n",
      "train loss:1.001024477948894\n",
      "train loss:0.9908491076959041\n",
      "train loss:1.1901805672401558\n",
      "train loss:0.9782768035005062\n",
      "train loss:1.045988580365746\n",
      "train loss:1.16372084619932\n",
      "train loss:1.0594523966482683\n",
      "train loss:1.0591451586489482\n",
      "train loss:1.0551760893913669\n",
      "train loss:0.9824888957193477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0155861068278906\n",
      "train loss:0.9505900629206643\n",
      "train loss:1.084217310399633\n",
      "train loss:1.0056818495318225\n",
      "train loss:0.9393426277091835\n",
      "train loss:1.0430815353076046\n",
      "train loss:1.2405168499904065\n",
      "train loss:1.1255925445306532\n",
      "train loss:0.9227369742949273\n",
      "train loss:1.0851106023839023\n",
      "train loss:1.0708367127956024\n",
      "train loss:1.0911483419480141\n",
      "train loss:1.1192512547261875\n",
      "train loss:1.1867195872356886\n",
      "train loss:1.0976817140576367\n",
      "train loss:0.8399893448896202\n",
      "train loss:0.9639991393166462\n",
      "train loss:1.0941321373850266\n",
      "train loss:1.0545806916656162\n",
      "train loss:0.9632489820589097\n",
      "train loss:0.9827018175488001\n",
      "train loss:1.1085560319815952\n",
      "train loss:1.3908802814464283\n",
      "train loss:1.1773201316163526\n",
      "train loss:1.0291732489931082\n",
      "train loss:1.0952333981390907\n",
      "train loss:1.108998176376342\n",
      "train loss:0.9560599522183787\n",
      "train loss:1.0617765234393581\n",
      "train loss:1.0666384794725645\n",
      "train loss:0.984665570689331\n",
      "train loss:1.0431096760536784\n",
      "train loss:1.0479028714622145\n",
      "train loss:0.9574467508912202\n",
      "train loss:0.9181975117199008\n",
      "train loss:0.9996299574568781\n",
      "train loss:0.9262116744916713\n",
      "train loss:1.0133911731130667\n",
      "train loss:1.0071618383083818\n",
      "train loss:1.0697098042106457\n",
      "train loss:1.2737155904409567\n",
      "train loss:1.107661583683191\n",
      "train loss:1.068440340164694\n",
      "train loss:0.8971848165695689\n",
      "train loss:1.0717632437743994\n",
      "train loss:1.0458870131977447\n",
      "train loss:1.0715415872694287\n",
      "train loss:1.0356177093789583\n",
      "train loss:1.0409469283838126\n",
      "train loss:1.0591960039078336\n",
      "=== epoch:2, train acc:0.973, test acc:0.971 ===\n",
      "train loss:1.0861354738239966\n",
      "train loss:0.9603584647755968\n",
      "train loss:0.8871347512686379\n",
      "train loss:1.0770926100256681\n",
      "train loss:1.077486729606786\n",
      "train loss:0.9899097218100822\n",
      "train loss:0.9457104460983232\n",
      "train loss:0.9260208731461471\n",
      "train loss:1.2080285172323364\n",
      "train loss:1.139353246899135\n",
      "train loss:0.9637908592888624\n",
      "train loss:1.0468225263821442\n",
      "train loss:1.0650284373449035\n",
      "train loss:1.0373791746576784\n",
      "train loss:1.0413343333480647\n",
      "train loss:0.9729244255390522\n",
      "train loss:1.213100672955778\n",
      "train loss:0.9702035345611673\n",
      "train loss:1.0602190849952897\n",
      "train loss:1.0815560090634493\n",
      "train loss:0.9360352843119815\n",
      "train loss:1.0703482550665968\n",
      "train loss:1.0286764818811092\n",
      "train loss:1.0384642574296838\n",
      "train loss:1.210241339916433\n",
      "train loss:1.207259003687692\n",
      "train loss:1.1164249076818067\n",
      "train loss:1.002819600571124\n",
      "train loss:1.0803216796888788\n",
      "train loss:1.1268030512854523\n",
      "train loss:1.0513371570553407\n",
      "train loss:0.98053341290015\n",
      "train loss:1.0079174359577088\n",
      "train loss:0.916676926076925\n",
      "train loss:1.0793323318265542\n",
      "train loss:1.0031043348628021\n",
      "train loss:1.0036255568505887\n",
      "train loss:1.1230353303739948\n",
      "train loss:1.15348365332249\n",
      "train loss:1.22035930573686\n",
      "train loss:0.9732301529803725\n",
      "train loss:1.1313719810156269\n",
      "train loss:1.1428026468007986\n",
      "train loss:0.9249697907270905\n",
      "train loss:1.1714149617010565\n",
      "train loss:1.0593313864230212\n",
      "train loss:0.9983995265789051\n",
      "train loss:1.0665719281704127\n",
      "train loss:1.01524949187192\n",
      "train loss:1.0564920009399277\n",
      "train loss:0.8972675117096004\n",
      "train loss:0.9760796633132003\n",
      "train loss:0.9677470151332066\n",
      "train loss:0.9524923072545372\n",
      "train loss:0.8967716715094489\n",
      "train loss:1.035439264553002\n",
      "train loss:1.0948919175668597\n",
      "train loss:1.1085856155374996\n",
      "train loss:1.0560491772849898\n",
      "train loss:0.9447954653010159\n",
      "train loss:1.0732701939654632\n",
      "train loss:0.8997413397324041\n",
      "train loss:0.9971980910898037\n",
      "train loss:0.9254865881010109\n",
      "train loss:1.0556925362681882\n",
      "train loss:1.2479394190339341\n",
      "train loss:1.1564478200981514\n",
      "train loss:1.083123758876885\n",
      "train loss:0.94875274744839\n",
      "train loss:0.9158539012882825\n",
      "train loss:1.057510056455174\n",
      "train loss:1.126683408567733\n",
      "train loss:1.0632095809998716\n",
      "train loss:0.967239753430228\n",
      "train loss:0.7406748872152937\n",
      "train loss:0.8821208675726679\n",
      "train loss:1.0820496188916184\n",
      "train loss:1.0647652047763088\n",
      "train loss:1.1630864730891783\n",
      "train loss:1.0818328855211172\n",
      "train loss:1.0538144598368617\n",
      "train loss:1.1286964469030873\n",
      "train loss:1.0612930054220657\n",
      "train loss:0.8428313863404113\n",
      "train loss:1.00527979728015\n",
      "train loss:1.0355780442287075\n",
      "train loss:1.045120613216978\n",
      "train loss:0.932290836105034\n",
      "train loss:1.2183937759387138\n",
      "train loss:1.1751986568204629\n",
      "train loss:0.9176079286738167\n",
      "train loss:1.1748738039898143\n",
      "train loss:1.158818957585101\n",
      "train loss:0.9819310526815529\n",
      "train loss:0.9574181637965671\n",
      "train loss:0.9272030521420987\n",
      "train loss:0.9520387997448804\n",
      "train loss:1.2769242720356457\n",
      "train loss:1.082613476672107\n",
      "train loss:1.071124713624051\n",
      "train loss:1.0974142278265269\n",
      "train loss:0.9344668146214242\n",
      "train loss:0.9663111831683783\n",
      "train loss:0.8785346452673253\n",
      "train loss:0.8151152038973641\n",
      "train loss:0.9374264434352171\n",
      "train loss:1.0971371176919293\n",
      "train loss:1.143836550898407\n",
      "train loss:0.9364228369225363\n",
      "train loss:0.9697947104562985\n",
      "train loss:0.7650256655448712\n",
      "train loss:1.185815460740879\n",
      "train loss:1.005896321256327\n",
      "train loss:1.2594314059693132\n",
      "train loss:0.9655271183482893\n",
      "train loss:1.0070720821469243\n",
      "train loss:1.0395296206181321\n",
      "train loss:0.9947777535549358\n",
      "train loss:1.0743448777987432\n",
      "train loss:1.0582175670626308\n",
      "train loss:1.1768286011135953\n",
      "train loss:1.189330843332241\n",
      "train loss:1.0400521033132473\n",
      "train loss:0.8870852922871407\n",
      "train loss:0.9427540477110478\n",
      "train loss:1.0254969002540861\n",
      "train loss:1.0164156259936938\n",
      "train loss:0.9954243118298352\n",
      "train loss:0.9672382312054935\n",
      "train loss:0.9921702872477912\n",
      "train loss:0.9089569801026741\n",
      "train loss:1.0345495369372693\n",
      "train loss:1.0512198882000752\n",
      "train loss:0.9398926765482609\n",
      "train loss:1.0032581676882297\n",
      "train loss:0.9369636846621644\n",
      "train loss:1.1030897696423814\n",
      "train loss:1.0582994881857388\n",
      "train loss:1.0491371764083905\n",
      "train loss:1.2069188877446035\n",
      "train loss:0.9122438360218308\n",
      "train loss:1.137695356620747\n",
      "train loss:1.0214920490986792\n",
      "train loss:0.9589625114828124\n",
      "train loss:0.9650785728933917\n",
      "train loss:1.011340932736126\n",
      "train loss:0.8761816624742391\n",
      "train loss:1.0128991833844525\n",
      "train loss:0.9910029283784564\n",
      "train loss:1.0868946086921472\n",
      "train loss:1.3338217822230607\n",
      "train loss:1.0450610649364769\n",
      "train loss:1.2267136324273429\n",
      "train loss:0.9517628885258946\n",
      "train loss:1.0157709440521538\n",
      "train loss:1.1408860461057886\n",
      "train loss:0.9140387290514953\n",
      "train loss:0.9713333456015288\n",
      "train loss:1.1656600311199836\n",
      "train loss:1.0641147942485893\n",
      "train loss:1.0299070978609748\n",
      "train loss:0.8497462284537298\n",
      "train loss:1.1240891070675056\n",
      "train loss:0.9271041032203943\n",
      "train loss:1.0741158208858805\n",
      "train loss:1.1161902315267185\n",
      "train loss:0.9980246253854489\n",
      "train loss:0.8969553839532977\n",
      "train loss:1.0305179626333587\n",
      "train loss:1.0516395384097172\n",
      "train loss:0.9952417597720303\n",
      "train loss:0.9600571728654714\n",
      "train loss:0.967716965353229\n",
      "train loss:0.9937051828981283\n",
      "train loss:0.9469597844409532\n",
      "train loss:1.0315666213619883\n",
      "train loss:0.987640657779686\n",
      "train loss:0.9800516220451345\n",
      "train loss:0.8368430482747249\n",
      "train loss:1.0540803250692308\n",
      "train loss:0.9196075607367357\n",
      "train loss:0.9328444769427446\n",
      "train loss:1.1107254806188775\n",
      "train loss:0.8761745012098764\n",
      "train loss:0.9508004628607467\n",
      "train loss:1.0390407763653267\n",
      "train loss:1.0177365748149885\n",
      "train loss:0.8654377470452101\n",
      "train loss:1.069211228326958\n",
      "train loss:0.8712166161890543\n",
      "train loss:1.0407585612123067\n",
      "train loss:1.168788807110491\n",
      "train loss:1.1213280808207768\n",
      "train loss:1.1034407360849399\n",
      "train loss:1.006187436927891\n",
      "train loss:1.1167450650794766\n",
      "train loss:0.8802504313906826\n",
      "train loss:0.9532005543929142\n",
      "train loss:1.1275951373109567\n",
      "train loss:1.0638564379395334\n",
      "train loss:1.0993149463195138\n",
      "train loss:0.8662408393116404\n",
      "train loss:0.9061328351158373\n",
      "train loss:1.089707467992959\n",
      "train loss:1.0145607193728166\n",
      "train loss:1.035909304731009\n",
      "train loss:1.101294012901589\n",
      "train loss:0.9763838139786637\n",
      "train loss:1.0979575353870237\n",
      "train loss:1.0598140550705717\n",
      "train loss:0.9863444472148538\n",
      "train loss:1.0840809831774747\n",
      "train loss:0.9683589286733261\n",
      "train loss:1.1410891979126603\n",
      "train loss:1.2159993007387653\n",
      "train loss:1.0968536911036673\n",
      "train loss:0.9569919481899359\n",
      "train loss:0.9716689581688999\n",
      "train loss:0.9110739526212107\n",
      "train loss:1.0321906798114477\n",
      "train loss:0.9844269741070701\n",
      "train loss:1.102167176238538\n",
      "train loss:1.130084750490806\n",
      "train loss:0.995784596735253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9498687286892574\n",
      "train loss:0.9835878526389\n",
      "train loss:1.0190244242054043\n",
      "train loss:1.02427628305391\n",
      "train loss:1.0217347953792295\n",
      "train loss:1.0598198430491994\n",
      "train loss:0.999881949534967\n",
      "train loss:1.147028390863633\n",
      "train loss:1.0800188553299748\n",
      "train loss:0.9268930859481564\n",
      "train loss:1.12809019193976\n",
      "train loss:1.0386240296476945\n",
      "train loss:0.9221320134841118\n",
      "train loss:0.8523505266669684\n",
      "train loss:0.8920243822666472\n",
      "train loss:1.0600823129670358\n",
      "train loss:0.9600783581734308\n",
      "train loss:1.1027688555879418\n",
      "train loss:1.0255472752656003\n",
      "train loss:1.0604898303064203\n",
      "train loss:0.9547416312632637\n",
      "train loss:0.7900207172260533\n",
      "train loss:0.8467541329927166\n",
      "train loss:1.0845180281265738\n",
      "train loss:1.0436906134426664\n",
      "train loss:0.9296865550480014\n",
      "train loss:1.0405172405560854\n",
      "train loss:1.0856436665665523\n",
      "train loss:0.8480670904968939\n",
      "train loss:1.067405564410658\n",
      "train loss:1.117043271359649\n",
      "train loss:1.1136086917852348\n",
      "train loss:1.0083550846072777\n",
      "train loss:1.1457918634143964\n",
      "train loss:0.8336848835497339\n",
      "train loss:0.85497485678609\n",
      "train loss:0.8911872660570727\n",
      "train loss:0.8523819666278848\n",
      "train loss:0.981686663184747\n",
      "train loss:0.7797017853646843\n",
      "train loss:1.0828813037006304\n",
      "train loss:1.023797408052229\n",
      "train loss:0.8650502768893541\n",
      "train loss:0.9440627775820454\n",
      "train loss:0.9564724053772475\n",
      "train loss:1.0153064322007828\n",
      "train loss:1.0954991526764843\n",
      "train loss:0.9171289679180349\n",
      "train loss:0.8714781824628216\n",
      "train loss:1.1069575762667467\n",
      "train loss:0.8497955709782917\n",
      "train loss:1.0701095013507649\n",
      "train loss:1.1193649050893697\n",
      "train loss:0.9883208356663117\n",
      "train loss:1.147231600813697\n",
      "train loss:0.9537172925549681\n",
      "train loss:0.9065709535377198\n",
      "train loss:1.0116133727541021\n",
      "train loss:0.954881783414683\n",
      "train loss:1.0960262182365736\n",
      "train loss:0.9284685861208982\n",
      "train loss:1.0228068012796898\n",
      "train loss:1.0818494089781305\n",
      "train loss:0.8794009919071457\n",
      "train loss:1.1682988671838228\n",
      "train loss:0.8497024539321368\n",
      "train loss:1.0894367129893623\n",
      "train loss:1.0064424293705505\n",
      "train loss:1.1573817602886403\n",
      "train loss:1.068527524794238\n",
      "train loss:1.0043560308905564\n",
      "train loss:0.929032728664245\n",
      "train loss:0.8714700570987105\n",
      "train loss:0.8626677911416507\n",
      "train loss:1.0688326151526788\n",
      "train loss:1.0316934473701393\n",
      "train loss:0.9609282011443194\n",
      "train loss:0.9405562651023839\n",
      "train loss:1.0336677188243824\n",
      "train loss:1.0947832318185635\n",
      "train loss:0.8946275500237355\n",
      "train loss:0.8444871372496714\n",
      "train loss:0.9715411922397169\n",
      "train loss:1.1724419346697952\n",
      "train loss:0.680782804688826\n",
      "train loss:0.8390120768693048\n",
      "train loss:0.9935901165055148\n",
      "train loss:0.9648272034834207\n",
      "train loss:0.8561773711864695\n",
      "train loss:1.1419482989114402\n",
      "train loss:0.9663654695260795\n",
      "train loss:1.0340937285879181\n",
      "train loss:1.1050592822476168\n",
      "train loss:1.0427874541923634\n",
      "train loss:0.9776542495499466\n",
      "train loss:0.7579982582967786\n",
      "train loss:0.8028083027352539\n",
      "train loss:0.9075879571317915\n",
      "train loss:0.9770371082138503\n",
      "train loss:1.17517034082937\n",
      "train loss:1.0120284473626626\n",
      "train loss:0.8884609219194524\n",
      "train loss:1.1042002975717617\n",
      "train loss:0.9416766365900803\n",
      "train loss:0.9418009104946347\n",
      "train loss:0.924833099356019\n",
      "train loss:0.9963027701013318\n",
      "train loss:1.0201261302628\n",
      "train loss:0.8534825504685389\n",
      "train loss:1.0163979186466825\n",
      "train loss:0.9304061929689916\n",
      "train loss:0.7294493982907886\n",
      "train loss:0.8847426350155871\n",
      "train loss:0.8465818202598895\n",
      "train loss:0.9242829407651346\n",
      "train loss:0.891507130895039\n",
      "train loss:1.1748053393895077\n",
      "train loss:1.0350836482229466\n",
      "train loss:1.060461991677353\n",
      "train loss:0.8579413596261558\n",
      "train loss:1.0877146541805578\n",
      "train loss:0.9622052950018803\n",
      "train loss:0.9888515880933194\n",
      "train loss:0.9588589527008569\n",
      "train loss:0.9971316086229371\n",
      "train loss:1.0074561127683284\n",
      "train loss:0.9448517794408612\n",
      "train loss:0.8775854234919884\n",
      "train loss:0.9020218144145739\n",
      "train loss:1.0836417706929304\n",
      "train loss:0.9698515859998339\n",
      "train loss:0.9053406792599621\n",
      "train loss:1.0445918621020363\n",
      "train loss:1.0850357701321376\n",
      "train loss:0.9398364943934026\n",
      "train loss:1.0249027659934336\n",
      "train loss:0.8169743387941469\n",
      "train loss:1.0280631091222525\n",
      "train loss:1.0089318314824127\n",
      "train loss:1.1571074954180467\n",
      "train loss:0.9651144842775932\n",
      "train loss:1.0162471384396594\n",
      "train loss:0.8968861752806555\n",
      "train loss:0.9192786929585608\n",
      "train loss:1.0955155829079535\n",
      "train loss:1.1169959279005774\n",
      "train loss:0.8989381438960734\n",
      "train loss:0.9547164777941726\n",
      "train loss:0.8853466187324172\n",
      "train loss:1.035747692564978\n",
      "train loss:1.0277864227822786\n",
      "train loss:0.960147260389319\n",
      "train loss:1.0123540435750025\n",
      "train loss:0.9244298807882673\n",
      "train loss:0.9854466212773917\n",
      "train loss:1.0084264496489501\n",
      "train loss:0.9970999324814498\n",
      "train loss:1.0159283896144624\n",
      "train loss:0.9152682594803265\n",
      "train loss:1.0720805452163902\n",
      "train loss:0.9448669947285591\n",
      "train loss:0.9723702464133713\n",
      "train loss:0.9417290266170771\n",
      "train loss:0.9321419810488533\n",
      "train loss:0.8469005436169076\n",
      "train loss:0.9304810340329189\n",
      "train loss:1.079369145675228\n",
      "train loss:1.026033899959808\n",
      "train loss:1.0088822306184448\n",
      "train loss:1.03372944685082\n",
      "train loss:0.7668854143598076\n",
      "train loss:1.1111579919795411\n",
      "train loss:0.9785808416608605\n",
      "train loss:0.9063652059215176\n",
      "train loss:1.035235840633557\n",
      "train loss:1.0239121904245982\n",
      "train loss:1.1180841579201473\n",
      "train loss:0.9887171429367873\n",
      "train loss:1.029270208601038\n",
      "train loss:1.1364053665037956\n",
      "train loss:0.9420124408936316\n",
      "train loss:0.9791455950148618\n",
      "train loss:1.0673528320621737\n",
      "train loss:0.9424725810518756\n",
      "train loss:0.9453471614639751\n",
      "train loss:0.9580322902222745\n",
      "train loss:0.9989201749609162\n",
      "train loss:0.9227058549473007\n",
      "train loss:0.9898701774007064\n",
      "train loss:1.0130234052843472\n",
      "train loss:0.9586320110868166\n",
      "train loss:0.8832504462270986\n",
      "train loss:1.0764983575007712\n",
      "train loss:1.0440611856716844\n",
      "train loss:1.0526661678622173\n",
      "train loss:1.0485479525255095\n",
      "train loss:0.9344229857045864\n",
      "train loss:0.9330200389569764\n",
      "train loss:0.8165551660110794\n",
      "train loss:0.9271530845187024\n",
      "train loss:1.035903803053995\n",
      "train loss:1.0961214557097798\n",
      "train loss:1.1465252858018091\n",
      "train loss:0.9812790251158855\n",
      "train loss:1.129453514711748\n",
      "train loss:1.0716732636798267\n",
      "train loss:0.9769165543965478\n",
      "train loss:0.8954629205807738\n",
      "train loss:0.824422213819155\n",
      "train loss:0.9627946512625196\n",
      "train loss:0.835202394801177\n",
      "train loss:0.9941648211378502\n",
      "train loss:0.9945028198560337\n",
      "train loss:1.1407523520249128\n",
      "train loss:1.005577250021468\n",
      "train loss:0.9749997553591482\n",
      "train loss:0.9577459247765933\n",
      "train loss:0.8821483789765524\n",
      "train loss:0.9463581122048694\n",
      "train loss:1.145839799045711\n",
      "train loss:1.00337906253766\n",
      "train loss:1.2647305321509563\n",
      "train loss:0.9490608620065784\n",
      "train loss:0.8764462622597313\n",
      "train loss:0.9966714993914506\n",
      "train loss:0.8966323765981576\n",
      "train loss:1.0281414273503064\n",
      "train loss:1.0219751821451524\n",
      "train loss:0.9010207105814471\n",
      "train loss:0.9495294380089412\n",
      "train loss:1.0247940988610067\n",
      "train loss:0.9396224532930789\n",
      "train loss:0.8962484831904023\n",
      "train loss:0.9269943434909531\n",
      "train loss:0.8994815683552243\n",
      "train loss:0.9932679043339313\n",
      "train loss:1.0389931754903219\n",
      "train loss:0.9340906049823932\n",
      "train loss:0.8890632744084254\n",
      "train loss:0.9934612511664015\n",
      "train loss:0.9572814051869537\n",
      "train loss:0.9745850104826299\n",
      "train loss:0.8690034641931567\n",
      "train loss:1.0023107818031296\n",
      "train loss:0.9634025330478522\n",
      "train loss:0.9270845214158827\n",
      "train loss:1.3292110046460073\n",
      "train loss:0.8866857250100658\n",
      "train loss:1.0834014428690972\n",
      "train loss:1.0890749096632888\n",
      "train loss:0.9474494849331768\n",
      "train loss:1.0383071582951802\n",
      "train loss:0.982225384107523\n",
      "train loss:0.863647086459025\n",
      "train loss:1.0742035786387274\n",
      "train loss:0.9715546270328451\n",
      "train loss:0.8986627710662018\n",
      "train loss:1.0488431049488771\n",
      "train loss:0.8710942565526242\n",
      "train loss:1.0563615359336915\n",
      "train loss:0.9888485910799405\n",
      "train loss:0.8202699732297947\n",
      "train loss:1.2017200439420004\n",
      "train loss:0.9446834375493467\n",
      "train loss:0.9775381099912362\n",
      "train loss:0.9683495196978998\n",
      "train loss:1.0582677544216\n",
      "train loss:0.9203780755481168\n",
      "train loss:0.8883567750216713\n",
      "train loss:1.007089322252887\n",
      "train loss:0.9878367994778126\n",
      "train loss:0.993151313166847\n",
      "train loss:0.9648092431279168\n",
      "train loss:0.9120517730097988\n",
      "train loss:1.0312579616867241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0695086965189606\n",
      "train loss:0.9995600401188323\n",
      "train loss:0.9472637368703108\n",
      "train loss:1.1273802443481957\n",
      "train loss:0.9130657277506389\n",
      "train loss:0.955167091208229\n",
      "train loss:1.0325789774576286\n",
      "train loss:1.0154696690589533\n",
      "train loss:1.0184058333910024\n",
      "train loss:1.063471115990785\n",
      "train loss:0.8859235692790383\n",
      "train loss:1.0597851629920059\n",
      "train loss:0.8899521797006926\n",
      "train loss:0.7753758628318317\n",
      "train loss:0.8282060873886461\n",
      "train loss:0.88946922947478\n",
      "train loss:1.0156655631182736\n",
      "train loss:0.9686191545754456\n",
      "train loss:0.958470330212053\n",
      "train loss:1.025203926611145\n",
      "train loss:0.8195046931126336\n",
      "train loss:0.8008429538284431\n",
      "train loss:0.8424133424699801\n",
      "train loss:1.0959227036933408\n",
      "train loss:0.8330020665930499\n",
      "train loss:0.8651157292150292\n",
      "train loss:1.203100987947985\n",
      "train loss:0.8107080064041403\n",
      "train loss:0.7850756439462448\n",
      "train loss:1.118285946996887\n",
      "train loss:1.041850362613321\n",
      "train loss:0.925769838985153\n",
      "train loss:0.98342889889058\n",
      "train loss:0.9366062979783679\n",
      "train loss:1.0053412651382105\n",
      "train loss:0.9195196855204972\n",
      "train loss:0.9875742916238053\n",
      "train loss:1.0618367217455313\n",
      "train loss:0.9314206805838328\n",
      "train loss:0.8353070561819226\n",
      "train loss:1.005347116610003\n",
      "train loss:0.9395747236376377\n",
      "train loss:0.9995965556770656\n",
      "train loss:0.9503684702819313\n",
      "train loss:1.0855906334815382\n",
      "train loss:0.8435904284951448\n",
      "train loss:1.0612267976769587\n",
      "train loss:0.9395554872011078\n",
      "train loss:0.9995335269105635\n",
      "train loss:0.9754624402661324\n",
      "train loss:0.8927789903310529\n",
      "train loss:0.9204359875899769\n",
      "train loss:0.8880248134854365\n",
      "train loss:1.0924965588470383\n",
      "train loss:1.050307811351444\n",
      "train loss:0.8402764580041745\n",
      "train loss:1.0147684168828146\n",
      "train loss:0.8915989185793818\n",
      "train loss:0.899155158598262\n",
      "train loss:0.7625529335533264\n",
      "train loss:1.051532321969358\n",
      "train loss:1.0126617553997153\n",
      "train loss:0.9139297981435572\n",
      "train loss:0.8156953407509655\n",
      "train loss:1.0395261567806136\n",
      "train loss:0.8424403501592682\n",
      "train loss:0.8829699356085682\n",
      "train loss:0.9701761049739249\n",
      "train loss:0.9443480565623742\n",
      "train loss:0.961248300259237\n",
      "train loss:1.009459559598169\n",
      "train loss:1.0534280988405993\n",
      "train loss:1.1707162130569282\n",
      "train loss:0.9197226155404948\n",
      "train loss:0.8286179574863065\n",
      "train loss:0.9287023125586066\n",
      "train loss:0.9404898138214294\n",
      "train loss:0.952550529878734\n",
      "train loss:0.8449666908133183\n",
      "train loss:0.9250643095429464\n",
      "train loss:1.012659952164177\n",
      "train loss:0.9986586073647912\n",
      "train loss:1.0814627872237412\n",
      "train loss:1.0047357918016706\n",
      "train loss:0.8773716831787378\n",
      "train loss:0.8614662826395971\n",
      "train loss:1.0063097820596167\n",
      "train loss:1.0386425679710036\n",
      "train loss:1.1222750281198193\n",
      "train loss:0.9030200832607888\n",
      "train loss:1.0046607020313163\n",
      "train loss:0.9756606391880177\n",
      "train loss:1.0963190656524846\n",
      "train loss:0.9430812500918628\n",
      "train loss:0.9911230531711438\n",
      "train loss:1.0706980990783215\n",
      "train loss:0.8232457131987319\n",
      "train loss:0.7425101351921974\n",
      "train loss:1.0257898729284165\n",
      "train loss:0.7938371513313544\n",
      "train loss:0.7833657180805411\n",
      "=== epoch:3, train acc:0.986, test acc:0.982 ===\n",
      "train loss:0.7622713407901351\n",
      "train loss:0.8781764946313534\n",
      "train loss:0.8696288454650655\n",
      "train loss:0.8707062489130537\n",
      "train loss:0.9685922013107647\n",
      "train loss:0.9578017771197836\n",
      "train loss:0.929354740464063\n",
      "train loss:0.9284546244031886\n",
      "train loss:0.8919822137604598\n",
      "train loss:0.8727870432481165\n",
      "train loss:0.9823192035442629\n",
      "train loss:0.8433440707120163\n",
      "train loss:0.9991191648828283\n",
      "train loss:0.8876873820167175\n",
      "train loss:0.9980169792133826\n",
      "train loss:1.0560149883362577\n",
      "train loss:1.0714906917885232\n",
      "train loss:0.8942447427586913\n",
      "train loss:0.9329508357665454\n",
      "train loss:1.1783074418810016\n",
      "train loss:1.0141543223260683\n",
      "train loss:1.0108661159860053\n",
      "train loss:0.9183655309393436\n",
      "train loss:0.9519941853232029\n",
      "train loss:0.9231675106204585\n",
      "train loss:1.0498879743895193\n",
      "train loss:1.0551426753922133\n",
      "train loss:0.8597354252733406\n",
      "train loss:0.8401324543841553\n",
      "train loss:0.9843079210130563\n",
      "train loss:0.7709030868303024\n",
      "train loss:1.1796606418470565\n",
      "train loss:0.902582363439759\n",
      "train loss:0.8928528674971736\n",
      "train loss:0.9915533914656546\n",
      "train loss:1.056473959007174\n",
      "train loss:0.8344589258901746\n",
      "train loss:0.99992839273661\n",
      "train loss:0.8337498295656087\n",
      "train loss:0.8977028061819098\n",
      "train loss:1.0847044990051402\n",
      "train loss:1.0486202969153278\n",
      "train loss:0.9947008853794614\n",
      "train loss:1.1194146140512453\n",
      "train loss:0.8825758410265584\n",
      "train loss:0.937034872720108\n",
      "train loss:0.8091229428680937\n",
      "train loss:1.0026127195435197\n",
      "train loss:0.9358355120516619\n",
      "train loss:0.9208872166452856\n",
      "train loss:0.8515677171701387\n",
      "train loss:0.7472946591501969\n",
      "train loss:0.9329246839693512\n",
      "train loss:1.0048653392464058\n",
      "train loss:1.1119049869877595\n",
      "train loss:0.8244973033850084\n",
      "train loss:1.0896215131256348\n",
      "train loss:0.9154458953161363\n",
      "train loss:0.9212126740157011\n",
      "train loss:0.953594564499754\n",
      "train loss:0.8100157541063866\n",
      "train loss:0.9375513999561419\n",
      "train loss:0.7639535495288247\n",
      "train loss:1.0183092578963875\n",
      "train loss:1.0463503515735757\n",
      "train loss:1.048045550657504\n",
      "train loss:0.9067009122255096\n",
      "train loss:0.9531979464636667\n",
      "train loss:0.8634197349632907\n",
      "train loss:0.79670884887911\n",
      "train loss:0.8363180600757038\n",
      "train loss:0.8348119301396091\n",
      "train loss:0.9280645564381272\n",
      "train loss:0.963361428740901\n",
      "train loss:1.057686215147578\n",
      "train loss:1.0395749501883251\n",
      "train loss:0.9574313675244227\n",
      "train loss:1.00305122624081\n",
      "train loss:1.0175657006451513\n",
      "train loss:1.023802200186153\n",
      "train loss:0.7889952070170494\n",
      "train loss:0.8303132720078092\n",
      "train loss:1.1003629903084515\n",
      "train loss:0.8209963900140467\n",
      "train loss:1.0050973582193716\n",
      "train loss:1.0229337671788492\n",
      "train loss:0.8715536617382219\n",
      "train loss:0.7885349171377111\n",
      "train loss:0.9232105459877431\n",
      "train loss:1.0077498574582195\n",
      "train loss:0.9352781501039267\n",
      "train loss:0.7965507055514698\n",
      "train loss:0.9037517557678143\n",
      "train loss:0.8388271082518637\n",
      "train loss:0.9746179124022977\n",
      "train loss:1.112607665226753\n",
      "train loss:0.9684286697865556\n",
      "train loss:0.8805721669570973\n",
      "train loss:0.8542009528081675\n",
      "train loss:1.0989579599356387\n",
      "train loss:0.8036490937951524\n",
      "train loss:0.9440412339459546\n",
      "train loss:0.8356799696424863\n",
      "train loss:0.9287276588416248\n",
      "train loss:1.0761404881932175\n",
      "train loss:0.9744360256043297\n",
      "train loss:1.0324835859827735\n",
      "train loss:0.8933734036575156\n",
      "train loss:0.9268263024804684\n",
      "train loss:0.9499086327356072\n",
      "train loss:1.0357678809368174\n",
      "train loss:1.0231039372596633\n",
      "train loss:1.038493688089867\n",
      "train loss:1.0215382224612006\n",
      "train loss:1.0307147302897846\n",
      "train loss:1.049432653575131\n",
      "train loss:0.863262143034952\n",
      "train loss:0.9577276678747362\n",
      "train loss:0.8794828910952335\n",
      "train loss:0.9847511444108713\n",
      "train loss:1.0865865337603045\n",
      "train loss:1.0016111827405851\n",
      "train loss:0.8401734847693705\n",
      "train loss:0.9264111875149407\n",
      "train loss:1.0734113135919423\n",
      "train loss:0.9668480523865282\n",
      "train loss:1.0949059452001866\n",
      "train loss:0.9189908691893354\n",
      "train loss:0.9483708285040617\n",
      "train loss:0.6190920116405579\n",
      "train loss:0.8849847711814262\n",
      "train loss:0.8599672900892127\n",
      "train loss:1.099684630042443\n",
      "train loss:0.9183625792040844\n",
      "train loss:0.9732252065253182\n",
      "train loss:0.831106302196085\n",
      "train loss:1.0519406252561168\n",
      "train loss:0.9532501861331659\n",
      "train loss:0.9279709062233876\n",
      "train loss:0.8696438803899871\n",
      "train loss:0.9073614954331721\n",
      "train loss:0.9770571694042378\n",
      "train loss:1.0516460087842854\n",
      "train loss:1.002582539997542\n",
      "train loss:0.8518149790152353\n",
      "train loss:0.9926549749277465\n",
      "train loss:0.9869839714190607\n",
      "train loss:1.1282713392266952\n",
      "train loss:0.9813558625260258\n",
      "train loss:0.9174494001982587\n",
      "train loss:0.8958032051091311\n",
      "train loss:1.0430891081478726\n",
      "train loss:0.9680291004243315\n",
      "train loss:0.9173072220941869\n",
      "train loss:0.8640107106003776\n",
      "train loss:1.0668568756868957\n",
      "train loss:0.9033194829395369\n",
      "train loss:0.8663015076718016\n",
      "train loss:0.8162227032020248\n",
      "train loss:0.8821690783962421\n",
      "train loss:0.9113195317347476\n",
      "train loss:0.9832318649019806\n",
      "train loss:1.05469752095789\n",
      "train loss:1.0309540052471078\n",
      "train loss:0.9267251044056168\n",
      "train loss:0.8704508907375613\n",
      "train loss:0.9544538222372091\n",
      "train loss:1.0336098855913844\n",
      "train loss:1.0297214834483404\n",
      "train loss:0.7609451825952656\n",
      "train loss:0.9757857151115753\n",
      "train loss:0.8840180325078042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.935156324729925\n",
      "train loss:1.0268545789634855\n",
      "train loss:1.0697860668159331\n",
      "train loss:0.7810479875652502\n",
      "train loss:0.9795375582333571\n",
      "train loss:0.860451834588794\n",
      "train loss:0.9630964376483355\n",
      "train loss:0.957041330550291\n",
      "train loss:0.9510361847980587\n",
      "train loss:0.7751296614975272\n",
      "train loss:0.9473436214945355\n",
      "train loss:1.0113138701382742\n",
      "train loss:1.3052808710004047\n",
      "train loss:1.0502787757563623\n",
      "train loss:0.8681736082109349\n",
      "train loss:0.8753664493332758\n",
      "train loss:0.7950309676474275\n",
      "train loss:0.915680406625137\n",
      "train loss:0.9612240037247143\n",
      "train loss:0.83956512237047\n",
      "train loss:0.9526531956100218\n",
      "train loss:0.8171171007590532\n",
      "train loss:0.8805500054971951\n",
      "train loss:0.9963805036046206\n",
      "train loss:0.8404670082979966\n",
      "train loss:0.8633240750246882\n",
      "train loss:0.9718176924555043\n",
      "train loss:0.890946415934858\n",
      "train loss:0.9801782620418555\n",
      "train loss:0.7823031549761211\n",
      "train loss:0.7824283034686471\n",
      "train loss:0.8868639981422046\n",
      "train loss:0.8637658316406798\n",
      "train loss:0.8433162166145476\n",
      "train loss:0.9706419361665489\n",
      "train loss:0.900139902932139\n",
      "train loss:0.9193297350091458\n",
      "train loss:0.9467963377124567\n",
      "train loss:0.86175806448587\n",
      "train loss:1.0479585487402074\n",
      "train loss:0.8186821740211405\n",
      "train loss:1.01719704052279\n",
      "train loss:1.0407433884862107\n",
      "train loss:0.8778314660638834\n",
      "train loss:0.9860415219078534\n",
      "train loss:0.5292078939739481\n",
      "train loss:0.9091047394595222\n",
      "train loss:0.9207135553988082\n",
      "train loss:0.8618141249795854\n",
      "train loss:0.8938742356566006\n",
      "train loss:0.8235623464599615\n",
      "train loss:1.106632726751309\n",
      "train loss:1.0340799297380283\n",
      "train loss:0.9770943680177017\n",
      "train loss:0.9350217349222877\n",
      "train loss:1.0161050099932492\n",
      "train loss:0.9500955139785588\n",
      "train loss:0.9840260247339714\n",
      "train loss:0.8779481164948685\n",
      "train loss:0.9121476399954784\n",
      "train loss:0.9833940276311747\n",
      "train loss:0.8135472251511431\n",
      "train loss:1.045476018644374\n",
      "train loss:0.9789112164464993\n",
      "train loss:0.9720109859589928\n",
      "train loss:1.0754882730654045\n",
      "train loss:0.9956648118808578\n",
      "train loss:1.0150655444123824\n",
      "train loss:0.9739182672975255\n",
      "train loss:1.0082950460715336\n",
      "train loss:0.9492329797102796\n",
      "train loss:0.9732823423953805\n",
      "train loss:0.9242201669784982\n",
      "train loss:0.8937327925112997\n",
      "train loss:0.7695371329420834\n",
      "train loss:1.0047948916660419\n",
      "train loss:0.9292884937121435\n",
      "train loss:1.0463439157574712\n",
      "train loss:0.8600139185152119\n",
      "train loss:0.9444373454820624\n",
      "train loss:1.082627784258598\n",
      "train loss:1.0505665230755405\n",
      "train loss:0.8938914319483482\n",
      "train loss:0.9137560351037185\n",
      "train loss:0.9344730539943435\n",
      "train loss:1.0770784136390625\n",
      "train loss:1.0775315955681888\n",
      "train loss:0.9494937496511874\n",
      "train loss:0.9652129511537835\n",
      "train loss:1.0924618978418859\n",
      "train loss:0.8985159699721937\n",
      "train loss:0.7713351334877063\n",
      "train loss:0.7976566958497802\n",
      "train loss:0.904366607776706\n",
      "train loss:1.0157807483394214\n",
      "train loss:1.010609062656856\n",
      "train loss:0.7612684392356144\n",
      "train loss:0.966747320899508\n",
      "train loss:1.0206669822703147\n",
      "train loss:0.9459916400312045\n",
      "train loss:1.095975818787895\n",
      "train loss:0.9822590415832351\n",
      "train loss:0.7501786525985149\n",
      "train loss:0.8752386597931503\n",
      "train loss:0.8827332616373645\n",
      "train loss:0.9618279293442688\n",
      "train loss:1.0725803641970912\n",
      "train loss:0.8939603404163481\n",
      "train loss:1.004999805057435\n",
      "train loss:0.9958803886518665\n",
      "train loss:0.9030614118167886\n",
      "train loss:0.8039906013632551\n",
      "train loss:0.8645927530565545\n",
      "train loss:0.9614864139209597\n",
      "train loss:0.9338516214691605\n",
      "train loss:0.9006861655099299\n",
      "train loss:0.8634161304607842\n",
      "train loss:0.8888239890486332\n",
      "train loss:0.9838220326773899\n",
      "train loss:1.0209036411791508\n",
      "train loss:0.8667125310973796\n",
      "train loss:0.8865241417712503\n",
      "train loss:0.9672030176099827\n",
      "train loss:1.0679553459394766\n",
      "train loss:0.8847850184858759\n",
      "train loss:1.0589623738522298\n",
      "train loss:0.7834516319886741\n",
      "train loss:1.0017326910505644\n",
      "train loss:0.9017453180832095\n",
      "train loss:1.184726769705535\n",
      "train loss:0.8696056808693797\n",
      "train loss:0.9832657092554292\n",
      "train loss:0.8487933788249501\n",
      "train loss:0.8652390185462195\n",
      "train loss:0.9569367771949437\n",
      "train loss:0.8045207542354504\n",
      "train loss:0.7677694604839435\n",
      "train loss:1.1128866396205452\n",
      "train loss:0.9302644001074571\n",
      "train loss:1.0283087167550664\n",
      "train loss:0.8707962655667545\n",
      "train loss:0.8985235038108889\n",
      "train loss:0.8380394244777983\n",
      "train loss:0.9692443773029291\n",
      "train loss:0.970835574530736\n",
      "train loss:0.9972232674151665\n",
      "train loss:0.9129043185703459\n",
      "train loss:0.9412671625727046\n",
      "train loss:0.8732736523721301\n",
      "train loss:0.8552781348317309\n",
      "train loss:0.8242827933546896\n",
      "train loss:0.8417185289318211\n",
      "train loss:0.9981792534433339\n",
      "train loss:0.8838466920578684\n",
      "train loss:0.8898322911506241\n",
      "train loss:1.0214134897001217\n",
      "train loss:0.8942039093757914\n",
      "train loss:0.8836737866480413\n",
      "train loss:0.9789843983694456\n",
      "train loss:1.0183745527385097\n",
      "train loss:0.9244431552688478\n",
      "train loss:0.8259676405613807\n",
      "train loss:0.8719575818921258\n",
      "train loss:0.7936921074660013\n",
      "train loss:1.0597012461936597\n",
      "train loss:0.9607680019307702\n",
      "train loss:0.8693052661724059\n",
      "train loss:0.8463028424302631\n",
      "train loss:0.9089708950674422\n",
      "train loss:1.0453346629936433\n",
      "train loss:1.0536383984689175\n",
      "train loss:1.0365719504325417\n",
      "train loss:1.0034970657482176\n",
      "train loss:1.0604573136447186\n",
      "train loss:0.9264236943504346\n",
      "train loss:1.0037729147382202\n",
      "train loss:0.9588832447524033\n",
      "train loss:0.7990792634407388\n",
      "train loss:1.0861054027349413\n",
      "train loss:1.0054256404230968\n",
      "train loss:0.7762732963597663\n",
      "train loss:1.068504070368733\n",
      "train loss:0.9649240795100924\n",
      "train loss:1.0635554688282556\n",
      "train loss:0.8723193023602563\n",
      "train loss:0.9591377984164828\n",
      "train loss:0.8187074796843308\n",
      "train loss:1.0126188313308546\n",
      "train loss:1.0102231614379382\n",
      "train loss:0.8244664985029305\n",
      "train loss:0.9747292450949849\n",
      "train loss:1.0048512785112533\n",
      "train loss:0.82540431977997\n",
      "train loss:0.9758358525412569\n",
      "train loss:0.9018377553863489\n",
      "train loss:0.7845583363040095\n",
      "train loss:0.7605883934988842\n",
      "train loss:0.8881080622317516\n",
      "train loss:0.8247773728034512\n",
      "train loss:0.8812927612218595\n",
      "train loss:0.9370847909403183\n",
      "train loss:0.7357156059536456\n",
      "train loss:1.0735837218151563\n",
      "train loss:0.7468867152029623\n",
      "train loss:0.9032361623547454\n",
      "train loss:0.9611835578137573\n",
      "train loss:0.8798782493531561\n",
      "train loss:0.9236962490472037\n",
      "train loss:1.243646055142104\n",
      "train loss:0.9728725424491662\n",
      "train loss:1.0548420937313034\n",
      "train loss:0.9762679708699573\n",
      "train loss:0.9743480676460083\n",
      "train loss:0.8766832692280775\n",
      "train loss:0.9320664619185547\n",
      "train loss:0.9758497884155649\n",
      "train loss:0.9813689779905843\n",
      "train loss:0.7997667206688032\n",
      "train loss:1.03781055485208\n",
      "train loss:0.9101895814989763\n",
      "train loss:1.1310031381742716\n",
      "train loss:1.256136594710835\n",
      "train loss:0.9917595041795886\n",
      "train loss:1.1009570859553919\n",
      "train loss:0.7888998570708714\n",
      "train loss:0.8185166596574526\n",
      "train loss:0.9598889683875522\n",
      "train loss:1.0002433077794186\n",
      "train loss:0.8057029918524837\n",
      "train loss:0.9409119969719957\n",
      "train loss:0.8702957474044211\n",
      "train loss:0.905546403743189\n",
      "train loss:0.8971728949763953\n",
      "train loss:0.8595240907827708\n",
      "train loss:0.8289044359637956\n",
      "train loss:0.9713912119422939\n",
      "train loss:0.9260970975521867\n",
      "train loss:1.083570176048373\n",
      "train loss:0.9463257696822203\n",
      "train loss:0.9465807737672054\n",
      "train loss:0.9527333425795687\n",
      "train loss:0.8531778657638539\n",
      "train loss:0.8152967318021309\n",
      "train loss:0.9671727980428928\n",
      "train loss:0.9538365054584647\n",
      "train loss:0.9022834425927476\n",
      "train loss:0.9592373181053321\n",
      "train loss:0.8962104060231182\n",
      "train loss:0.9821945597515327\n",
      "train loss:1.026313722859861\n",
      "train loss:0.7470417251031267\n",
      "train loss:1.012705461477497\n",
      "train loss:0.8560116411303724\n",
      "train loss:1.047954722142453\n",
      "train loss:0.9800832337169265\n",
      "train loss:0.8727268306458065\n",
      "train loss:0.9733834382563336\n",
      "train loss:1.0167240288403143\n",
      "train loss:0.8487177535095567\n",
      "train loss:1.0289435074520803\n",
      "train loss:0.7160062322245715\n",
      "train loss:0.8829463551241793\n",
      "train loss:0.8654843571613181\n",
      "train loss:0.8239409882461896\n",
      "train loss:0.9972479025987795\n",
      "train loss:1.0199898887802556\n",
      "train loss:0.967967604403451\n",
      "train loss:0.9411346276504878\n",
      "train loss:1.018328172387659\n",
      "train loss:1.0020500792413487\n",
      "train loss:0.8669984451880604\n",
      "train loss:0.865235851132538\n",
      "train loss:1.0213292388508348\n",
      "train loss:0.871306988879685\n",
      "train loss:0.8640013070090304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9380250896314688\n",
      "train loss:0.8548630649583363\n",
      "train loss:0.9539577757335789\n",
      "train loss:0.8762903047739676\n",
      "train loss:0.915876342150458\n",
      "train loss:1.1253906223700954\n",
      "train loss:0.8798001349789348\n",
      "train loss:0.9886538490210259\n",
      "train loss:0.9165184988878444\n",
      "train loss:0.8599276927245445\n",
      "train loss:0.8690600258955604\n",
      "train loss:0.9422319550394468\n",
      "train loss:1.0250779614637073\n",
      "train loss:0.9376886544978918\n",
      "train loss:0.8370009844619137\n",
      "train loss:0.9655319064691937\n",
      "train loss:0.8206025448627708\n",
      "train loss:1.0151596885640657\n",
      "train loss:0.8116228902902397\n",
      "train loss:0.8859152622657875\n",
      "train loss:0.9608200079282588\n",
      "train loss:0.9774529056340863\n",
      "train loss:0.9745508246155373\n",
      "train loss:0.9559669717355592\n",
      "train loss:1.0179838498503964\n",
      "train loss:0.8150439556468051\n",
      "train loss:1.0039760878040682\n",
      "train loss:0.8969456742960881\n",
      "train loss:1.0790744233364016\n",
      "train loss:0.8365643103151761\n",
      "train loss:0.8390972769045968\n",
      "train loss:0.984856312834358\n",
      "train loss:0.9759132327627662\n",
      "train loss:0.7859974049838463\n",
      "train loss:0.8968680783250541\n",
      "train loss:0.8200672871611501\n",
      "train loss:0.7383439823067519\n",
      "train loss:1.153227955133502\n",
      "train loss:1.0087110687835485\n",
      "train loss:0.7637253781055904\n",
      "train loss:0.9824231504355495\n",
      "train loss:0.8133784976320888\n",
      "train loss:0.9268588319319266\n",
      "train loss:1.0403383074036952\n",
      "train loss:0.8411834952311936\n",
      "train loss:0.9227976794286858\n",
      "train loss:0.9077433020144737\n",
      "train loss:1.0007136334463296\n",
      "train loss:0.8077859525467024\n",
      "train loss:1.0525111044330322\n",
      "train loss:1.0353271594362918\n",
      "train loss:0.8568438808824702\n",
      "train loss:1.0058744447358314\n",
      "train loss:0.9997069961651368\n",
      "train loss:0.8220156604801453\n",
      "train loss:0.8943555786334625\n",
      "train loss:1.0765634029831477\n",
      "train loss:0.9267537398653244\n",
      "train loss:1.0057285023114613\n",
      "train loss:0.9910505906452292\n",
      "train loss:0.9492949835054817\n",
      "train loss:0.8718729525100878\n",
      "train loss:0.8410477125615833\n",
      "train loss:0.9947194979975237\n",
      "train loss:0.929907461286717\n",
      "train loss:0.8729199719938967\n",
      "train loss:0.8736779479786524\n",
      "train loss:0.8563559561921709\n",
      "train loss:1.0796182851252487\n",
      "train loss:1.074872345811003\n",
      "train loss:0.8572732099915101\n",
      "train loss:0.8052027310364716\n",
      "train loss:0.9826672333618061\n",
      "train loss:1.060099922588818\n",
      "train loss:1.057374143498013\n",
      "train loss:0.7706182078177204\n",
      "train loss:0.9222884222935869\n",
      "train loss:0.9030111693421587\n",
      "train loss:1.0303848058169889\n",
      "train loss:1.0403931619135718\n",
      "train loss:0.8986257904390397\n",
      "train loss:0.9185099840909261\n",
      "train loss:1.1052316114858365\n",
      "train loss:0.9566175341808381\n",
      "train loss:0.9113982823638951\n",
      "train loss:1.0338136528409705\n",
      "train loss:1.0112762984022305\n",
      "train loss:0.8608456655998538\n",
      "train loss:1.0992052530450067\n",
      "train loss:1.0384108084377646\n",
      "train loss:0.9045731494839688\n",
      "train loss:1.0203866149489464\n",
      "train loss:0.8537486328436823\n",
      "train loss:0.9963124085956474\n",
      "train loss:0.900048164193145\n",
      "train loss:1.051305964313228\n",
      "train loss:0.9838964400134309\n",
      "train loss:1.0669113221219932\n",
      "train loss:0.8326286712067037\n",
      "train loss:0.9006773565207363\n",
      "train loss:1.0357933250721125\n",
      "train loss:0.8795667199495507\n",
      "train loss:1.0208373325418452\n",
      "train loss:0.8588980672263954\n",
      "train loss:0.9795707559727149\n",
      "train loss:1.0631935563365906\n",
      "train loss:0.9411195505943895\n",
      "train loss:0.8312624005130196\n",
      "train loss:0.8447228518118102\n",
      "train loss:0.8110364306667057\n",
      "train loss:1.1721671131225901\n",
      "train loss:0.9188090857305476\n",
      "train loss:0.9598374030758617\n",
      "train loss:1.0928856744852857\n",
      "train loss:0.8469836989623694\n",
      "train loss:1.0178607080188957\n",
      "train loss:0.9497913632670865\n",
      "train loss:1.0763908291599837\n",
      "train loss:1.0573246049795173\n",
      "train loss:0.9661090098758346\n",
      "train loss:1.0800961276149574\n",
      "train loss:1.0355917249972564\n",
      "train loss:1.1311862994417887\n",
      "train loss:0.8706279040616911\n",
      "train loss:1.0169267335382084\n",
      "train loss:0.9675065362084098\n",
      "train loss:0.9670705392097888\n",
      "train loss:1.11976761045965\n",
      "train loss:0.9855226038409367\n",
      "train loss:0.9323407522000637\n",
      "train loss:0.9429464085238238\n",
      "train loss:0.863327869332188\n",
      "train loss:0.9051498480729027\n",
      "train loss:0.9187439793950651\n",
      "train loss:0.7232292132286067\n",
      "train loss:1.0852661771315733\n",
      "train loss:0.7769313947586325\n",
      "train loss:0.9792765096666878\n",
      "train loss:1.170911783378475\n",
      "train loss:0.9900783843755318\n",
      "train loss:0.8720001588240816\n",
      "train loss:0.9423169627390906\n",
      "train loss:0.8597962503400146\n",
      "train loss:0.9927026936922841\n",
      "train loss:0.9168404538882303\n",
      "train loss:0.9819703655672888\n",
      "train loss:0.9593730295924785\n",
      "train loss:1.0670790791181368\n",
      "train loss:0.912379317279787\n",
      "train loss:1.0408019410992262\n",
      "train loss:0.9497954682928552\n",
      "train loss:1.0589572745922922\n",
      "train loss:1.0215843775795763\n",
      "=== epoch:4, train acc:0.986, test acc:0.986 ===\n",
      "train loss:0.9531544206517536\n",
      "train loss:0.9239051004891509\n",
      "train loss:0.96282245454222\n",
      "train loss:0.8566006020028506\n",
      "train loss:0.9798398939618401\n",
      "train loss:0.9378023574396716\n",
      "train loss:0.8603510099460285\n",
      "train loss:0.9657240930034939\n",
      "train loss:0.9751106794771583\n",
      "train loss:0.8734203347326236\n",
      "train loss:0.7504448261856637\n",
      "train loss:0.830431271413418\n",
      "train loss:0.951297553379286\n",
      "train loss:0.974388628413458\n",
      "train loss:0.8328170695513901\n",
      "train loss:0.86522006471431\n",
      "train loss:0.9508538738821244\n",
      "train loss:0.9029868458855005\n",
      "train loss:0.9146367743626262\n",
      "train loss:1.150251403974754\n",
      "train loss:0.8628185515665747\n",
      "train loss:0.8773859229648276\n",
      "train loss:0.9388427510887187\n",
      "train loss:0.8244871181107288\n",
      "train loss:0.8244860513610197\n",
      "train loss:0.9675879543223169\n",
      "train loss:0.9221130265527457\n",
      "train loss:0.9465473291105139\n",
      "train loss:1.0577785343703652\n",
      "train loss:0.9110182167576041\n",
      "train loss:1.0315176966238742\n",
      "train loss:0.9431721802264715\n",
      "train loss:0.8522019285760299\n",
      "train loss:1.0212534101812312\n",
      "train loss:0.8467798944735923\n",
      "train loss:0.9311166434126722\n",
      "train loss:0.9139144783191415\n",
      "train loss:0.9711157951743384\n",
      "train loss:0.9537021138314418\n",
      "train loss:0.9574174906115305\n",
      "train loss:0.9408938145819323\n",
      "train loss:0.9947541151120192\n",
      "train loss:1.0195687914721885\n",
      "train loss:1.002986045351781\n",
      "train loss:0.705276740508501\n",
      "train loss:0.9283739605479758\n",
      "train loss:0.9191817619807299\n",
      "train loss:0.9158740488515149\n",
      "train loss:1.0796545806817315\n",
      "train loss:0.8251267811685813\n",
      "train loss:0.9777298324328447\n",
      "train loss:0.9253825445799095\n",
      "train loss:0.9448950017387797\n",
      "train loss:0.8592159684555257\n",
      "train loss:0.9073242522010189\n",
      "train loss:0.9689144533530206\n",
      "train loss:0.7793595397265317\n",
      "train loss:0.8707760651083716\n",
      "train loss:0.8928442311148964\n",
      "train loss:0.8782641977929068\n",
      "train loss:0.9513609699326429\n",
      "train loss:0.9776769405332694\n",
      "train loss:0.8857104410029926\n",
      "train loss:1.1217191175939676\n",
      "train loss:0.9823761459516603\n",
      "train loss:0.942174076007414\n",
      "train loss:1.0050283341443333\n",
      "train loss:0.8582302074704543\n",
      "train loss:0.9018225001689325\n",
      "train loss:0.9199788861014305\n",
      "train loss:0.9510737186460573\n",
      "train loss:0.9134238439793242\n",
      "train loss:1.0318860993077006\n",
      "train loss:0.9125032550028415\n",
      "train loss:0.9526762592215953\n",
      "train loss:0.960963668328645\n",
      "train loss:0.7848766612515482\n",
      "train loss:0.9273909816056448\n",
      "train loss:0.9221293473811482\n",
      "train loss:1.0241312780171679\n",
      "train loss:0.898780119030574\n",
      "train loss:0.9951464253223462\n",
      "train loss:0.9905198834458392\n",
      "train loss:0.9659940473007823\n",
      "train loss:1.0239985433907117\n",
      "train loss:0.9914734499023506\n",
      "train loss:0.9855686543281934\n",
      "train loss:0.910814665373969\n",
      "train loss:0.8673642573025981\n",
      "train loss:0.8962761538354578\n",
      "train loss:0.9428797745850559\n",
      "train loss:0.8798955054286347\n",
      "train loss:1.1479035740666084\n",
      "train loss:1.0863983192680033\n",
      "train loss:0.7995844888224337\n",
      "train loss:0.9464634214628744\n",
      "train loss:0.829580515318623\n",
      "train loss:1.0905069011827542\n",
      "train loss:0.7478134449776858\n",
      "train loss:0.8937094888085696\n",
      "train loss:1.0153812613090911\n",
      "train loss:1.0318260622213782\n",
      "train loss:0.899933884990971\n",
      "train loss:1.0681843220962102\n",
      "train loss:0.9034594206291235\n",
      "train loss:0.93475493294596\n",
      "train loss:0.9484223160194901\n",
      "train loss:0.9692430059748871\n",
      "train loss:1.002147792171038\n",
      "train loss:0.9800737326840308\n",
      "train loss:0.9100021327704302\n",
      "train loss:0.9775092971290679\n",
      "train loss:0.8937971186466175\n",
      "train loss:1.0650916337250185\n",
      "train loss:0.9439416939847767\n",
      "train loss:0.9692849886818762\n",
      "train loss:0.7416295811798669\n",
      "train loss:1.1495060660613134\n",
      "train loss:0.8896834556978053\n",
      "train loss:1.0170017253761658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0676773021261767\n",
      "train loss:0.7716232719713976\n",
      "train loss:0.7369502402865551\n",
      "train loss:0.9536026243372538\n",
      "train loss:0.8230717369076954\n",
      "train loss:0.8706397196898026\n",
      "train loss:0.8745247116630515\n",
      "train loss:0.9032660781610983\n",
      "train loss:1.0401792873154203\n",
      "train loss:1.0082597021101511\n",
      "train loss:0.8330148136179111\n",
      "train loss:0.748839234628373\n",
      "train loss:1.0019860663729951\n",
      "train loss:0.9317180514753101\n",
      "train loss:0.9929646540286103\n",
      "train loss:0.9903778094661807\n",
      "train loss:1.0647818836421714\n",
      "train loss:0.9313226323490333\n",
      "train loss:0.8678721667608\n",
      "train loss:1.0387947645647009\n",
      "train loss:0.8895805829575404\n",
      "train loss:0.9069557297306554\n",
      "train loss:1.0577074172601568\n",
      "train loss:0.9963143061181227\n",
      "train loss:0.9945353692956392\n",
      "train loss:0.8590395146590423\n",
      "train loss:0.9229276052344172\n",
      "train loss:0.8152254193649761\n",
      "train loss:0.8602359108065692\n",
      "train loss:0.8749490129359261\n",
      "train loss:0.990687705961002\n",
      "train loss:0.9937936389170453\n",
      "train loss:0.9297658460272222\n",
      "train loss:1.083414812619086\n",
      "train loss:0.7579002828283302\n",
      "train loss:0.9345065410660669\n",
      "train loss:0.9555222209296101\n",
      "train loss:0.9989522719227903\n",
      "train loss:0.9029037664872319\n",
      "train loss:0.8978398377993723\n",
      "train loss:0.9882175873864008\n",
      "train loss:0.9195373425835272\n",
      "train loss:0.8878433629627845\n",
      "train loss:1.0819717872753096\n",
      "train loss:0.9221704225935814\n",
      "train loss:1.0735842639683526\n",
      "train loss:0.8214754942146704\n",
      "train loss:0.8927893238310135\n",
      "train loss:1.080955311705123\n",
      "train loss:0.9239293526301016\n",
      "train loss:0.8757848075671485\n",
      "train loss:0.8649746745544327\n",
      "train loss:0.8752642721044791\n",
      "train loss:0.8332629841529027\n",
      "train loss:0.9272640698760507\n",
      "train loss:1.0002472811294987\n",
      "train loss:0.9247118314764755\n",
      "train loss:0.8989802175595046\n",
      "train loss:0.8280867794833523\n",
      "train loss:0.8897986097447594\n",
      "train loss:1.0153260578529073\n",
      "train loss:0.8705357756584701\n",
      "train loss:0.8226725131388015\n",
      "train loss:0.8414889329197721\n",
      "train loss:1.0078194125655036\n",
      "train loss:1.0495348637438768\n",
      "train loss:0.979398491855469\n",
      "train loss:0.8765005839463249\n",
      "train loss:0.7701876773027942\n",
      "train loss:0.8075854593245417\n",
      "train loss:0.9297532523200751\n",
      "train loss:0.8399576430929143\n",
      "train loss:0.9405639930381091\n",
      "train loss:0.8923887888683908\n",
      "train loss:0.7666842882864867\n",
      "train loss:0.9731806108787271\n",
      "train loss:0.9577525481307319\n",
      "train loss:1.0711889245897772\n",
      "train loss:0.8638215869169481\n",
      "train loss:0.7250574806995058\n",
      "train loss:0.9214902951941533\n",
      "train loss:0.9512544903743234\n",
      "train loss:0.9226656560034076\n",
      "train loss:0.7489153001745241\n",
      "train loss:0.9150661378754136\n",
      "train loss:0.9350703658769757\n",
      "train loss:0.8630528126493805\n",
      "train loss:1.2113320639742668\n",
      "train loss:0.9474129437015206\n",
      "train loss:1.0348912502747136\n",
      "train loss:0.974794897277492\n",
      "train loss:1.0703873209388997\n",
      "train loss:1.0430471898092775\n",
      "train loss:0.9978564891116676\n",
      "train loss:0.8694653060772517\n",
      "train loss:1.0482657222937335\n",
      "train loss:0.9987397024115414\n",
      "train loss:1.0467083628248663\n",
      "train loss:0.9820659091682035\n",
      "train loss:0.9234108180914039\n",
      "train loss:1.1665410041233517\n",
      "train loss:0.9205417044939072\n",
      "train loss:1.045171743992884\n",
      "train loss:0.7965516442997519\n",
      "train loss:1.0536821050032825\n",
      "train loss:0.8086202621090244\n",
      "train loss:1.0039111992418623\n",
      "train loss:0.9103795754485712\n",
      "train loss:0.8990809394915287\n",
      "train loss:0.8717249230356946\n",
      "train loss:0.9060210981030626\n",
      "train loss:0.794026528766084\n",
      "train loss:0.7238171997385142\n",
      "train loss:0.9861606966638273\n",
      "train loss:0.9832015849618523\n",
      "train loss:0.9071729680941983\n",
      "train loss:0.9775113447563052\n",
      "train loss:1.0398787282156585\n",
      "train loss:0.926565730535122\n",
      "train loss:1.0488075950755538\n",
      "train loss:0.9502797342870721\n",
      "train loss:1.0030213552931306\n",
      "train loss:1.0293167589206849\n",
      "train loss:0.7922356618647802\n",
      "train loss:0.9076152343025419\n",
      "train loss:1.0478307136740614\n",
      "train loss:0.8674777738670688\n",
      "train loss:0.9801189756509876\n",
      "train loss:0.7764302648998774\n",
      "train loss:0.8242859659849056\n",
      "train loss:0.8204390256995908\n",
      "train loss:0.9719402468616933\n",
      "train loss:0.7942493404069931\n",
      "train loss:1.177205735512732\n",
      "train loss:0.8069349400264332\n",
      "train loss:0.9879359216639669\n",
      "train loss:0.9580862433100726\n",
      "train loss:0.9101865467421806\n",
      "train loss:0.863986962230907\n",
      "train loss:0.8888959622433668\n",
      "train loss:0.9395200199346532\n",
      "train loss:0.8362094468765872\n",
      "train loss:0.8962950311286058\n",
      "train loss:0.9280131955718726\n",
      "train loss:0.8892381134309738\n",
      "train loss:0.90960291723725\n",
      "train loss:0.8118266991221184\n",
      "train loss:1.0549133682376475\n",
      "train loss:0.8693540043419986\n",
      "train loss:0.9915508140672601\n",
      "train loss:0.7792216697044816\n",
      "train loss:0.8495542392206518\n",
      "train loss:0.9163489057392994\n",
      "train loss:0.9916926429841412\n",
      "train loss:0.9579273380316533\n",
      "train loss:0.8440041765276978\n",
      "train loss:0.8544856708488463\n",
      "train loss:0.9693774827962325\n",
      "train loss:0.896065451328666\n",
      "train loss:0.8926723192669921\n",
      "train loss:0.9396445124817139\n",
      "train loss:0.924243023996343\n",
      "train loss:0.9211719115708183\n",
      "train loss:0.8759698245933163\n",
      "train loss:0.9353438465256549\n",
      "train loss:1.0999234875931456\n",
      "train loss:0.7360056035624142\n",
      "train loss:0.9189170142598246\n",
      "train loss:0.9432582708949692\n",
      "train loss:1.116810904865887\n",
      "train loss:0.7836678180868332\n",
      "train loss:0.7988709780254711\n",
      "train loss:0.9220566500192269\n",
      "train loss:0.9003095859580206\n",
      "train loss:0.9969494695648784\n",
      "train loss:0.9006773410363887\n",
      "train loss:0.8112892007455856\n",
      "train loss:0.8739059048295248\n",
      "train loss:0.8972978427936951\n",
      "train loss:0.9507484526135316\n",
      "train loss:0.9977535737260707\n",
      "train loss:1.0032634841635248\n",
      "train loss:0.7293940567464331\n",
      "train loss:0.734346566794089\n",
      "train loss:0.846747021551013\n",
      "train loss:0.8277042680942295\n",
      "train loss:0.8422364253907126\n",
      "train loss:0.9241196258502221\n",
      "train loss:0.7923493282117837\n",
      "train loss:0.7824788925880037\n",
      "train loss:0.8059913528597701\n",
      "train loss:0.8251451655290957\n",
      "train loss:0.8528158137790761\n",
      "train loss:0.6917458953592877\n",
      "train loss:0.9193253015782322\n",
      "train loss:0.7915094731670554\n",
      "train loss:0.9950567651780433\n",
      "train loss:1.1084226322926094\n",
      "train loss:0.9761898552606\n",
      "train loss:0.7983937310250535\n",
      "train loss:0.8457487889471851\n",
      "train loss:0.8948908898675242\n",
      "train loss:0.8278775063590552\n",
      "train loss:0.9197316689786957\n",
      "train loss:0.6834040287728012\n",
      "train loss:0.8891521841038699\n",
      "train loss:0.8740445104743904\n",
      "train loss:0.9920835315022457\n",
      "train loss:0.9323138360542204\n",
      "train loss:0.9000166893111218\n",
      "train loss:1.0408614853434732\n",
      "train loss:0.8617683771622998\n",
      "train loss:0.9445714677803497\n",
      "train loss:0.7997219922556326\n",
      "train loss:0.7701043486051858\n",
      "train loss:0.7467460857308139\n",
      "train loss:0.9879302142923972\n",
      "train loss:0.941126162083154\n",
      "train loss:0.8513483519214645\n",
      "train loss:0.9118463556726226\n",
      "train loss:0.8095124356884876\n",
      "train loss:0.9336268565661001\n",
      "train loss:0.911843478615214\n",
      "train loss:1.096509269163693\n",
      "train loss:0.9244024304797052\n",
      "train loss:0.963461632560564\n",
      "train loss:0.9275322096020429\n",
      "train loss:0.7410389253746641\n",
      "train loss:0.9538168971432135\n",
      "train loss:0.9854564336040775\n",
      "train loss:0.8280112331584304\n",
      "train loss:0.8815451194607686\n",
      "train loss:1.007862212585146\n",
      "train loss:0.9965976182700237\n",
      "train loss:0.7875191442249541\n",
      "train loss:0.8014838607588324\n",
      "train loss:0.8472434505007884\n",
      "train loss:0.8183221558943266\n",
      "train loss:0.9451553324358567\n",
      "train loss:1.0632435357558818\n",
      "train loss:0.8140240019744361\n",
      "train loss:0.9805707406531708\n",
      "train loss:0.9605427410490236\n",
      "train loss:0.878431314121989\n",
      "train loss:0.8947356080283139\n",
      "train loss:0.9533931040899795\n",
      "train loss:0.8547727245297643\n",
      "train loss:1.0811326744328593\n",
      "train loss:0.7205053439321261\n",
      "train loss:0.8734433384207112\n",
      "train loss:0.8122973475355565\n",
      "train loss:0.9329159342940965\n",
      "train loss:0.844134147637876\n",
      "train loss:0.996430399832557\n",
      "train loss:0.9244802453456287\n",
      "train loss:0.9831955155175837\n",
      "train loss:0.788647197006912\n",
      "train loss:1.060792778459421\n",
      "train loss:0.9184945319986276\n",
      "train loss:0.8309989297495182\n",
      "train loss:0.9167425666984194\n",
      "train loss:0.9232022401275725\n",
      "train loss:0.88249808337327\n",
      "train loss:0.9158825294739735\n",
      "train loss:0.9267445797865947\n",
      "train loss:0.7026794192597474\n",
      "train loss:0.8772151737479332\n",
      "train loss:0.9614506954422223\n",
      "train loss:0.7451682417482082\n",
      "train loss:0.8754801574460034\n",
      "train loss:0.9784241956245281\n",
      "train loss:0.9358865200266854\n",
      "train loss:1.065076107215082\n",
      "train loss:0.9450255297197363\n",
      "train loss:0.964567012410114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9221275751854856\n",
      "train loss:0.9241882143990001\n",
      "train loss:0.8505383424488515\n",
      "train loss:0.9082448052609444\n",
      "train loss:0.7736958596910387\n",
      "train loss:0.9273956868425272\n",
      "train loss:1.1519412316602504\n",
      "train loss:0.9401456082657098\n",
      "train loss:1.055050713293707\n",
      "train loss:0.8042387100961891\n",
      "train loss:0.8768987851099813\n",
      "train loss:0.903370269847914\n",
      "train loss:1.1198759377280787\n",
      "train loss:0.8459257690665721\n",
      "train loss:0.9020797503024558\n",
      "train loss:0.9483897383690766\n",
      "train loss:0.746752107126145\n",
      "train loss:1.029838827187173\n",
      "train loss:0.9086616857892573\n",
      "train loss:0.7650995051216001\n",
      "train loss:0.9947548556768452\n",
      "train loss:0.8595681617507342\n",
      "train loss:0.94165653321185\n",
      "train loss:0.8923826828130327\n",
      "train loss:0.9482834874258299\n",
      "train loss:0.932171780548433\n",
      "train loss:0.8806582285660857\n",
      "train loss:0.9039980578953027\n",
      "train loss:1.080527730007511\n",
      "train loss:0.9391605664548761\n",
      "train loss:1.0870331407365015\n",
      "train loss:0.9521347613151389\n",
      "train loss:0.9377983535089688\n",
      "train loss:0.7292460032362924\n",
      "train loss:1.1153136729819537\n",
      "train loss:0.955937550502028\n",
      "train loss:0.7943654998788218\n",
      "train loss:0.972951881181517\n",
      "train loss:0.8576481557553827\n",
      "train loss:0.9009798289889921\n",
      "train loss:1.0441426714766644\n",
      "train loss:0.9918142048933833\n",
      "train loss:0.9337308777294397\n",
      "train loss:0.9350238261102745\n",
      "train loss:0.8299157840320831\n",
      "train loss:0.9152370368390927\n",
      "train loss:1.0365800686915412\n",
      "train loss:0.8634411003661626\n",
      "train loss:0.9460024573177891\n",
      "train loss:0.9477959341525617\n",
      "train loss:0.9807999395786783\n",
      "train loss:0.960733545259845\n",
      "train loss:1.1253623341135184\n",
      "train loss:0.7508619685105546\n",
      "train loss:0.8611740503154108\n",
      "train loss:0.9645638460670496\n",
      "train loss:0.910094580941222\n",
      "train loss:0.9614570050283003\n",
      "train loss:0.8045597049559623\n",
      "train loss:0.8069782029043059\n",
      "train loss:0.9683905509784557\n",
      "train loss:0.9143678430089838\n",
      "train loss:0.9106858667934784\n",
      "train loss:0.8544986262184164\n",
      "train loss:0.8958879453532029\n",
      "train loss:1.0279397800450187\n",
      "train loss:0.9994334291469406\n",
      "train loss:1.0080479160923435\n",
      "train loss:0.9950538386538474\n",
      "train loss:0.7917291865176982\n",
      "train loss:0.9091080774746939\n",
      "train loss:0.8747715995471778\n",
      "train loss:1.1232559177809465\n",
      "train loss:0.939092119355697\n",
      "train loss:0.9156635509080681\n",
      "train loss:0.8756996326471486\n",
      "train loss:0.9201343261322976\n",
      "train loss:0.9444834810881656\n",
      "train loss:1.1095064872054454\n",
      "train loss:0.9339610978426104\n",
      "train loss:0.8689452376570356\n",
      "train loss:1.1070223483791284\n",
      "train loss:1.0158240380016366\n",
      "train loss:0.8347374409753534\n",
      "train loss:0.9822605539361632\n",
      "train loss:0.8788724422828185\n",
      "train loss:0.9415618066019944\n",
      "train loss:0.856742726376901\n",
      "train loss:0.8087809709694423\n",
      "train loss:0.8205448689076715\n",
      "train loss:0.9844578902161447\n",
      "train loss:1.0035228549650657\n",
      "train loss:1.0289803257575605\n",
      "train loss:1.031321916997545\n",
      "train loss:0.8205517102327977\n",
      "train loss:0.8751567741605839\n",
      "train loss:0.888118788468316\n",
      "train loss:0.7286256280744975\n",
      "train loss:0.7280726023980018\n",
      "train loss:0.9855680844704219\n",
      "train loss:0.9630238997491337\n",
      "train loss:0.9445358953427605\n",
      "train loss:0.8894292915314171\n",
      "train loss:0.9664459497847533\n",
      "train loss:0.9409402686775316\n",
      "train loss:0.9278484592781452\n",
      "train loss:0.8002650501063774\n",
      "train loss:0.8678153834927421\n",
      "train loss:1.0855438091656415\n",
      "train loss:0.9686214548783236\n",
      "train loss:0.9521795806584497\n",
      "train loss:0.9290570278974493\n",
      "train loss:0.8690968275822926\n",
      "train loss:0.9411106255629516\n",
      "train loss:0.9741542233394884\n",
      "train loss:1.022030128971566\n",
      "train loss:0.8877683731008145\n",
      "train loss:0.7721299443323442\n",
      "train loss:0.9789378773362913\n",
      "train loss:0.8088761150292406\n",
      "train loss:1.0429246413846378\n",
      "train loss:0.9791486557444476\n",
      "train loss:0.777170580441706\n",
      "train loss:1.097242089930034\n",
      "train loss:0.9298413443982444\n",
      "train loss:0.9728870738255889\n",
      "train loss:0.8185919020001683\n",
      "train loss:0.8656146631219189\n",
      "train loss:0.9392982402237382\n",
      "train loss:0.8686652961803936\n",
      "train loss:0.8096533697308211\n",
      "train loss:0.8869952696330249\n",
      "train loss:0.8810448984051844\n",
      "train loss:0.9535430965171505\n",
      "train loss:0.9956180760727861\n",
      "train loss:0.9190206589762042\n",
      "train loss:0.7645088086454499\n",
      "train loss:0.942955877906806\n",
      "train loss:0.8888528029974836\n",
      "train loss:0.949183243082263\n",
      "train loss:0.938417667892137\n",
      "train loss:0.8126566270838629\n",
      "train loss:0.9041025435577877\n",
      "train loss:0.9541097997675108\n",
      "train loss:0.9244814027092285\n",
      "train loss:0.9587846263034191\n",
      "train loss:0.8559439377885342\n",
      "train loss:0.7507453407707814\n",
      "train loss:0.8386587575927877\n",
      "train loss:1.1407899850122762\n",
      "train loss:0.8646784716853536\n",
      "train loss:1.0455972849641404\n",
      "train loss:0.8495909569056478\n",
      "train loss:1.0429589276132125\n",
      "train loss:0.8550947098748267\n",
      "train loss:0.9437796549096228\n",
      "train loss:0.8319804298485671\n",
      "train loss:0.9739337773129276\n",
      "train loss:0.7001721794369823\n",
      "train loss:0.8826886426031351\n",
      "train loss:1.0231493610408309\n",
      "train loss:0.914503710518082\n",
      "train loss:0.9689264254298342\n",
      "train loss:0.8312405548328319\n",
      "train loss:0.9649841860403029\n",
      "train loss:1.002501368679055\n",
      "train loss:1.1061887822881162\n",
      "train loss:0.9780070215781804\n",
      "train loss:0.8318941009989477\n",
      "train loss:0.9518652697089592\n",
      "train loss:0.9558216547959634\n",
      "train loss:1.0231840896761717\n",
      "train loss:0.8356235325745112\n",
      "train loss:0.933351598783822\n",
      "train loss:0.9040322603018995\n",
      "train loss:1.1420388808512265\n",
      "train loss:0.9223673732695901\n",
      "train loss:0.9453955551621016\n",
      "train loss:1.072709560096105\n",
      "train loss:0.8927391221735047\n",
      "train loss:0.821214548257028\n",
      "train loss:1.054272118520973\n",
      "train loss:1.0216461816750977\n",
      "train loss:0.7625572256613046\n",
      "train loss:0.9839336936150783\n",
      "train loss:0.7273378670599218\n",
      "train loss:1.0985122883263212\n",
      "train loss:1.154563094170293\n",
      "train loss:0.8895949462257482\n",
      "train loss:0.9373615643412182\n",
      "train loss:1.0145902377482385\n",
      "train loss:0.8825973878219802\n",
      "train loss:1.0348095697361515\n",
      "train loss:0.9422287752386639\n",
      "train loss:0.902658566386865\n",
      "train loss:0.960604470630847\n",
      "train loss:0.9590935335477727\n",
      "train loss:0.8596995051266388\n",
      "train loss:1.1360822679670315\n",
      "train loss:0.872552736348132\n",
      "train loss:0.871509883966588\n",
      "train loss:0.8174614898622085\n",
      "train loss:0.7772364142262291\n",
      "train loss:0.9740576271677267\n",
      "train loss:0.995174399408161\n",
      "=== epoch:5, train acc:0.988, test acc:0.988 ===\n",
      "train loss:0.9284263854554504\n",
      "train loss:0.8399083320928814\n",
      "train loss:0.9457977562581688\n",
      "train loss:0.7945064461254036\n",
      "train loss:0.7831754392705309\n",
      "train loss:0.8093407584674693\n",
      "train loss:1.0028584687521434\n",
      "train loss:0.8421309491318687\n",
      "train loss:1.0007663838687946\n",
      "train loss:0.8800836684441637\n",
      "train loss:0.9143209989997781\n",
      "train loss:0.9945518731746605\n",
      "train loss:1.066426502371448\n",
      "train loss:0.9660730449592368\n",
      "train loss:0.8447892790744385\n",
      "train loss:0.8404979232897\n",
      "train loss:0.7908894003711153\n",
      "train loss:0.8647898129847233\n",
      "train loss:0.8084133074372652\n",
      "train loss:0.8970952653331403\n",
      "train loss:1.012994763718555\n",
      "train loss:0.849946990410018\n",
      "train loss:0.9745877144086385\n",
      "train loss:1.0135710093385137\n",
      "train loss:0.690567228963399\n",
      "train loss:1.100871873906239\n",
      "train loss:0.9561171425279811\n",
      "train loss:0.9947124665821981\n",
      "train loss:1.0477253378529339\n",
      "train loss:0.7520412652171966\n",
      "train loss:0.9726975553033524\n",
      "train loss:0.8663831306682909\n",
      "train loss:0.9144843804782772\n",
      "train loss:0.996933539105416\n",
      "train loss:0.8297012197410184\n",
      "train loss:1.050427671069172\n",
      "train loss:0.7848362524972033\n",
      "train loss:0.8789933306798967\n",
      "train loss:1.0044800703653036\n",
      "train loss:1.0136849231956855\n",
      "train loss:0.7784809721334613\n",
      "train loss:0.9172265559959285\n",
      "train loss:0.9855139918189729\n",
      "train loss:1.0235806244092918\n",
      "train loss:0.9583063645913191\n",
      "train loss:0.8420258843021238\n",
      "train loss:0.8834628098207556\n",
      "train loss:0.7370798991640073\n",
      "train loss:1.0082306233134763\n",
      "train loss:0.9572417242549469\n",
      "train loss:0.9554573890514096\n",
      "train loss:0.9436024684717433\n",
      "train loss:1.0412295066322235\n",
      "train loss:0.88223185853382\n",
      "train loss:0.8917734942569868\n",
      "train loss:0.8606961038028852\n",
      "train loss:0.9237016999834674\n",
      "train loss:0.9434960968295659\n",
      "train loss:0.7914762828277473\n",
      "train loss:0.8735281086234914\n",
      "train loss:0.8453555943926437\n",
      "train loss:0.8118613271963183\n",
      "train loss:0.7431902792276552\n",
      "train loss:0.9341008795049853\n",
      "train loss:0.9266684193332516\n",
      "train loss:1.0333443734831418\n",
      "train loss:0.8347751530146613\n",
      "train loss:0.7609443808727171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9138703595455893\n",
      "train loss:0.9033176276350787\n",
      "train loss:0.8296064568174377\n",
      "train loss:0.8446989971411841\n",
      "train loss:0.9653702331185702\n",
      "train loss:0.9039872185780043\n",
      "train loss:0.8806681887452678\n",
      "train loss:0.9103151586303079\n",
      "train loss:0.8982268532540675\n",
      "train loss:0.9462444283456773\n",
      "train loss:0.9332573428859382\n",
      "train loss:0.994020939594457\n",
      "train loss:0.9829937589288938\n",
      "train loss:0.7748164277025635\n",
      "train loss:0.832879063115822\n",
      "train loss:1.1508099880668559\n",
      "train loss:0.841081093410541\n",
      "train loss:0.8053243280403994\n",
      "train loss:0.8203942510660981\n",
      "train loss:0.7300562348622897\n",
      "train loss:0.8535532660203485\n",
      "train loss:0.9643225254592356\n",
      "train loss:0.9481763404087116\n",
      "train loss:0.9933402713891275\n",
      "train loss:1.103744266520789\n",
      "train loss:0.786123807504923\n",
      "train loss:1.0332689204912424\n",
      "train loss:0.8831528151852583\n",
      "train loss:0.9057451890051764\n",
      "train loss:1.0426272971989956\n",
      "train loss:0.9068831031537391\n",
      "train loss:0.8294343506455394\n",
      "train loss:1.0177081836936608\n",
      "train loss:0.8913108315998062\n",
      "train loss:0.9145621580010329\n",
      "train loss:1.0512786422935496\n",
      "train loss:0.8650719901142725\n",
      "train loss:0.9396075251913208\n",
      "train loss:0.926912227624728\n",
      "train loss:0.9350300553993405\n",
      "train loss:0.9057786920023174\n",
      "train loss:0.7792943759853925\n",
      "train loss:1.0749477992774403\n",
      "train loss:0.8199703651680238\n",
      "train loss:0.9090893355137095\n",
      "train loss:0.8835495996265726\n",
      "train loss:0.9557038113478638\n",
      "train loss:0.9876413184470048\n",
      "train loss:0.9431629193554314\n",
      "train loss:0.7568079148846804\n",
      "train loss:0.8617265356936546\n",
      "train loss:0.8916414876316253\n",
      "train loss:0.8202461825974313\n",
      "train loss:0.8817700916509067\n",
      "train loss:0.8190847316239261\n",
      "train loss:0.9186901099836403\n",
      "train loss:0.8629314727214027\n",
      "train loss:1.0210367752062053\n",
      "train loss:1.055498050184098\n",
      "train loss:0.889166473650398\n",
      "train loss:0.990394697293913\n",
      "train loss:0.7357270135441535\n",
      "train loss:0.883855695585875\n",
      "train loss:0.7917997481745604\n",
      "train loss:1.0520495543043986\n",
      "train loss:0.854718260164433\n",
      "train loss:0.8783568394931462\n",
      "train loss:0.8826628068694401\n",
      "train loss:0.8667314320266521\n",
      "train loss:0.9907884994131062\n",
      "train loss:0.8197192009360421\n",
      "train loss:0.9069530016406107\n",
      "train loss:0.9029919042018435\n",
      "train loss:0.8977393777535347\n",
      "train loss:0.8209239178888208\n",
      "train loss:1.0523061879219995\n",
      "train loss:0.9850149880730057\n",
      "train loss:0.8767160891702814\n",
      "train loss:0.8198461952900289\n",
      "train loss:0.9083837894620759\n",
      "train loss:0.9118187094814039\n",
      "train loss:0.9190218682069365\n",
      "train loss:1.044341752833991\n",
      "train loss:1.09543663036051\n",
      "train loss:0.9827153365904481\n",
      "train loss:1.0575655130588648\n",
      "train loss:1.0039775878235055\n",
      "train loss:0.9627925080467108\n",
      "train loss:0.9858137176563182\n",
      "train loss:0.9427254020618477\n",
      "train loss:0.798158473909649\n",
      "train loss:0.8972776188789302\n",
      "train loss:0.9580789677146145\n",
      "train loss:0.8739351568173558\n",
      "train loss:1.127236451973821\n",
      "train loss:0.7788222988746771\n",
      "train loss:0.7909025246134135\n",
      "train loss:0.7693718381297865\n",
      "train loss:0.9819470870509953\n",
      "train loss:0.814473167293564\n",
      "train loss:0.8365362813331594\n",
      "train loss:0.7967292317270922\n",
      "train loss:0.8808667911153938\n",
      "train loss:0.8734147052952342\n",
      "train loss:1.060285943865916\n",
      "train loss:0.9999978607676883\n",
      "train loss:0.9114640411821475\n",
      "train loss:0.8618176379133651\n",
      "train loss:0.9325346196847044\n",
      "train loss:0.9440004011879539\n",
      "train loss:0.9072833630515593\n",
      "train loss:1.0068204097088262\n",
      "train loss:0.7028454451926096\n",
      "train loss:0.8507300013694539\n",
      "train loss:1.1449751502171142\n",
      "train loss:0.9924364621924046\n",
      "train loss:1.0317573890531404\n",
      "train loss:0.9204517199952726\n",
      "train loss:0.933522009501041\n",
      "train loss:0.9439957226844312\n",
      "train loss:0.9281395323916685\n",
      "train loss:0.9310228587087228\n",
      "train loss:0.9578863369111934\n",
      "train loss:0.8519037132987289\n",
      "train loss:0.9867774298898984\n",
      "train loss:0.6496693346064109\n",
      "train loss:0.9051635994554118\n",
      "train loss:0.9531009544076968\n",
      "train loss:0.810574118873808\n",
      "train loss:1.0660021431725781\n",
      "train loss:0.9488562391935262\n",
      "train loss:0.9097826259280204\n",
      "train loss:0.8179165524453441\n",
      "train loss:0.8917661558192421\n",
      "train loss:0.9008395730933677\n",
      "train loss:0.9790479874090761\n",
      "train loss:0.838385855026798\n",
      "train loss:0.9596925468122686\n",
      "train loss:1.1044649552231967\n",
      "train loss:0.9421098018286372\n",
      "train loss:0.8916589755242188\n",
      "train loss:0.8870564775684976\n",
      "train loss:0.7533619443559956\n",
      "train loss:0.6963395002112062\n",
      "train loss:0.7655060109624177\n",
      "train loss:0.8657208436754632\n",
      "train loss:0.9883318193766495\n",
      "train loss:0.8519776194292453\n",
      "train loss:0.9546020007220096\n",
      "train loss:0.8795148612852646\n",
      "train loss:0.9501789648389299\n",
      "train loss:0.9135125900912917\n",
      "train loss:0.9010504414308644\n",
      "train loss:0.9144047746710919\n",
      "train loss:0.7428307064503575\n",
      "train loss:0.9154743796940525\n",
      "train loss:0.8942996036420972\n",
      "train loss:0.9495128065753474\n",
      "train loss:0.9699140383043676\n",
      "train loss:0.9829788306179307\n",
      "train loss:0.8134678640555143\n",
      "train loss:0.8586185278957471\n",
      "train loss:0.9059768753227603\n",
      "train loss:0.9028945150591683\n",
      "train loss:0.8179954891825335\n",
      "train loss:0.9141717798508562\n",
      "train loss:1.0769874385882605\n",
      "train loss:0.8324364766808514\n",
      "train loss:0.8636920706619887\n",
      "train loss:0.9198097064393803\n",
      "train loss:1.1050654767154027\n",
      "train loss:0.9540055238508012\n",
      "train loss:0.9122804230458434\n",
      "train loss:0.7508361393428378\n",
      "train loss:1.0979069323298718\n",
      "train loss:0.8931218076102767\n",
      "train loss:0.9308727036318225\n",
      "train loss:0.8924699938047226\n",
      "train loss:1.013052712789108\n",
      "train loss:0.7614680398577873\n",
      "train loss:0.9602668323034226\n",
      "train loss:1.0207340894277674\n",
      "train loss:0.8522215773680324\n",
      "train loss:0.940578648695476\n",
      "train loss:0.8633203872454651\n",
      "train loss:1.0512735531237325\n",
      "train loss:0.8240134775392957\n",
      "train loss:0.9413989851968608\n",
      "train loss:0.98466342298386\n",
      "train loss:0.904113047804595\n",
      "train loss:1.1266057388868354\n",
      "train loss:0.972888444410493\n",
      "train loss:0.8557931137360426\n",
      "train loss:0.8600420420785526\n",
      "train loss:0.7667512653242038\n",
      "train loss:1.0474371060574317\n",
      "train loss:1.0736627831289294\n",
      "train loss:0.8429286643144173\n",
      "train loss:0.9412348350147943\n",
      "train loss:0.9181829394282458\n",
      "train loss:0.8591929500733368\n",
      "train loss:1.0347233002856455\n",
      "train loss:1.077176006647707\n",
      "train loss:1.0098973794100734\n",
      "train loss:0.8584664910087167\n",
      "train loss:0.9691882816874126\n",
      "train loss:0.8926019209016313\n",
      "train loss:0.837032508738283\n",
      "train loss:0.9646498828801525\n",
      "train loss:1.0101862583251362\n",
      "train loss:0.8698035521899115\n",
      "train loss:0.8105009080805472\n",
      "train loss:0.9639028567511168\n",
      "train loss:0.8484252399166101\n",
      "train loss:1.0003655657981156\n",
      "train loss:0.8852008300777642\n",
      "train loss:0.9087005360974918\n",
      "train loss:0.8384949401393753\n",
      "train loss:0.729036377247844\n",
      "train loss:0.882848948336307\n",
      "train loss:1.075966891848431\n",
      "train loss:0.9064299724561761\n",
      "train loss:0.774321291541338\n",
      "train loss:1.0616827418509402\n",
      "train loss:0.9597713788336832\n",
      "train loss:0.8692285281927898\n",
      "train loss:0.8323755808162175\n",
      "train loss:0.972927169196271\n",
      "train loss:1.0136946347395104\n",
      "train loss:0.9226722641796633\n",
      "train loss:0.9810595337769008\n",
      "train loss:0.8806434995041181\n",
      "train loss:0.8389656749794056\n",
      "train loss:0.8179960776572777\n",
      "train loss:0.9837486897448235\n",
      "train loss:0.8416754205529965\n",
      "train loss:0.8734061164623895\n",
      "train loss:0.9015864996083228\n",
      "train loss:0.9219478853740272\n",
      "train loss:0.8050315140560355\n",
      "train loss:0.8489237146863198\n",
      "train loss:0.8641428116488028\n",
      "train loss:0.8392902177698969\n",
      "train loss:0.8923711658340651\n",
      "train loss:0.8814609900016435\n",
      "train loss:0.8085922576393365\n",
      "train loss:0.9256957778813625\n",
      "train loss:0.8673430251786065\n",
      "train loss:0.9404240864354181\n",
      "train loss:0.8136616206434263\n",
      "train loss:0.8674151921209017\n",
      "train loss:0.9629032248759581\n",
      "train loss:1.0009369833877522\n",
      "train loss:0.8434100571437472\n",
      "train loss:1.0252949486874718\n",
      "train loss:0.8068140580644878\n",
      "train loss:1.1182855496481778\n",
      "train loss:0.935632486387564\n",
      "train loss:1.1103719949666786\n",
      "train loss:0.8312905846146514\n",
      "train loss:0.786634875713105\n",
      "train loss:0.8137730694986304\n",
      "train loss:0.810791269890921\n",
      "train loss:0.9246101144587113\n",
      "train loss:0.8607028818701541\n",
      "train loss:0.858226147230463\n",
      "train loss:0.8992830079296711\n",
      "train loss:0.8219515162602842\n",
      "train loss:1.0699441686751765\n",
      "train loss:0.9892026307296726\n",
      "train loss:0.8296762616731066\n",
      "train loss:0.8125932234263848\n",
      "train loss:0.8355578943362032\n",
      "train loss:1.0903792869868199\n",
      "train loss:1.0241270629621275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9435702503482932\n",
      "train loss:0.8685005491397232\n",
      "train loss:0.8031967371933344\n",
      "train loss:0.8787500169912533\n",
      "train loss:1.163361495245293\n",
      "train loss:0.8860893671465024\n",
      "train loss:0.9804132272935858\n",
      "train loss:0.8985184769407634\n",
      "train loss:0.9518262684780895\n",
      "train loss:1.0736140539714434\n",
      "train loss:0.7466981358060361\n",
      "train loss:0.7746561870951552\n",
      "train loss:0.9644551186998213\n",
      "train loss:0.8840078363149451\n",
      "train loss:0.8388342737087582\n",
      "train loss:0.7314176135279143\n",
      "train loss:0.9237416346914665\n",
      "train loss:1.0376564635067262\n",
      "train loss:0.8774404875644152\n",
      "train loss:0.9693596372064651\n",
      "train loss:0.7638347026809074\n",
      "train loss:0.9778115134783125\n",
      "train loss:0.8196323143656098\n",
      "train loss:0.9260928876154945\n",
      "train loss:1.1097133701362565\n",
      "train loss:0.7884386606789126\n",
      "train loss:1.0067747073902578\n",
      "train loss:0.9622071164235239\n",
      "train loss:0.8584463161113821\n",
      "train loss:0.7517575991263449\n",
      "train loss:1.0243508326462503\n",
      "train loss:0.9790703709309304\n",
      "train loss:0.8228600108020578\n",
      "train loss:0.9049234741541053\n",
      "train loss:0.997933792920252\n",
      "train loss:0.8515789050087014\n",
      "train loss:0.880113351776338\n",
      "train loss:0.8451585293265653\n",
      "train loss:0.93286449516939\n",
      "train loss:0.8734388876686253\n",
      "train loss:0.8419883337388323\n",
      "train loss:0.8350948346627157\n",
      "train loss:0.81593367558429\n",
      "train loss:0.8115793842159558\n",
      "train loss:0.7780906891265659\n",
      "train loss:0.8741762575280704\n",
      "train loss:0.9451735063524527\n",
      "train loss:0.8836220482325126\n",
      "train loss:0.9554904710234088\n",
      "train loss:1.142016584844199\n",
      "train loss:0.9229580111099707\n",
      "train loss:0.7856019285626639\n",
      "train loss:0.8295712919147675\n",
      "train loss:1.0016550313430082\n",
      "train loss:0.9058250150512727\n",
      "train loss:0.8270108556215051\n",
      "train loss:0.8655939688206132\n",
      "train loss:0.8664765320041729\n",
      "train loss:0.9874437519985851\n",
      "train loss:0.8326520744018633\n",
      "train loss:0.9166173758217906\n",
      "train loss:1.0556744125609276\n",
      "train loss:0.8268372036457424\n",
      "train loss:0.7463527424946511\n",
      "train loss:0.8223327291123459\n",
      "train loss:0.951488975037667\n",
      "train loss:0.8743483978238724\n",
      "train loss:0.7833616786487572\n",
      "train loss:0.8755940158545543\n",
      "train loss:0.8988262218401347\n",
      "train loss:1.0677103780302566\n",
      "train loss:0.8037113403082592\n",
      "train loss:0.808434490671305\n",
      "train loss:0.7788310164313187\n",
      "train loss:0.9959988301307781\n",
      "train loss:1.2978689041654627\n",
      "train loss:0.9752115267653511\n",
      "train loss:1.021220777982008\n",
      "train loss:0.8260808739653264\n",
      "train loss:0.9457665527527687\n",
      "train loss:0.919280219848162\n",
      "train loss:1.0497311199045292\n",
      "train loss:0.9288400573872386\n",
      "train loss:0.9266411732003081\n",
      "train loss:0.9718536193985707\n",
      "train loss:0.9458982829688132\n",
      "train loss:0.9337655975234956\n",
      "train loss:0.7817127256942823\n",
      "train loss:1.0677124480345013\n",
      "train loss:0.9818808731140729\n",
      "train loss:1.0107403701979765\n",
      "train loss:0.9472327108783755\n",
      "train loss:0.975748847352977\n",
      "train loss:0.9236503932881555\n",
      "train loss:0.9936076037136625\n",
      "train loss:0.8494996506649697\n",
      "train loss:1.0156276541486515\n",
      "train loss:0.8325515375623127\n",
      "train loss:1.0146624572094425\n",
      "train loss:0.957429394689602\n",
      "train loss:0.895509563760956\n",
      "train loss:0.9384240799121168\n",
      "train loss:0.929605507019676\n",
      "train loss:0.870687796025506\n",
      "train loss:0.8993669969600631\n",
      "train loss:0.8537193079799033\n",
      "train loss:0.9100615882679446\n",
      "train loss:0.9970738868998096\n",
      "train loss:0.8352172954694969\n",
      "train loss:0.8723466903612368\n",
      "train loss:0.7837932818613812\n",
      "train loss:0.898114905000432\n",
      "train loss:1.0226405469647342\n",
      "train loss:0.8868427957647702\n",
      "train loss:1.0433088424836854\n",
      "train loss:1.0616277126937852\n",
      "train loss:1.0660919569014882\n",
      "train loss:0.9260109741266\n",
      "train loss:0.9970228592226548\n",
      "train loss:0.9832127691000773\n",
      "train loss:0.9085206847131679\n",
      "train loss:0.9098967713253227\n",
      "train loss:0.8104706316427313\n",
      "train loss:1.04367661715548\n",
      "train loss:0.9094248958776424\n",
      "train loss:0.9733925935405356\n",
      "train loss:0.8773775896493583\n",
      "train loss:0.9127126122465314\n",
      "train loss:0.9594485438663325\n",
      "train loss:0.9661249478998596\n",
      "train loss:0.8227330697908122\n",
      "train loss:0.8660954867299178\n",
      "train loss:1.0979126391310543\n",
      "train loss:0.8643118453597519\n",
      "train loss:0.8778908480125608\n",
      "train loss:1.0307861666062579\n",
      "train loss:0.9963841166067483\n",
      "train loss:0.9141274358562267\n",
      "train loss:0.7904576179541138\n",
      "train loss:0.9495721864947142\n",
      "train loss:0.9246972644175387\n",
      "train loss:1.2184551625868258\n",
      "train loss:0.91926277483762\n",
      "train loss:0.8635272336435544\n",
      "train loss:0.8444007793692323\n",
      "train loss:0.9930610823699136\n",
      "train loss:0.9327625068425456\n",
      "train loss:0.9480327881309627\n",
      "train loss:0.9758327866872655\n",
      "train loss:0.8293517736917544\n",
      "train loss:0.8315122306225027\n",
      "train loss:0.8963554255442756\n",
      "train loss:0.9135557893964789\n",
      "train loss:0.8973787839631904\n",
      "train loss:0.8262762525158003\n",
      "train loss:0.9311045021713702\n",
      "train loss:1.014929499515271\n",
      "train loss:0.9520375874007793\n",
      "train loss:0.9981818997321841\n",
      "train loss:0.7654460591665257\n",
      "train loss:0.9000059680280711\n",
      "train loss:0.8868576972175604\n",
      "train loss:0.9774548669325017\n",
      "train loss:1.113654857571081\n",
      "train loss:0.8653400898958968\n",
      "train loss:1.0104463930275356\n",
      "train loss:1.049087019073258\n",
      "train loss:0.943143622259476\n",
      "train loss:0.9664437363042039\n",
      "train loss:0.8843849320878745\n",
      "train loss:0.9855957971853642\n",
      "train loss:0.7679161930627616\n",
      "train loss:1.08363842293069\n",
      "train loss:1.009970163250758\n",
      "train loss:1.0282296129530764\n",
      "train loss:0.9285337093677067\n",
      "train loss:0.8853882652483379\n",
      "train loss:1.0075730877545868\n",
      "train loss:0.8386639980921899\n",
      "train loss:0.7344235666467444\n",
      "train loss:0.783651951201353\n",
      "train loss:0.64535418515285\n",
      "train loss:0.8239106088410441\n",
      "train loss:0.9800929766651036\n",
      "train loss:0.8983506695868568\n",
      "train loss:0.7786879975865445\n",
      "train loss:0.6815103362368267\n",
      "train loss:0.9519482775691509\n",
      "train loss:0.7712191753302561\n",
      "train loss:0.7970366757725672\n",
      "train loss:0.8952422606780439\n",
      "train loss:0.8981277463737526\n",
      "train loss:1.0879963722734418\n",
      "train loss:0.8954868971763313\n",
      "train loss:1.0200522296360155\n",
      "train loss:1.0345574431399043\n",
      "train loss:0.8844784557694686\n",
      "train loss:0.9964815417704282\n",
      "train loss:0.8705513844157536\n",
      "train loss:0.8593319039238108\n",
      "train loss:1.017596624478891\n",
      "train loss:0.671434112993629\n",
      "train loss:1.0219913090940933\n",
      "train loss:0.88460899662757\n",
      "train loss:0.8971927593240272\n",
      "train loss:0.9359525407575142\n",
      "train loss:0.8295885956530823\n",
      "train loss:1.155287501078582\n",
      "train loss:0.8931950400667589\n",
      "train loss:0.9546441268681263\n",
      "train loss:1.0295134894464\n",
      "train loss:0.7869432047940521\n",
      "train loss:1.0905284013965701\n",
      "train loss:0.8707855763131834\n",
      "train loss:0.8494349292977248\n",
      "train loss:0.8115335009823642\n",
      "train loss:0.7862818105194559\n",
      "train loss:0.8098540700177936\n",
      "train loss:0.9045102132625271\n",
      "train loss:0.9789281442893131\n",
      "train loss:0.9713923512948343\n",
      "train loss:0.8319903969897757\n",
      "train loss:0.8652267868722315\n",
      "train loss:0.8964665910205225\n",
      "train loss:1.0861396357558406\n",
      "train loss:1.0187996554161858\n",
      "train loss:0.8954994685901919\n",
      "train loss:0.884127951892073\n",
      "train loss:1.0248803305272534\n",
      "train loss:0.7313767497461341\n",
      "train loss:0.9878213114546418\n",
      "train loss:0.8259240163757073\n",
      "train loss:1.1017633209542017\n",
      "train loss:0.9051440636860869\n",
      "train loss:0.6660971327548717\n",
      "train loss:0.968225949358267\n",
      "train loss:0.9457609383746024\n",
      "train loss:0.8832786871147377\n",
      "train loss:0.797864307114192\n",
      "train loss:0.8108930075382216\n",
      "train loss:1.0469467758503919\n",
      "train loss:0.9715667890464694\n",
      "train loss:1.0253215961254203\n",
      "train loss:0.9248093797341879\n",
      "train loss:0.8113904083471987\n",
      "train loss:0.9177809838065778\n",
      "train loss:0.8296356676831682\n",
      "train loss:0.9914766811569542\n",
      "train loss:0.7731168812259511\n",
      "train loss:0.9426748883705046\n",
      "train loss:1.0398462200635425\n",
      "train loss:0.9208045442229803\n",
      "train loss:1.058430941560614\n",
      "train loss:0.9236897093627454\n",
      "train loss:0.8218603192496076\n",
      "train loss:0.8150103244569405\n",
      "train loss:0.862237334915599\n",
      "=== epoch:6, train acc:0.995, test acc:0.985 ===\n",
      "train loss:0.8865599636475247\n",
      "train loss:0.8801000703513838\n",
      "train loss:0.9685815353995001\n",
      "train loss:0.9118453884110803\n",
      "train loss:0.9264712526989146\n",
      "train loss:0.7334184691254293\n",
      "train loss:0.9310551367764347\n",
      "train loss:0.9777875778315209\n",
      "train loss:0.9060005755540762\n",
      "train loss:1.0754318471136481\n",
      "train loss:0.9569062817545979\n",
      "train loss:0.913161099784124\n",
      "train loss:0.9127923367637429\n",
      "train loss:0.8826582692039517\n",
      "train loss:0.8021446726437005\n",
      "train loss:0.7878694406544555\n",
      "train loss:0.991608613657232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0142954227889422\n",
      "train loss:0.6971299353236572\n",
      "train loss:1.0593041209146028\n",
      "train loss:0.8713232865525997\n",
      "train loss:0.8911020010007802\n",
      "train loss:0.91347082669535\n",
      "train loss:0.876454193677207\n",
      "train loss:0.9020843667052031\n",
      "train loss:0.8862534050166979\n",
      "train loss:0.9072166735864703\n",
      "train loss:0.9101421612259629\n",
      "train loss:0.942499170036274\n",
      "train loss:0.8288732468567295\n",
      "train loss:0.9198908438807443\n",
      "train loss:0.8943925056200938\n",
      "train loss:0.795641134525002\n",
      "train loss:0.6956641396270475\n",
      "train loss:0.8224057773681726\n",
      "train loss:1.0212239606290878\n",
      "train loss:0.8468221208085105\n",
      "train loss:0.874642914009018\n",
      "train loss:0.9739584361274889\n",
      "train loss:1.0484232466160257\n",
      "train loss:0.9583209268838191\n",
      "train loss:0.8694037862702284\n",
      "train loss:1.0064222539707757\n",
      "train loss:0.9766250978082479\n",
      "train loss:1.0987548897493395\n",
      "train loss:0.8749391837963786\n",
      "train loss:0.9989388361541656\n",
      "train loss:1.0318641841828908\n",
      "train loss:0.9912566852059419\n",
      "train loss:1.0361465698291739\n",
      "train loss:0.9625002311917205\n",
      "train loss:0.832221898075972\n",
      "train loss:0.9043585980202671\n",
      "train loss:0.854778118131145\n",
      "train loss:1.015281529716528\n",
      "train loss:0.8771809682938043\n",
      "train loss:0.851054629710446\n",
      "train loss:1.0485285302422889\n",
      "train loss:0.865591232648926\n",
      "train loss:0.7283300278085192\n",
      "train loss:0.9135523981865156\n",
      "train loss:0.8592192243251184\n",
      "train loss:0.8131441267451348\n",
      "train loss:0.9145939666294293\n",
      "train loss:0.9566334811973677\n",
      "train loss:0.8422712835880969\n",
      "train loss:0.9435392397866207\n",
      "train loss:1.0483618658610958\n",
      "train loss:0.9566555527700532\n",
      "train loss:0.9490650318920728\n",
      "train loss:0.9154262582499616\n",
      "train loss:1.1329681544595478\n",
      "train loss:0.9411539401308616\n",
      "train loss:0.8181857097071982\n",
      "train loss:1.0252958999200261\n",
      "train loss:1.0113263677280733\n",
      "train loss:0.9661912409511835\n",
      "train loss:0.9931607615316328\n",
      "train loss:0.939422800486018\n",
      "train loss:0.917760777064361\n",
      "train loss:0.7712495931676342\n",
      "train loss:0.8575322623427131\n",
      "train loss:1.0006861745720432\n",
      "train loss:0.8626002605951374\n",
      "train loss:0.9654818665996191\n",
      "train loss:0.776384024001565\n",
      "train loss:0.7868523875613477\n",
      "train loss:0.8853104271921837\n",
      "train loss:0.8878001648637263\n",
      "train loss:0.9011164312853239\n",
      "train loss:0.9885644626136382\n",
      "train loss:0.8568613495488097\n",
      "train loss:0.8665895292423326\n",
      "train loss:0.8668339327254487\n",
      "train loss:0.9233252956348433\n",
      "train loss:0.9423578432277675\n",
      "train loss:0.7577376868218961\n",
      "train loss:0.8468807158306791\n",
      "train loss:0.9588894637428536\n",
      "train loss:0.9536974421866694\n",
      "train loss:0.8988303439589598\n",
      "train loss:0.9273597376748746\n",
      "train loss:1.0168201611306882\n",
      "train loss:0.8500563286738498\n",
      "train loss:0.8147172497691564\n",
      "train loss:0.9698892323844964\n",
      "train loss:0.8946904493897833\n",
      "train loss:0.9541786924637059\n",
      "train loss:0.7499887812419469\n",
      "train loss:0.6974849342549619\n",
      "train loss:1.0973327501709913\n",
      "train loss:1.0230621045493846\n",
      "train loss:1.147816118355837\n",
      "train loss:1.0876774659031208\n",
      "train loss:0.8342089776491648\n",
      "train loss:0.7483810821509306\n",
      "train loss:0.9578189517871613\n",
      "train loss:0.99123601693169\n",
      "train loss:0.8069679109851593\n",
      "train loss:0.7042465538135667\n",
      "train loss:1.0399183289816427\n",
      "train loss:0.904740086811558\n",
      "train loss:0.8594800700607981\n",
      "train loss:0.7257598502597685\n",
      "train loss:0.8005496623209676\n",
      "train loss:0.8689970887279962\n",
      "train loss:0.9826265563868982\n",
      "train loss:0.8928844155873158\n",
      "train loss:0.8476006636545409\n",
      "train loss:0.9977282069612631\n",
      "train loss:0.8886102867961665\n",
      "train loss:1.011014720480691\n",
      "train loss:0.8803283676124083\n",
      "train loss:0.8728784482650976\n",
      "train loss:0.8886595857504632\n",
      "train loss:0.947911846653129\n",
      "train loss:0.9266921894287935\n",
      "train loss:0.8721657384917688\n",
      "train loss:0.9719916126450123\n",
      "train loss:1.0168887203188688\n",
      "train loss:0.9981404275309699\n",
      "train loss:0.9495697471722848\n",
      "train loss:0.9509840276822915\n",
      "train loss:0.9013020449899581\n",
      "train loss:0.8105795836690861\n",
      "train loss:0.9188146034110243\n",
      "train loss:1.091666046905582\n",
      "train loss:0.861980947369777\n",
      "train loss:0.8040260856115631\n",
      "train loss:0.892744565353797\n",
      "train loss:0.985093066374771\n",
      "train loss:0.8488801666493405\n",
      "train loss:0.9081000935582537\n",
      "train loss:0.9293722858965972\n",
      "train loss:1.0763746465477897\n",
      "train loss:0.9194480365941372\n",
      "train loss:0.9203769411030015\n",
      "train loss:0.9443354839086092\n",
      "train loss:0.7939314100524499\n",
      "train loss:0.9032810711898859\n",
      "train loss:0.862287218974543\n",
      "train loss:0.7915046876968873\n",
      "train loss:0.7382610076980636\n",
      "train loss:0.8564320903790869\n",
      "train loss:0.9171998450834223\n",
      "train loss:0.9297431308070014\n",
      "train loss:0.842224531003773\n",
      "train loss:0.8947959286079548\n",
      "train loss:0.8979482153914037\n",
      "train loss:0.8336410910437482\n",
      "train loss:0.878131922930456\n",
      "train loss:0.9905150946291215\n",
      "train loss:0.9012558695632756\n",
      "train loss:0.9523278605872096\n",
      "train loss:0.9104208841643683\n",
      "train loss:0.8702851589703432\n",
      "train loss:0.9315843910224559\n",
      "train loss:0.7559608396379217\n",
      "train loss:0.9893082526810189\n",
      "train loss:1.0092985521975313\n",
      "train loss:0.8391202722722639\n",
      "train loss:0.8422911532736562\n",
      "train loss:1.0492849834770457\n",
      "train loss:0.9265384661209146\n",
      "train loss:0.883181800176242\n",
      "train loss:0.7961763567343583\n",
      "train loss:0.9154612415127654\n",
      "train loss:0.8657648438316373\n",
      "train loss:0.8596819142396583\n",
      "train loss:0.8255856956925542\n",
      "train loss:0.9789607460936766\n",
      "train loss:0.9501321657014956\n",
      "train loss:0.8739225740064033\n",
      "train loss:0.9267847434159936\n",
      "train loss:0.8708629403256427\n",
      "train loss:0.9598431683473707\n",
      "train loss:1.0633060936572856\n",
      "train loss:1.1108154075378796\n",
      "train loss:0.8004420973935944\n",
      "train loss:0.7950457831780162\n",
      "train loss:0.8266143327854025\n",
      "train loss:0.8663479234762492\n",
      "train loss:0.996210158378124\n",
      "train loss:1.0185646998452857\n",
      "train loss:0.8692281485652648\n",
      "train loss:0.9175587968317747\n",
      "train loss:0.7544836639681327\n",
      "train loss:0.8768553606096012\n",
      "train loss:0.8851660863374579\n",
      "train loss:0.9446884617633203\n",
      "train loss:0.7152557234193321\n",
      "train loss:0.832403820070819\n",
      "train loss:0.9212086223242036\n",
      "train loss:0.8255634786220449\n",
      "train loss:0.9282125399294461\n",
      "train loss:1.00685650728299\n",
      "train loss:0.9307797303241077\n",
      "train loss:0.8751210126248083\n",
      "train loss:0.8255366541561382\n",
      "train loss:0.9392635435861818\n",
      "train loss:0.8912896274652813\n",
      "train loss:0.876986145984525\n",
      "train loss:0.786925310618165\n",
      "train loss:0.9946573331318105\n",
      "train loss:0.7882206676781555\n",
      "train loss:0.9440589342207769\n",
      "train loss:0.7881182314863522\n",
      "train loss:0.9521810005731248\n",
      "train loss:0.9118935617807066\n",
      "train loss:0.8334501115220821\n",
      "train loss:0.8034327893374857\n",
      "train loss:0.9693769957411363\n",
      "train loss:1.0194705028907043\n",
      "train loss:0.9173677333828452\n",
      "train loss:1.0659880161746764\n",
      "train loss:0.90779582730745\n",
      "train loss:0.8629603738830849\n",
      "train loss:1.062412380691834\n",
      "train loss:0.8281509005672656\n",
      "train loss:0.9541279541046882\n",
      "train loss:0.8679923488860589\n",
      "train loss:0.7812950763555675\n",
      "train loss:1.0017663336780667\n",
      "train loss:0.8919269059091232\n",
      "train loss:0.9188157268844032\n",
      "train loss:1.0022100132799838\n",
      "train loss:0.78390515816535\n",
      "train loss:0.8214657598588074\n",
      "train loss:1.0248297811691183\n",
      "train loss:0.8199030349918721\n",
      "train loss:1.003028007451783\n",
      "train loss:1.098898877003884\n",
      "train loss:0.8000382666777703\n",
      "train loss:0.9492389653325808\n",
      "train loss:0.9182027902342652\n",
      "train loss:1.023729710062402\n",
      "train loss:0.8916458928127149\n",
      "train loss:0.8898675628158744\n",
      "train loss:0.8896705771341962\n",
      "train loss:0.8539294974378429\n",
      "train loss:0.7708032045885084\n",
      "train loss:0.9883518479643741\n",
      "train loss:0.7915387936933892\n",
      "train loss:0.8445336884637707\n",
      "train loss:0.8611861596500059\n",
      "train loss:1.0586520072089065\n",
      "train loss:0.8975600857976098\n",
      "train loss:0.7338979182912884\n",
      "train loss:0.9000017934766389\n",
      "train loss:0.8708830114231154\n",
      "train loss:0.9453198172935037\n",
      "train loss:0.9641327746653638\n",
      "train loss:0.8810081755258885\n",
      "train loss:1.0429076860215463\n",
      "train loss:0.9441232767017301\n",
      "train loss:0.8787366604904876\n",
      "train loss:0.9959237794668927\n",
      "train loss:1.1224526352347046\n",
      "train loss:0.9959387363272867\n",
      "train loss:0.95783232291705\n",
      "train loss:1.0267235453004262\n",
      "train loss:0.7411078711379256\n",
      "train loss:0.8895079732539358\n",
      "train loss:0.9523269103515858\n",
      "train loss:0.839153480668887\n",
      "train loss:0.9514830734338833\n",
      "train loss:0.8626100708036855\n",
      "train loss:0.7637354048621375\n",
      "train loss:0.8674520665220199\n",
      "train loss:0.9024856614186882\n",
      "train loss:0.8736602535141804\n",
      "train loss:0.883432099365622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8861167906738229\n",
      "train loss:1.118998597294448\n",
      "train loss:0.8778354008481607\n",
      "train loss:0.8104802493160325\n",
      "train loss:0.9134158144655043\n",
      "train loss:0.9202340237844223\n",
      "train loss:1.0067670428154896\n",
      "train loss:0.8976672480186213\n",
      "train loss:0.9253091290361207\n",
      "train loss:0.8822334256920703\n",
      "train loss:0.9502300141962712\n",
      "train loss:1.0230994150644188\n",
      "train loss:0.8095537757170215\n",
      "train loss:1.0629119808649365\n",
      "train loss:0.8956647020288924\n",
      "train loss:1.0309406160173178\n",
      "train loss:0.9158411629512281\n",
      "train loss:1.0412795209197894\n",
      "train loss:0.705118089892995\n",
      "train loss:0.8546090880487064\n",
      "train loss:1.044529290463131\n",
      "train loss:0.8548526841580201\n",
      "train loss:0.8525061198690641\n",
      "train loss:0.9412762242447507\n",
      "train loss:0.9703077042600609\n",
      "train loss:0.9452734470408651\n",
      "train loss:0.9629785958819014\n",
      "train loss:1.0046692318624324\n",
      "train loss:0.8281536568741094\n",
      "train loss:1.0429348939155592\n",
      "train loss:0.9190095889881941\n",
      "train loss:0.7461910005041864\n",
      "train loss:1.0066624531169084\n",
      "train loss:0.9726462199476735\n",
      "train loss:0.8053356757672708\n",
      "train loss:0.8841291994831059\n",
      "train loss:0.8633738746840561\n",
      "train loss:0.8227871924878087\n",
      "train loss:0.9888095615613091\n",
      "train loss:1.1776920660467827\n",
      "train loss:1.0025467704672546\n",
      "train loss:0.9707935800934241\n",
      "train loss:0.9704152310465091\n",
      "train loss:1.0056179196865092\n",
      "train loss:0.8581446058536853\n",
      "train loss:0.7350472865379379\n",
      "train loss:0.9424312863005554\n",
      "train loss:0.8982201657710958\n",
      "train loss:0.9673504972844027\n",
      "train loss:0.8729087391110804\n",
      "train loss:1.053752893784482\n",
      "train loss:0.9260663740576157\n",
      "train loss:0.7744128982781067\n",
      "train loss:0.9260368020076178\n",
      "train loss:0.8935046254634935\n",
      "train loss:0.8759350244821336\n",
      "train loss:0.920337351178833\n",
      "train loss:0.8765279911738255\n",
      "train loss:0.8798730615469633\n",
      "train loss:0.8288326137077542\n",
      "train loss:0.8923532571577459\n",
      "train loss:0.8887919617009914\n",
      "train loss:0.8881903460811482\n",
      "train loss:0.9026905567158107\n",
      "train loss:0.9278079527079192\n",
      "train loss:0.9264027352389229\n",
      "train loss:0.9382724229639381\n",
      "train loss:0.8797107606306617\n",
      "train loss:1.0373442370390002\n",
      "train loss:0.7400177516561126\n",
      "train loss:0.8150613866843055\n",
      "train loss:0.955860383509564\n",
      "train loss:0.9664834078027862\n",
      "train loss:0.9636981491762721\n",
      "train loss:0.986380063732687\n",
      "train loss:0.8310119681878413\n",
      "train loss:0.8077082720247755\n",
      "train loss:0.805626726624795\n",
      "train loss:0.9249508466730363\n",
      "train loss:0.8948065291231637\n",
      "train loss:0.9036834831150548\n",
      "train loss:0.8626594649012362\n",
      "train loss:0.7075785617831478\n",
      "train loss:0.7939504109176849\n",
      "train loss:0.8601717384279273\n",
      "train loss:0.9258192395851637\n",
      "train loss:0.8098234480214559\n",
      "train loss:0.9630986010116845\n",
      "train loss:0.73947569695174\n",
      "train loss:1.0255165968561726\n",
      "train loss:1.0030686464525205\n",
      "train loss:0.8102320601180452\n",
      "train loss:0.6616659966603464\n",
      "train loss:0.813723200361699\n",
      "train loss:0.7862713910273395\n",
      "train loss:0.778457622040987\n",
      "train loss:1.042929673948685\n",
      "train loss:0.941728741806023\n",
      "train loss:0.9236533740446364\n",
      "train loss:0.9237580006593347\n",
      "train loss:0.9695718969504263\n",
      "train loss:0.7785629942098438\n",
      "train loss:0.9568365587962596\n",
      "train loss:0.9153631496883419\n",
      "train loss:0.8002930137266365\n",
      "train loss:0.7781631417847416\n",
      "train loss:0.9948838617489189\n",
      "train loss:0.8854450517546084\n",
      "train loss:0.9810956051324132\n",
      "train loss:1.1471162633069374\n",
      "train loss:0.7144735003762058\n",
      "train loss:1.0707774357164634\n",
      "train loss:0.8012397339589553\n",
      "train loss:0.9444240487590398\n",
      "train loss:0.9546986242798873\n",
      "train loss:0.8509639369838824\n",
      "train loss:0.8246182475827527\n",
      "train loss:0.9170830894354672\n",
      "train loss:0.9055123170990678\n",
      "train loss:0.8154162431464654\n",
      "train loss:0.8672104134272105\n",
      "train loss:0.9100172593227654\n",
      "train loss:0.8532744796087305\n",
      "train loss:0.778696561255687\n",
      "train loss:0.8445849758914707\n",
      "train loss:0.8121319032570181\n",
      "train loss:0.821531102626219\n",
      "train loss:1.0131657449644833\n",
      "train loss:0.7785601987421131\n",
      "train loss:1.0579279823275405\n",
      "train loss:0.9810521346249346\n",
      "train loss:0.7831517590659023\n",
      "train loss:0.9829022245475895\n",
      "train loss:1.0180744980577678\n",
      "train loss:1.0753160158271025\n",
      "train loss:0.7858003023297332\n",
      "train loss:0.8920786538689548\n",
      "train loss:0.9927368524721212\n",
      "train loss:0.933549557507266\n",
      "train loss:1.0345972918753221\n",
      "train loss:0.9872066233750535\n",
      "train loss:1.1192326579509269\n",
      "train loss:0.963290384605493\n",
      "train loss:0.9258485468519428\n",
      "train loss:0.847511222906257\n",
      "train loss:0.9618386398216974\n",
      "train loss:0.8463590058912104\n",
      "train loss:0.8448233744291676\n",
      "train loss:0.9733096809377215\n",
      "train loss:0.8587978703160762\n",
      "train loss:0.8225026741352471\n",
      "train loss:0.9417205645898918\n",
      "train loss:0.8178981837150344\n",
      "train loss:0.6626465215825905\n",
      "train loss:0.8536569801358863\n",
      "train loss:1.0795614618841716\n",
      "train loss:0.960135647420571\n",
      "train loss:0.8331378505684199\n",
      "train loss:0.906373354959234\n",
      "train loss:1.0201902322470129\n",
      "train loss:0.909970545860785\n",
      "train loss:1.001947509203547\n",
      "train loss:0.7619189115967606\n",
      "train loss:0.8668418350028282\n",
      "train loss:0.751530149057476\n",
      "train loss:0.8463486258739923\n",
      "train loss:0.9417481647108947\n",
      "train loss:0.7040306356414578\n",
      "train loss:0.9477060942706821\n",
      "train loss:1.028148747280467\n",
      "train loss:0.7201148024565451\n",
      "train loss:0.9193788385046616\n",
      "train loss:0.9373251167835761\n",
      "train loss:1.0230990190780365\n",
      "train loss:0.9307557888317334\n",
      "train loss:0.7524338263133237\n",
      "train loss:0.7468865215610069\n",
      "train loss:1.0168996084302584\n",
      "train loss:0.9668725246280319\n",
      "train loss:1.0953169441934159\n",
      "train loss:1.0291900049030744\n",
      "train loss:0.8279588303905201\n",
      "train loss:0.8515654428414682\n",
      "train loss:0.771690484717364\n",
      "train loss:1.0908640172181512\n",
      "train loss:0.9002912805176007\n",
      "train loss:0.9497312062062063\n",
      "train loss:0.9525244610409567\n",
      "train loss:1.0138505005378513\n",
      "train loss:0.8930261857070664\n",
      "train loss:1.1242328854882517\n",
      "train loss:0.894962121059001\n",
      "train loss:0.9486886214281829\n",
      "train loss:1.0071862122013522\n",
      "train loss:0.8314560011665926\n",
      "train loss:0.8194456373342635\n",
      "train loss:0.8058216196408565\n",
      "train loss:0.837283816574259\n",
      "train loss:1.1220203786326886\n",
      "train loss:0.8297633813579087\n",
      "train loss:0.9836003894494261\n",
      "train loss:0.8752506036924942\n",
      "train loss:0.9891006919160712\n",
      "train loss:1.1477738577160768\n",
      "train loss:1.0069920734920736\n",
      "train loss:0.9707879123197057\n",
      "train loss:0.9963670043940727\n",
      "train loss:0.984040518153404\n",
      "train loss:0.9028002630684137\n",
      "train loss:0.9718141319049269\n",
      "train loss:0.8745232007245058\n",
      "train loss:0.94900192067378\n",
      "train loss:0.9642810798113417\n",
      "train loss:1.00063609497724\n",
      "train loss:0.7208638894941314\n",
      "train loss:0.7931093352615225\n",
      "train loss:0.8055149248049328\n",
      "train loss:0.8817882519777559\n",
      "train loss:0.9331552747156638\n",
      "train loss:0.8983352951729836\n",
      "train loss:0.9437566679194448\n",
      "train loss:0.8966307949592364\n",
      "train loss:0.8993285635409555\n",
      "train loss:0.846225597182734\n",
      "train loss:0.8969359445569438\n",
      "train loss:0.8148427867012518\n",
      "train loss:0.9758071152870816\n",
      "train loss:0.9986372678964649\n",
      "train loss:0.7700076901514633\n",
      "train loss:0.8778732844014833\n",
      "train loss:0.9003464930790345\n",
      "train loss:0.8544230865820542\n",
      "train loss:0.7391318731569082\n",
      "train loss:0.9153941142865116\n",
      "train loss:1.002928087609063\n",
      "train loss:0.8747669323131683\n",
      "train loss:1.0177755080482174\n",
      "train loss:0.8652085818202602\n",
      "train loss:0.887285843535579\n",
      "train loss:0.9051371211652804\n",
      "train loss:0.9370663631560494\n",
      "train loss:0.6951352344810556\n",
      "train loss:0.9887885121304358\n",
      "train loss:0.8574095652924886\n",
      "train loss:0.9725507405043773\n",
      "train loss:1.0327785314318438\n",
      "train loss:0.9747616334856641\n",
      "train loss:0.9622151073193933\n",
      "train loss:0.8745464083031519\n",
      "train loss:1.051071172291703\n",
      "train loss:0.8139591859852854\n",
      "train loss:0.9776481604176073\n",
      "train loss:1.0295342714822016\n",
      "train loss:1.0350595958290962\n",
      "train loss:0.8466066401369815\n",
      "train loss:0.9401888693939341\n",
      "train loss:0.8818147857107966\n",
      "train loss:0.9677036629344328\n",
      "train loss:0.9551708767311885\n",
      "train loss:0.9469522661643812\n",
      "train loss:0.9551976824151105\n",
      "train loss:0.8171549050273442\n",
      "train loss:0.9718865417433368\n",
      "train loss:0.8771654868760806\n",
      "train loss:1.021327533132961\n",
      "train loss:0.9301466866849846\n",
      "train loss:1.0427325462383559\n",
      "train loss:0.9853119396556019\n",
      "train loss:0.6950147025267615\n",
      "train loss:0.8414451461501261\n",
      "train loss:0.9560248424766165\n",
      "train loss:0.9416112960055614\n",
      "train loss:0.9580163304329389\n",
      "train loss:0.9766810696842417\n",
      "train loss:0.8444112528103489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9598158936783832\n",
      "train loss:0.8518702623392096\n",
      "train loss:0.8516297479099219\n",
      "train loss:0.9847163894144326\n",
      "train loss:0.9333042459708001\n",
      "train loss:1.0221750885490122\n",
      "train loss:0.8748914473853624\n",
      "train loss:0.8911785248897341\n",
      "train loss:0.9499697233420283\n",
      "train loss:0.8699970272025028\n",
      "train loss:0.9865148984135866\n",
      "train loss:0.9701753868071505\n",
      "train loss:0.7963024994052299\n",
      "train loss:0.9685140053109172\n",
      "train loss:0.7776110208665701\n",
      "train loss:0.9657699080581321\n",
      "train loss:0.9956134114176878\n",
      "train loss:0.6979715880771107\n",
      "train loss:0.9753407735296713\n",
      "train loss:0.8634882542704954\n",
      "train loss:0.9212544132138006\n",
      "train loss:0.862263461045996\n",
      "train loss:0.8418158640556841\n",
      "train loss:0.8968592395061071\n",
      "train loss:0.7289899101084752\n",
      "train loss:0.9240928210828789\n",
      "train loss:0.8824617769253764\n",
      "train loss:0.8644390722153524\n",
      "train loss:0.8099411394166768\n",
      "train loss:0.8684218371598642\n",
      "train loss:0.9249963971032975\n",
      "train loss:0.8838016511094007\n",
      "train loss:0.9315230568665583\n",
      "=== epoch:7, train acc:0.992, test acc:0.982 ===\n",
      "train loss:0.9050651503757626\n",
      "train loss:0.8023846880546892\n",
      "train loss:0.8581756948591468\n",
      "train loss:0.8305104050515295\n",
      "train loss:0.9749048459435676\n",
      "train loss:0.8180768932383561\n",
      "train loss:0.9364742899899184\n",
      "train loss:0.9203955891973132\n",
      "train loss:0.8673459168663123\n",
      "train loss:0.8648370772798575\n",
      "train loss:0.8378658558021127\n",
      "train loss:0.9092545935471696\n",
      "train loss:0.8350790954548358\n",
      "train loss:1.0225762254530981\n",
      "train loss:1.0634129161375778\n",
      "train loss:1.0140129890880478\n",
      "train loss:0.9058173690054154\n",
      "train loss:0.8381292091557342\n",
      "train loss:0.7365060804461535\n",
      "train loss:0.8814824434980373\n",
      "train loss:0.8673540232239293\n",
      "train loss:0.8592616578154852\n",
      "train loss:0.9044393101485568\n",
      "train loss:0.8248182866718063\n",
      "train loss:0.9627268971474904\n",
      "train loss:0.8933769462643493\n",
      "train loss:0.8861042857585686\n",
      "train loss:0.7985040454532358\n",
      "train loss:0.8010200177657165\n",
      "train loss:1.0232576855647142\n",
      "train loss:0.8483045897953347\n",
      "train loss:0.8862699905898919\n",
      "train loss:0.827152880080285\n",
      "train loss:0.958155007352291\n",
      "train loss:0.9700075419919533\n",
      "train loss:0.8041619447141456\n",
      "train loss:0.7867133048839218\n",
      "train loss:0.9548658423468264\n",
      "train loss:1.0479590651619912\n",
      "train loss:0.8790732526567555\n",
      "train loss:0.7941494884981443\n",
      "train loss:0.8827604549659062\n",
      "train loss:0.852668294809172\n",
      "train loss:0.855488082682256\n",
      "train loss:0.9655525389991483\n",
      "train loss:0.8676910262869041\n",
      "train loss:0.8946029875968765\n",
      "train loss:1.057543742967146\n",
      "train loss:0.8215914744827991\n",
      "train loss:1.0464078018221379\n",
      "train loss:0.9894487014707157\n",
      "train loss:0.9550513204111365\n",
      "train loss:0.7784980509275928\n",
      "train loss:0.8309558329278119\n",
      "train loss:1.0492953355984034\n",
      "train loss:0.9363919535194687\n",
      "train loss:0.9242988207285481\n",
      "train loss:0.8970093358667427\n",
      "train loss:0.876633799857758\n",
      "train loss:1.0752333176418312\n",
      "train loss:0.9175043145454578\n",
      "train loss:0.7956325960383144\n",
      "train loss:1.1195690106164442\n",
      "train loss:0.8599512409186555\n",
      "train loss:1.0206075792274072\n",
      "train loss:0.8516320372150759\n",
      "train loss:0.870991525501021\n",
      "train loss:0.8639430799024851\n",
      "train loss:0.9480547670375004\n",
      "train loss:1.0059379498988457\n",
      "train loss:0.946361993931718\n",
      "train loss:0.8431000608537353\n",
      "train loss:0.9177803945365632\n",
      "train loss:0.916199947590702\n",
      "train loss:0.8134078777272221\n",
      "train loss:0.8120250367676993\n",
      "train loss:0.8219206563146679\n",
      "train loss:0.8543714592842467\n",
      "train loss:1.0428262481148007\n",
      "train loss:0.8020131790727247\n",
      "train loss:0.8450365591980425\n",
      "train loss:1.0787500488900372\n",
      "train loss:0.9887278384984444\n",
      "train loss:0.7411341196597862\n",
      "train loss:0.8449474296089049\n",
      "train loss:0.9265502145938711\n",
      "train loss:1.0443020997269914\n",
      "train loss:1.0362203528143812\n",
      "train loss:0.9923124906696315\n",
      "train loss:0.7884376035174704\n",
      "train loss:0.9484435182032365\n",
      "train loss:0.8372425364452033\n",
      "train loss:0.8936450850551916\n",
      "train loss:0.8504038010940382\n",
      "train loss:0.8899276351929883\n",
      "train loss:0.8369324054477812\n",
      "train loss:0.8937662263646451\n",
      "train loss:0.8397370648212313\n",
      "train loss:0.9326225662458024\n",
      "train loss:0.8945700332206225\n",
      "train loss:0.9044538237396813\n",
      "train loss:0.8947495463553697\n",
      "train loss:0.9659559518771949\n",
      "train loss:0.9271004132075817\n",
      "train loss:0.8499323153067112\n",
      "train loss:0.908174386406065\n",
      "train loss:0.8157677753579874\n",
      "train loss:0.9586119100758219\n",
      "train loss:0.8524328352209117\n",
      "train loss:0.8960307598705\n",
      "train loss:0.7987039706526882\n",
      "train loss:0.8379941056834364\n",
      "train loss:0.9044504708857241\n",
      "train loss:0.8178799324210477\n",
      "train loss:1.0474437793226907\n",
      "train loss:0.7264682278609679\n",
      "train loss:0.8873877735225872\n",
      "train loss:1.0342583582735607\n",
      "train loss:0.7974298380552861\n",
      "train loss:1.0650115104122282\n",
      "train loss:0.8838204762408128\n",
      "train loss:0.8146002719176312\n",
      "train loss:1.0681026651153522\n",
      "train loss:0.9218541049680827\n",
      "train loss:0.8434200392416593\n",
      "train loss:1.1452482328401679\n",
      "train loss:1.007009118099707\n",
      "train loss:0.8544669574460996\n",
      "train loss:0.7608588621285451\n",
      "train loss:0.9185401725789947\n",
      "train loss:0.7369630074113886\n",
      "train loss:1.0822682031164796\n",
      "train loss:0.8851103753243521\n",
      "train loss:1.0236620127467924\n",
      "train loss:0.8454028534293652\n",
      "train loss:1.042168058591816\n",
      "train loss:0.7681083886275196\n",
      "train loss:0.8445464358258087\n",
      "train loss:0.8206822713985459\n",
      "train loss:0.9156976967236059\n",
      "train loss:0.9260292455627436\n",
      "train loss:0.876138205682131\n",
      "train loss:0.8171572471476538\n",
      "train loss:0.983877201354862\n",
      "train loss:0.7188571105916439\n",
      "train loss:0.9466806366111378\n",
      "train loss:0.9089323524852831\n",
      "train loss:0.832611103591602\n",
      "train loss:0.9228289253981548\n",
      "train loss:0.8568413714834827\n",
      "train loss:0.8921614014190175\n",
      "train loss:1.0231846507261348\n",
      "train loss:1.016738186807837\n",
      "train loss:1.041685413838044\n",
      "train loss:0.98502089412831\n",
      "train loss:0.8285773677799795\n",
      "train loss:0.9341606919682239\n",
      "train loss:0.8466702045654729\n",
      "train loss:0.9579681596677017\n",
      "train loss:0.9131315591169572\n",
      "train loss:0.8739720591672635\n",
      "train loss:1.0521124456637434\n",
      "train loss:1.0661392765291164\n",
      "train loss:0.8548556206648867\n",
      "train loss:1.0602412247204276\n",
      "train loss:0.8717045912899216\n",
      "train loss:0.7741966261774929\n",
      "train loss:0.9294276961694127\n",
      "train loss:0.9490164394742163\n",
      "train loss:1.116966789830014\n",
      "train loss:1.092782950872278\n",
      "train loss:0.8737918114281783\n",
      "train loss:0.7878115938571437\n",
      "train loss:0.8382392274733581\n",
      "train loss:0.8594629309375263\n",
      "train loss:0.8517831530292096\n",
      "train loss:0.9837361614494969\n",
      "train loss:0.6848483808394373\n",
      "train loss:0.7653674466152041\n",
      "train loss:0.8264827974747866\n",
      "train loss:0.9309546338459614\n",
      "train loss:0.7971072801256902\n",
      "train loss:0.6406225393741799\n",
      "train loss:0.9624753604596353\n",
      "train loss:0.976065032201241\n",
      "train loss:0.7721876000107912\n",
      "train loss:0.9340397380500929\n",
      "train loss:0.8185632703256286\n",
      "train loss:0.890478541279046\n",
      "train loss:0.9534283375598942\n",
      "train loss:0.9370386916461045\n",
      "train loss:0.8174190691493979\n",
      "train loss:0.9119960445040063\n",
      "train loss:0.942197078261533\n",
      "train loss:0.9255092392263669\n",
      "train loss:0.8381452694357658\n",
      "train loss:0.9455661459230236\n",
      "train loss:0.7728751770323576\n",
      "train loss:0.9808341973501264\n",
      "train loss:0.9845719883005206\n",
      "train loss:0.897696401807451\n",
      "train loss:1.0140940935341185\n",
      "train loss:0.8418794071057373\n",
      "train loss:0.7536010974225233\n",
      "train loss:0.9485118942859857\n",
      "train loss:0.7604101893790041\n",
      "train loss:0.8390153046785064\n",
      "train loss:0.8514340631137357\n",
      "train loss:0.739539782054498\n",
      "train loss:0.6810384967321227\n",
      "train loss:0.9886920719625509\n",
      "train loss:0.9266138555413821\n",
      "train loss:0.8499589828489365\n",
      "train loss:0.9701424729682719\n",
      "train loss:0.9034080566734505\n",
      "train loss:0.9389952921179927\n",
      "train loss:0.7241618030051786\n",
      "train loss:1.0478508888692537\n",
      "train loss:0.8809810020320172\n",
      "train loss:0.8710746338836757\n",
      "train loss:1.1194228466824978\n",
      "train loss:1.0187469519890429\n",
      "train loss:0.7444380827342758\n",
      "train loss:0.8849220659769909\n",
      "train loss:0.8380607203936365\n",
      "train loss:0.8687679269420072\n",
      "train loss:0.8793430558120994\n",
      "train loss:0.8625532501097396\n",
      "train loss:0.9474683135325496\n",
      "train loss:0.9598940491753548\n",
      "train loss:1.0355334989832807\n",
      "train loss:0.883600132899204\n",
      "train loss:0.87997536630467\n",
      "train loss:0.9218993420716664\n",
      "train loss:0.9087943081419394\n",
      "train loss:0.8714953655889179\n",
      "train loss:1.0646664034336735\n",
      "train loss:0.9522525780245512\n",
      "train loss:0.8706531939037001\n",
      "train loss:0.6828360308372214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7963398699411092\n",
      "train loss:0.911402592152072\n",
      "train loss:0.8870255025379405\n",
      "train loss:0.9430922001733595\n",
      "train loss:0.7481166703416773\n",
      "train loss:0.9227671039591692\n",
      "train loss:1.0546070527900262\n",
      "train loss:0.8498080362566327\n",
      "train loss:0.8521672970725875\n",
      "train loss:0.9456109803834264\n",
      "train loss:0.7743481354563617\n",
      "train loss:0.8398928355276428\n",
      "train loss:0.8807745089279535\n",
      "train loss:0.9351078590726946\n",
      "train loss:0.8375793986747104\n",
      "train loss:0.9088215327210841\n",
      "train loss:0.8273554530697328\n",
      "train loss:1.1212904327006559\n",
      "train loss:1.0240772838314292\n",
      "train loss:0.8309185428515048\n",
      "train loss:0.9852854110592311\n",
      "train loss:0.8902814430449111\n",
      "train loss:0.8370110796190667\n",
      "train loss:0.8261105061766914\n",
      "train loss:0.7249324353345046\n",
      "train loss:1.0097470027935311\n",
      "train loss:0.8528772277897158\n",
      "train loss:0.835921287848401\n",
      "train loss:0.9980139936828533\n",
      "train loss:1.0263481592683525\n",
      "train loss:0.9532987196157156\n",
      "train loss:0.9450422813787226\n",
      "train loss:1.0461015634960416\n",
      "train loss:0.8008767477815404\n",
      "train loss:0.8288638589191915\n",
      "train loss:0.8974075655483883\n",
      "train loss:0.6767571230534364\n",
      "train loss:0.8805145839118748\n",
      "train loss:0.7358088393324327\n",
      "train loss:0.8215989924894928\n",
      "train loss:0.876968671372586\n",
      "train loss:0.906906364702842\n",
      "train loss:0.9475378059452446\n",
      "train loss:0.8903609319374399\n",
      "train loss:0.8189761742695275\n",
      "train loss:0.8769776378742492\n",
      "train loss:0.8603139079776738\n",
      "train loss:0.8852080756532038\n",
      "train loss:0.9192788176507634\n",
      "train loss:0.8587687688772525\n",
      "train loss:0.7993545964883141\n",
      "train loss:0.8841737305731523\n",
      "train loss:1.1325906732453113\n",
      "train loss:0.8575078230363044\n",
      "train loss:0.8475063584465624\n",
      "train loss:0.9611417757871785\n",
      "train loss:0.940312262488526\n",
      "train loss:0.9584097756974336\n",
      "train loss:0.7547684676303622\n",
      "train loss:0.7988493873512827\n",
      "train loss:0.738198913493938\n",
      "train loss:0.8484337106933713\n",
      "train loss:1.0396536009586024\n",
      "train loss:1.0816466815419417\n",
      "train loss:0.9683774406928514\n",
      "train loss:0.9049649364710229\n",
      "train loss:0.8471184513846111\n",
      "train loss:0.9396269933781802\n",
      "train loss:0.9932658437282501\n",
      "train loss:0.8834123889563353\n",
      "train loss:0.849213152811223\n",
      "train loss:0.9009815813385121\n",
      "train loss:0.9682932149573945\n",
      "train loss:0.8474504322033822\n",
      "train loss:0.883507669078434\n",
      "train loss:0.7296648002755874\n",
      "train loss:0.8532647574734061\n",
      "train loss:1.0308823114547727\n",
      "train loss:1.0124206775087083\n",
      "train loss:0.888840033009405\n",
      "train loss:0.5947559659713971\n",
      "train loss:0.7919767915968535\n",
      "train loss:0.7926242587243238\n",
      "train loss:0.7844316742318498\n",
      "train loss:0.7152597957772657\n",
      "train loss:0.9050643296531382\n",
      "train loss:0.8843176784154693\n",
      "train loss:1.078142439526135\n",
      "train loss:1.0047306399786626\n",
      "train loss:0.7353552240855349\n",
      "train loss:0.8337337827783499\n",
      "train loss:0.7333551736396429\n",
      "train loss:0.7887285176030164\n",
      "train loss:0.9833308547078705\n",
      "train loss:0.8092559275736615\n",
      "train loss:0.9119587631046656\n",
      "train loss:1.0604008138444951\n",
      "train loss:0.7960731157222318\n",
      "train loss:0.8982001590247077\n",
      "train loss:0.7032441500561996\n",
      "train loss:1.070649803103088\n",
      "train loss:0.8708384535880342\n",
      "train loss:0.8257568167519131\n",
      "train loss:0.8321790650625479\n",
      "train loss:0.711470895149872\n",
      "train loss:0.8819507982574121\n",
      "train loss:0.8107397377038736\n",
      "train loss:1.0133828880891462\n",
      "train loss:0.8680677552905189\n",
      "train loss:0.8801900753829339\n",
      "train loss:0.8670714867675207\n",
      "train loss:0.7710043246447041\n",
      "train loss:0.831068230105511\n",
      "train loss:1.0279510248285395\n",
      "train loss:0.8807671580754564\n",
      "train loss:0.8132381872042191\n",
      "train loss:1.104148089031155\n",
      "train loss:0.8601971104091216\n",
      "train loss:0.9267314314085607\n",
      "train loss:0.7609636366360795\n",
      "train loss:0.9730808319584079\n",
      "train loss:0.6939583441211173\n",
      "train loss:0.8574521463907039\n",
      "train loss:0.9891901850060908\n",
      "train loss:0.8829011308242304\n",
      "train loss:0.968462352264293\n",
      "train loss:0.834648098701032\n",
      "train loss:0.7838770144479986\n",
      "train loss:0.7703565912814857\n",
      "train loss:0.7379568360444771\n",
      "train loss:0.8995380573169467\n",
      "train loss:0.8785923671924016\n",
      "train loss:0.8568371659310202\n",
      "train loss:0.8000089124300201\n",
      "train loss:0.8099803908729035\n",
      "train loss:0.9419445543182681\n",
      "train loss:0.8218669065168271\n",
      "train loss:0.8700385309223333\n",
      "train loss:0.7162937212676477\n",
      "train loss:0.8112893069901327\n",
      "train loss:0.9674535723933342\n",
      "train loss:0.9577216783842843\n",
      "train loss:1.0337440859745741\n",
      "train loss:1.0397205021728277\n",
      "train loss:0.6880470015055906\n",
      "train loss:0.6693914087087639\n",
      "train loss:0.8372530145169474\n",
      "train loss:0.9408985406456327\n",
      "train loss:0.9184434558380644\n",
      "train loss:0.8540684484387054\n",
      "train loss:0.8686938158112867\n",
      "train loss:0.9886191556958457\n",
      "train loss:0.8094536750212472\n",
      "train loss:0.9619358470052127\n",
      "train loss:0.8343347592093201\n",
      "train loss:0.7701918789610069\n",
      "train loss:0.9764501553553976\n",
      "train loss:0.9549799884418833\n",
      "train loss:0.8382824520414199\n",
      "train loss:0.8023660004889909\n",
      "train loss:0.7965375965762039\n",
      "train loss:0.9659515032514631\n",
      "train loss:0.979214840349544\n",
      "train loss:0.9041971025610426\n",
      "train loss:0.7773992289023138\n",
      "train loss:0.9605333631173316\n",
      "train loss:0.9506870298888067\n",
      "train loss:0.8449311273240724\n",
      "train loss:1.0074742210246586\n",
      "train loss:1.0403612164165184\n",
      "train loss:0.9655798520990908\n",
      "train loss:0.775276191281242\n",
      "train loss:0.8450117880313252\n",
      "train loss:0.7566707167093284\n",
      "train loss:0.8798013158471405\n",
      "train loss:0.8773942027986168\n",
      "train loss:0.8723813751970954\n",
      "train loss:0.7783297374634579\n",
      "train loss:0.8410142010320334\n",
      "train loss:1.0264378022293597\n",
      "train loss:0.7668290258311968\n",
      "train loss:0.8661851905291058\n",
      "train loss:0.9368838824805283\n",
      "train loss:0.9209647734985222\n",
      "train loss:0.979431424943068\n",
      "train loss:0.8373745710346694\n",
      "train loss:0.9265540421448014\n",
      "train loss:0.6982715801984972\n",
      "train loss:0.6978591910595076\n",
      "train loss:0.7838598396198465\n",
      "train loss:0.892457739805306\n",
      "train loss:0.8354821126930219\n",
      "train loss:0.7729068865371269\n",
      "train loss:0.928285956267226\n",
      "train loss:0.9334602199460204\n",
      "train loss:0.9378425099435254\n",
      "train loss:0.9461195540224696\n",
      "train loss:0.8911188206223685\n",
      "train loss:1.003670893073674\n",
      "train loss:0.7399031197337803\n",
      "train loss:1.0236454147273852\n",
      "train loss:0.6629400282980952\n",
      "train loss:0.7957147127901759\n",
      "train loss:0.960060635888436\n",
      "train loss:0.9938464935136971\n",
      "train loss:0.8624215676687689\n",
      "train loss:1.0052730664743166\n",
      "train loss:0.8667943246072802\n",
      "train loss:0.8385510090774683\n",
      "train loss:0.7754181057782595\n",
      "train loss:0.9463457851412493\n",
      "train loss:1.0114277821409225\n",
      "train loss:0.8094643451849894\n",
      "train loss:0.903032854764318\n",
      "train loss:0.9589713205745645\n",
      "train loss:0.8099836433098794\n",
      "train loss:0.8677292509018444\n",
      "train loss:0.862512942433845\n",
      "train loss:0.920168138455593\n",
      "train loss:1.0314596752270346\n",
      "train loss:0.7588205692706121\n",
      "train loss:0.7480141607675592\n",
      "train loss:0.8351838564843967\n",
      "train loss:0.8672244242368983\n",
      "train loss:0.8304468281808411\n",
      "train loss:0.8237896041283499\n",
      "train loss:0.9067249272603983\n",
      "train loss:0.8811879971813472\n",
      "train loss:0.9499918844152389\n",
      "train loss:0.8943666187782503\n",
      "train loss:0.8250323268264569\n",
      "train loss:0.8606098731326182\n",
      "train loss:0.7929212166138966\n",
      "train loss:0.9599529220239418\n",
      "train loss:0.8490070773619199\n",
      "train loss:0.9298706541823055\n",
      "train loss:0.9670332221103363\n",
      "train loss:0.8653748685220701\n",
      "train loss:0.9736325683146287\n",
      "train loss:0.7766077790064869\n",
      "train loss:0.8262744406427784\n",
      "train loss:0.9805057618807135\n",
      "train loss:0.9265617558622395\n",
      "train loss:0.7619468312537974\n",
      "train loss:0.8195925285108746\n",
      "train loss:0.9613530171154347\n",
      "train loss:0.8873885287134489\n",
      "train loss:0.7725195890803758\n",
      "train loss:0.8132578464857803\n",
      "train loss:0.8660187743464219\n",
      "train loss:0.8139611240118073\n",
      "train loss:0.8386194163338382\n",
      "train loss:0.8432651066787252\n",
      "train loss:0.9546114583005189\n",
      "train loss:1.0785719013460784\n",
      "train loss:0.7902401690540298\n",
      "train loss:1.041486631330549\n",
      "train loss:0.7923044443410013\n",
      "train loss:0.9053058600899653\n",
      "train loss:0.979707794003167\n",
      "train loss:0.8096808192604157\n",
      "train loss:0.8696355029627266\n",
      "train loss:0.9875185278643575\n",
      "train loss:0.9367407111908672\n",
      "train loss:0.7916862269431978\n",
      "train loss:0.9988563871964683\n",
      "train loss:0.7747504152406336\n",
      "train loss:0.9331737940261177\n",
      "train loss:1.0302579052792673\n",
      "train loss:0.8762156665788976\n",
      "train loss:0.9348925356045393\n",
      "train loss:0.7398075582394416\n",
      "train loss:0.9918910241312748\n",
      "train loss:0.925082265952108\n",
      "train loss:0.7880140219074941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7338165882647822\n",
      "train loss:0.932713936040193\n",
      "train loss:0.7985394348743565\n",
      "train loss:0.8087818165147909\n",
      "train loss:1.0075146914896347\n",
      "train loss:1.0579912425277964\n",
      "train loss:0.9386081732721381\n",
      "train loss:0.7029213983922626\n",
      "train loss:0.9341390137273285\n",
      "train loss:0.9004317011546762\n",
      "train loss:0.7829960720248549\n",
      "train loss:1.0821641866001688\n",
      "train loss:0.7960541908297479\n",
      "train loss:0.6837438286592898\n",
      "train loss:1.1473843722586903\n",
      "train loss:0.8961549932408543\n",
      "train loss:0.6421131606652444\n",
      "train loss:0.729640281443944\n",
      "train loss:0.7374038565104207\n",
      "train loss:0.8808189968762088\n",
      "train loss:0.8218154175552206\n",
      "train loss:0.9209553402285944\n",
      "train loss:1.030914327476189\n",
      "train loss:0.8732767121788886\n",
      "train loss:0.7509115728913197\n",
      "train loss:1.102656102593084\n",
      "train loss:0.8692055252839692\n",
      "train loss:0.8999159848901673\n",
      "train loss:1.0188403879437344\n",
      "train loss:0.8303319450820272\n",
      "train loss:0.8918070551056239\n",
      "train loss:0.8533538131652311\n",
      "train loss:0.9420467501574799\n",
      "train loss:0.8369494516097278\n",
      "train loss:0.8956713976926541\n",
      "train loss:0.8873216277425083\n",
      "train loss:0.655098824133471\n",
      "train loss:0.8103814054389155\n",
      "train loss:0.865826234251682\n",
      "train loss:0.9399475345912351\n",
      "train loss:0.9124755783954954\n",
      "train loss:0.9045197938645909\n",
      "train loss:1.189446791602251\n",
      "train loss:0.9401966490269946\n",
      "train loss:0.7798014937227198\n",
      "train loss:0.9600117062530431\n",
      "train loss:0.7664402450102739\n",
      "train loss:0.9015059427366481\n",
      "train loss:1.0573660247384915\n",
      "train loss:0.9147446739504653\n",
      "train loss:0.7515844218325095\n",
      "train loss:1.0241130307910646\n",
      "train loss:0.8770178900432031\n",
      "train loss:0.9675006256756763\n",
      "train loss:0.7820224110540788\n",
      "train loss:0.9461496708131178\n",
      "train loss:0.8041407340723685\n",
      "train loss:0.7597089198567634\n",
      "train loss:0.943391410079743\n",
      "train loss:0.747951299331105\n",
      "train loss:0.8818158486934616\n",
      "train loss:0.8677024980557536\n",
      "train loss:0.8768548165460017\n",
      "train loss:0.8523590432254623\n",
      "train loss:0.8972126548147311\n",
      "train loss:0.9379984434255271\n",
      "train loss:1.0328298735110863\n",
      "train loss:0.927897898618844\n",
      "train loss:1.0733245370208246\n",
      "train loss:0.9002771431228028\n",
      "train loss:0.9775527147387711\n",
      "train loss:0.9097027580470767\n",
      "train loss:1.0363113960571169\n",
      "train loss:0.9575894204409571\n",
      "train loss:0.8707066191548338\n",
      "train loss:0.9782556155993847\n",
      "train loss:1.0409761531351338\n",
      "train loss:0.8864564365565422\n",
      "train loss:0.7781063404275983\n",
      "train loss:0.8408864581650403\n",
      "train loss:0.994484344095784\n",
      "train loss:0.9041375225789652\n",
      "train loss:0.9426479624469999\n",
      "train loss:0.8737814003661676\n",
      "train loss:0.953857743804997\n",
      "=== epoch:8, train acc:0.988, test acc:0.986 ===\n",
      "train loss:0.9800424604033019\n",
      "train loss:0.8976868071253391\n",
      "train loss:0.880446237960355\n",
      "train loss:0.9061813601121407\n",
      "train loss:0.9306763299005838\n",
      "train loss:0.8280587147066614\n",
      "train loss:0.8595445817010077\n",
      "train loss:0.9720599885249968\n",
      "train loss:0.8428583117807904\n",
      "train loss:0.9261790404276171\n",
      "train loss:0.8828432208837717\n",
      "train loss:0.8658361764443565\n",
      "train loss:0.9674421958453199\n",
      "train loss:0.8374732256047737\n",
      "train loss:0.8763947187371751\n",
      "train loss:0.9087477696543984\n",
      "train loss:0.9965801344023604\n",
      "train loss:0.7313657546503972\n",
      "train loss:1.1661434638363222\n",
      "train loss:0.9929709908973084\n",
      "train loss:1.0391259709871168\n",
      "train loss:0.9771940500376595\n",
      "train loss:0.8635922872718069\n",
      "train loss:0.8543379730202411\n",
      "train loss:0.8324993586261195\n",
      "train loss:0.8670559722760784\n",
      "train loss:0.9222843622551906\n",
      "train loss:0.9456774858991203\n",
      "train loss:0.8096368742876969\n",
      "train loss:0.8732062067159998\n",
      "train loss:0.7900796897906456\n",
      "train loss:1.044746678675623\n",
      "train loss:0.9558341004682862\n",
      "train loss:1.0164091136398132\n",
      "train loss:0.8781854199749372\n",
      "train loss:0.7682254003395971\n",
      "train loss:0.7506750810361342\n",
      "train loss:0.9671992507941521\n",
      "train loss:0.9871706283711119\n",
      "train loss:0.9412087035110772\n",
      "train loss:1.0187040604447188\n",
      "train loss:0.8486340727334846\n",
      "train loss:0.9209573208763525\n",
      "train loss:0.9615513915487146\n",
      "train loss:0.9133173161056669\n",
      "train loss:0.6847923424209926\n",
      "train loss:0.790283776837681\n",
      "train loss:1.0721124659720116\n",
      "train loss:0.9564235570143191\n",
      "train loss:0.8290719063855687\n",
      "train loss:0.8527617792784009\n",
      "train loss:0.9125530345515837\n",
      "train loss:0.8820493929391996\n",
      "train loss:0.8342496964877969\n",
      "train loss:0.8419337542564321\n",
      "train loss:1.0922679384065972\n",
      "train loss:0.9579782266892295\n",
      "train loss:0.9993830122803914\n",
      "train loss:0.909349968766723\n",
      "train loss:0.8476589636988026\n",
      "train loss:0.8182647532038101\n",
      "train loss:1.039599328959213\n",
      "train loss:0.7734428379082873\n",
      "train loss:0.8287717196364192\n",
      "train loss:0.815420446869799\n",
      "train loss:0.8625719817326244\n",
      "train loss:0.796662762637483\n",
      "train loss:1.0051873198035488\n",
      "train loss:0.9351451750482531\n",
      "train loss:0.7734921099954974\n",
      "train loss:1.0476939124015197\n",
      "train loss:0.9237721541708881\n",
      "train loss:0.773244801092866\n",
      "train loss:0.9086754274621391\n",
      "train loss:0.9358983580142399\n",
      "train loss:0.8440014162724034\n",
      "train loss:0.8722850952123248\n",
      "train loss:0.9230598583161854\n",
      "train loss:1.0047163706567461\n",
      "train loss:0.7758616040966798\n",
      "train loss:0.8482156495735275\n",
      "train loss:1.0294183250266074\n",
      "train loss:0.8587756123429614\n",
      "train loss:0.989599191163856\n",
      "train loss:0.9091485822825132\n",
      "train loss:0.9229458814906174\n",
      "train loss:0.7614559680245212\n",
      "train loss:0.7465247531005214\n",
      "train loss:0.8990972794891233\n",
      "train loss:0.9626243609941473\n",
      "train loss:0.8574590461164087\n",
      "train loss:0.8762913967921953\n",
      "train loss:0.8319009477174868\n",
      "train loss:0.8984579728291225\n",
      "train loss:0.8469317358481492\n",
      "train loss:0.9253621262510602\n",
      "train loss:0.89252644373813\n",
      "train loss:0.7460631887517947\n",
      "train loss:0.8958435548219604\n",
      "train loss:0.8973554649947297\n",
      "train loss:0.9669988146654481\n",
      "train loss:0.86315396695035\n",
      "train loss:0.9017324959885239\n",
      "train loss:0.8495879993550862\n",
      "train loss:0.7974119405518977\n",
      "train loss:0.7587672391147237\n",
      "train loss:0.8353848333482682\n",
      "train loss:0.857132143477533\n",
      "train loss:0.8384575001043977\n",
      "train loss:0.9485387226676305\n",
      "train loss:0.9592968986334627\n",
      "train loss:0.8593990046199415\n",
      "train loss:0.9015508308016836\n",
      "train loss:0.9130933705802233\n",
      "train loss:0.90977138489029\n",
      "train loss:0.8383634043463011\n",
      "train loss:0.7240814464990641\n",
      "train loss:0.9528692469794988\n",
      "train loss:0.7923116293475693\n",
      "train loss:0.6163065231938548\n",
      "train loss:0.8645914867121107\n",
      "train loss:0.8991796144491042\n",
      "train loss:0.8588104368842169\n",
      "train loss:0.8987425557734238\n",
      "train loss:1.0122479213242213\n",
      "train loss:0.9090301329657767\n",
      "train loss:0.8391167215541299\n",
      "train loss:0.9888131934345478\n",
      "train loss:0.8034323812132549\n",
      "train loss:0.9364623961535125\n",
      "train loss:1.0028446241998714\n",
      "train loss:0.805307611502736\n",
      "train loss:1.012039034331688\n",
      "train loss:1.0512319996937807\n",
      "train loss:0.9214111410187842\n",
      "train loss:0.9419637691173848\n",
      "train loss:1.0844796899288829\n",
      "train loss:0.9184817991482963\n",
      "train loss:0.8382027172394835\n",
      "train loss:0.8266529354489711\n",
      "train loss:0.9653092544905912\n",
      "train loss:0.9288531209895876\n",
      "train loss:0.8798309894406938\n",
      "train loss:0.8706879830725363\n",
      "train loss:1.0955570066743576\n",
      "train loss:0.7571063452180451\n",
      "train loss:0.8347502140334017\n",
      "train loss:1.167720075627522\n",
      "train loss:0.9406115712944838\n",
      "train loss:0.9932563840652882\n",
      "train loss:0.6792107511532192\n",
      "train loss:0.783739303572515\n",
      "train loss:0.9948012658220443\n",
      "train loss:1.030861731474276\n",
      "train loss:0.9217638445964615\n",
      "train loss:0.9270538794045272\n",
      "train loss:0.9381483227653554\n",
      "train loss:0.9720181503515647\n",
      "train loss:0.7853235571138871\n",
      "train loss:0.8169314900330583\n",
      "train loss:0.8546844650769997\n",
      "train loss:0.970165317649537\n",
      "train loss:0.9321226731594194\n",
      "train loss:0.9086830946805006\n",
      "train loss:0.9174349490142384\n",
      "train loss:1.0378115308197078\n",
      "train loss:0.77877235737912\n",
      "train loss:0.9987891650097044\n",
      "train loss:0.8677926067354149\n",
      "train loss:0.7853429810971798\n",
      "train loss:1.0138474076825443\n",
      "train loss:0.9636171863099766\n",
      "train loss:0.8504905071536045\n",
      "train loss:0.835881603602582\n",
      "train loss:0.8734228991683469\n",
      "train loss:0.8726119807000897\n",
      "train loss:0.9464659842762925\n",
      "train loss:0.9694554545239937\n",
      "train loss:0.847773327421419\n",
      "train loss:0.8679449743721639\n",
      "train loss:0.9556743911822366\n",
      "train loss:0.7781814021386648\n",
      "train loss:0.9481935131501104\n",
      "train loss:0.8065072258943529\n",
      "train loss:0.8597208388495166\n",
      "train loss:0.8129240864263578\n",
      "train loss:0.8220198348634165\n",
      "train loss:1.0305770418845546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8923147953709885\n",
      "train loss:0.8420334872931527\n",
      "train loss:1.0313198765901712\n",
      "train loss:0.9495707375132548\n",
      "train loss:1.0231646588857695\n",
      "train loss:0.9845113467267761\n",
      "train loss:0.7792903382659793\n",
      "train loss:0.7566700143766225\n",
      "train loss:0.8545533986344886\n",
      "train loss:0.703651688344915\n",
      "train loss:0.8634816609506079\n",
      "train loss:0.9019033222334997\n",
      "train loss:0.9528773762614315\n",
      "train loss:0.9023943157884774\n",
      "train loss:0.8382841160658471\n",
      "train loss:0.633148467128475\n",
      "train loss:0.9051352378664131\n",
      "train loss:0.8652845368015051\n",
      "train loss:1.0028184844909993\n",
      "train loss:0.945490968134419\n",
      "train loss:0.8661828685866986\n",
      "train loss:0.8647938978825578\n",
      "train loss:0.9418181412576235\n",
      "train loss:0.8933653370057546\n",
      "train loss:0.8859490485006551\n",
      "train loss:0.829348296504623\n",
      "train loss:0.8214718369322922\n",
      "train loss:0.9644593885744617\n",
      "train loss:0.7331781824163071\n",
      "train loss:0.9296513054876379\n",
      "train loss:0.9082302748923836\n",
      "train loss:0.8546125096505796\n",
      "train loss:0.9109528065140797\n",
      "train loss:0.902934366255865\n",
      "train loss:0.9150376150623135\n",
      "train loss:0.9080433394953803\n",
      "train loss:0.8745525045376779\n",
      "train loss:0.8435484914531186\n",
      "train loss:0.9421332917602651\n",
      "train loss:0.8490003950036414\n",
      "train loss:0.7866049540133365\n",
      "train loss:0.9373385107505614\n",
      "train loss:0.7637828537912221\n",
      "train loss:0.85543453307769\n",
      "train loss:0.9117459590221239\n",
      "train loss:0.8935379445937444\n",
      "train loss:0.9730167091661168\n",
      "train loss:0.9625787048101757\n",
      "train loss:0.8543663087828505\n",
      "train loss:0.8334436873880661\n",
      "train loss:0.9571295050305569\n",
      "train loss:1.1616077450501299\n",
      "train loss:1.0083392575467318\n",
      "train loss:0.8259352743981576\n",
      "train loss:0.8518477694807837\n",
      "train loss:0.7906880868854594\n",
      "train loss:0.7771000105148542\n",
      "train loss:0.8801114700109693\n",
      "train loss:0.94330527381934\n",
      "train loss:0.7299188458962351\n",
      "train loss:1.1229424331439868\n",
      "train loss:0.9984326398955033\n",
      "train loss:0.9062526354636546\n",
      "train loss:0.9335957558786387\n",
      "train loss:0.9737314231231597\n",
      "train loss:0.9767163219821273\n",
      "train loss:0.7854894512989796\n",
      "train loss:0.7742240190877119\n",
      "train loss:1.0039255432288001\n",
      "train loss:0.7988667232632689\n",
      "train loss:0.9239620044380429\n",
      "train loss:0.8310149165841862\n",
      "train loss:0.9552148177886863\n",
      "train loss:0.8565419458080199\n",
      "train loss:0.8737305788572681\n",
      "train loss:0.793954378604723\n",
      "train loss:0.7264223379684105\n",
      "train loss:0.9307655556894464\n",
      "train loss:0.9335732111319663\n",
      "train loss:0.8727140494743346\n",
      "train loss:0.9297483703394209\n",
      "train loss:1.0047579558832702\n",
      "train loss:0.8882987580740185\n",
      "train loss:0.99906444789574\n",
      "train loss:0.7736360255055647\n",
      "train loss:0.7981896570589777\n",
      "train loss:0.9023601695466509\n",
      "train loss:1.0132603362194361\n",
      "train loss:0.9153773984515143\n",
      "train loss:0.9268775527175583\n",
      "train loss:0.8518247661103033\n",
      "train loss:0.8751502494064448\n",
      "train loss:1.0805150591053323\n",
      "train loss:1.0049629121955765\n",
      "train loss:0.8862404732730016\n",
      "train loss:0.846648977171607\n",
      "train loss:0.8200507987849277\n",
      "train loss:0.9316748149768191\n",
      "train loss:0.774224612679879\n",
      "train loss:0.8782296436807211\n",
      "train loss:0.8053245140495927\n",
      "train loss:0.9381460355840922\n",
      "train loss:0.7919274685431236\n",
      "train loss:0.9163548683170744\n",
      "train loss:0.8332345774704357\n",
      "train loss:0.6753093713629412\n",
      "train loss:0.9606186141382644\n",
      "train loss:0.8156676806254215\n",
      "train loss:0.9668770529796599\n",
      "train loss:0.6934412856824501\n",
      "train loss:0.910468685247994\n",
      "train loss:0.9515022789944422\n",
      "train loss:1.0837569280648347\n",
      "train loss:0.9076701000420674\n",
      "train loss:0.9104921488723466\n",
      "train loss:0.9584996618852455\n",
      "train loss:0.7444054530986824\n",
      "train loss:0.9842651540071798\n",
      "train loss:0.9179627177480683\n",
      "train loss:0.8805766863364763\n",
      "train loss:0.9194823322166983\n",
      "train loss:0.9017259969790119\n",
      "train loss:0.8514727160430131\n",
      "train loss:1.067050222461439\n",
      "train loss:0.8390372518295582\n",
      "train loss:0.9031889935053995\n",
      "train loss:0.976149700396798\n",
      "train loss:0.9505683061139004\n",
      "train loss:0.9391562349537853\n",
      "train loss:1.0262466618959487\n",
      "train loss:0.995252958521758\n",
      "train loss:0.9815674421189428\n",
      "train loss:1.0273213606171223\n",
      "train loss:0.7211847881882578\n",
      "train loss:1.0535104995966598\n",
      "train loss:0.882366759302354\n",
      "train loss:0.750936450114006\n",
      "train loss:0.8323559191105119\n",
      "train loss:1.0093293365110811\n",
      "train loss:0.8460721943881242\n",
      "train loss:0.8140255103183134\n",
      "train loss:1.0145415638945456\n",
      "train loss:0.9394986493562569\n",
      "train loss:0.8870077540754415\n",
      "train loss:0.7508435416798076\n",
      "train loss:0.9385873139905689\n",
      "train loss:0.9432686236711129\n",
      "train loss:0.8376520303144775\n",
      "train loss:0.8171043464601838\n",
      "train loss:0.6646627157397863\n",
      "train loss:1.0493156949801108\n",
      "train loss:0.794231229737187\n",
      "train loss:0.799220429570892\n",
      "train loss:0.8798940701026962\n",
      "train loss:1.0335874979191033\n",
      "train loss:0.7386470410060697\n",
      "train loss:0.8937433796044726\n",
      "train loss:0.9483897688885712\n",
      "train loss:0.7573933818749581\n",
      "train loss:0.8139436710471307\n",
      "train loss:0.9044335458547133\n",
      "train loss:0.8140136165347578\n",
      "train loss:0.8807890719548118\n",
      "train loss:0.8976361231185976\n",
      "train loss:0.7163936864182545\n",
      "train loss:0.9808107390644291\n",
      "train loss:0.8354108182565113\n",
      "train loss:0.8792861937356179\n",
      "train loss:0.8316404879094044\n",
      "train loss:0.8832435312476395\n",
      "train loss:0.9916696899162732\n",
      "train loss:1.0578836960836575\n",
      "train loss:0.8606471506987984\n",
      "train loss:1.0021070309268798\n",
      "train loss:0.8001268514332915\n",
      "train loss:0.992176652114606\n",
      "train loss:0.928053645341995\n",
      "train loss:1.0163821165781992\n",
      "train loss:0.8598925968830994\n",
      "train loss:0.8631844831089086\n",
      "train loss:0.8925243042469974\n",
      "train loss:0.959678814109981\n",
      "train loss:0.9539089158354929\n",
      "train loss:0.9079467614619419\n",
      "train loss:0.9216380866323648\n",
      "train loss:0.8309203054604509\n",
      "train loss:0.9016605867837183\n",
      "train loss:0.9054449763370296\n",
      "train loss:0.9714102395887703\n",
      "train loss:0.9191025050906341\n",
      "train loss:0.9818373865954232\n",
      "train loss:0.9108344618705783\n",
      "train loss:0.9142984869921704\n",
      "train loss:0.8869171064956538\n",
      "train loss:0.8895689801227651\n",
      "train loss:0.9595035139333045\n",
      "train loss:0.6685983768006447\n",
      "train loss:0.8805415537427899\n",
      "train loss:0.7826310847073628\n",
      "train loss:0.8102262897361018\n",
      "train loss:1.177096305595657\n",
      "train loss:1.0727028597990182\n",
      "train loss:0.8858937806860869\n",
      "train loss:1.0337290066304918\n",
      "train loss:0.8554768426085869\n",
      "train loss:0.835301998390722\n",
      "train loss:0.8940130938884964\n",
      "train loss:0.8536385897173692\n",
      "train loss:0.7656037531132927\n",
      "train loss:0.9436935077485014\n",
      "train loss:0.9231697048239107\n",
      "train loss:0.9343894641446557\n",
      "train loss:0.9481835608907296\n",
      "train loss:0.8871230571186968\n",
      "train loss:1.1503099466929227\n",
      "train loss:0.9565596837281484\n",
      "train loss:0.9189143801463128\n",
      "train loss:1.0249106109864115\n",
      "train loss:0.9190612309413569\n",
      "train loss:0.8816743442038976\n",
      "train loss:0.9536242316747219\n",
      "train loss:0.8981813137452928\n",
      "train loss:0.9335974952940407\n",
      "train loss:0.7540594357352746\n",
      "train loss:1.0877211946952219\n",
      "train loss:0.9644970404208764\n",
      "train loss:0.8252729433704477\n",
      "train loss:0.9761559599971609\n",
      "train loss:1.0212612281935507\n",
      "train loss:0.8176404378422159\n",
      "train loss:0.8305975841000983\n",
      "train loss:0.9027423106063348\n",
      "train loss:0.8214974001159141\n",
      "train loss:0.8823389437188961\n",
      "train loss:0.8659142730912022\n",
      "train loss:0.9139297626170169\n",
      "train loss:0.8077592726692114\n",
      "train loss:0.8761177327902984\n",
      "train loss:0.9995953124413197\n",
      "train loss:1.0569466045311506\n",
      "train loss:0.9425124521214144\n",
      "train loss:1.0130595819365944\n",
      "train loss:1.0593584744881774\n",
      "train loss:1.0260684997197365\n",
      "train loss:0.8228607791199544\n",
      "train loss:0.7421017835704232\n",
      "train loss:0.7346591917009575\n",
      "train loss:1.032762364420374\n",
      "train loss:0.8998259642228125\n",
      "train loss:0.8830911567420923\n",
      "train loss:0.8124738166572628\n",
      "train loss:0.9780155355999475\n",
      "train loss:0.9572552016170148\n",
      "train loss:0.7755765094335919\n",
      "train loss:0.8730599488489201\n",
      "train loss:0.779822977352149\n",
      "train loss:0.9255215026223766\n",
      "train loss:0.9426540806821788\n",
      "train loss:0.712956195448945\n",
      "train loss:0.8749588743547156\n",
      "train loss:0.8740223322779751\n",
      "train loss:0.9472708525736887\n",
      "train loss:0.832582911196143\n",
      "train loss:0.8127641125380553\n",
      "train loss:0.8102724160075654\n",
      "train loss:0.8303111845192136\n",
      "train loss:0.957590585598955\n",
      "train loss:0.9872118055563693\n",
      "train loss:0.997707486650037\n",
      "train loss:0.9131432047874135\n",
      "train loss:0.926086070600558\n",
      "train loss:0.8541031541120657\n",
      "train loss:0.738482087049184\n",
      "train loss:0.7517097108394872\n",
      "train loss:0.9622071756428386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8365176736496766\n",
      "train loss:1.0085245619701708\n",
      "train loss:0.9369134687435211\n",
      "train loss:0.8536044567934337\n",
      "train loss:0.941992285482713\n",
      "train loss:0.8139049483989866\n",
      "train loss:0.9160148291581058\n",
      "train loss:0.7205496516769321\n",
      "train loss:0.880956196233583\n",
      "train loss:0.7813545830839154\n",
      "train loss:0.946843673925411\n",
      "train loss:0.8561960212701081\n",
      "train loss:0.9833299789068758\n",
      "train loss:0.7970467422691612\n",
      "train loss:0.940767651612568\n",
      "train loss:0.8360045942788489\n",
      "train loss:0.8373038565258818\n",
      "train loss:0.8610652970227959\n",
      "train loss:0.7918158501992493\n",
      "train loss:0.7711078083517121\n",
      "train loss:0.9696089830117718\n",
      "train loss:0.8560027179762081\n",
      "train loss:0.7910728486537786\n",
      "train loss:0.8655767191383009\n",
      "train loss:0.8714031905456726\n",
      "train loss:0.9813005650646732\n",
      "train loss:0.940429186424931\n",
      "train loss:0.8618685416043195\n",
      "train loss:0.9780174444137073\n",
      "train loss:0.8901795817045172\n",
      "train loss:0.9225650799479201\n",
      "train loss:0.7973548993667786\n",
      "train loss:1.0054667992797925\n",
      "train loss:0.8355912287777955\n",
      "train loss:0.832034435185464\n",
      "train loss:0.810522003344871\n",
      "train loss:0.7075171248057894\n",
      "train loss:0.9376131310472658\n",
      "train loss:0.7944880721055695\n",
      "train loss:0.9034908472907357\n",
      "train loss:0.919380507446398\n",
      "train loss:0.8653453832775793\n",
      "train loss:1.0613527422287774\n",
      "train loss:0.7988702666683044\n",
      "train loss:0.9563593569482518\n",
      "train loss:0.7525436357152482\n",
      "train loss:0.7910869250459442\n",
      "train loss:0.9619682271832742\n",
      "train loss:0.9486391605739604\n",
      "train loss:0.8966700596690765\n",
      "train loss:1.011504546900019\n",
      "train loss:0.9251976521520335\n",
      "train loss:0.9953366036555497\n",
      "train loss:0.8859971495420348\n",
      "train loss:0.9389309829409617\n",
      "train loss:0.8855690236311137\n",
      "train loss:0.7811448716415286\n",
      "train loss:0.7543337253369701\n",
      "train loss:0.96314792844673\n",
      "train loss:0.8702638814829993\n",
      "train loss:0.9422561006807385\n",
      "train loss:0.697277928698621\n",
      "train loss:0.9014833812484053\n",
      "train loss:0.8650262929357198\n",
      "train loss:0.9209096589943786\n",
      "train loss:0.9932618013428137\n",
      "train loss:0.8489481569593574\n",
      "train loss:0.8967968300242578\n",
      "train loss:0.8665028552581748\n",
      "train loss:0.8879296536532959\n",
      "train loss:0.7996118520392881\n",
      "train loss:0.7842960961999061\n",
      "train loss:1.0485582543006708\n",
      "train loss:0.8121912577112724\n",
      "train loss:0.7236330467047306\n",
      "train loss:1.0186585034658326\n",
      "train loss:0.9690525285825373\n",
      "train loss:0.947800305137545\n",
      "train loss:0.9235242994885937\n",
      "train loss:0.7773879704314861\n",
      "train loss:0.8678783058077494\n",
      "train loss:0.8986126634608486\n",
      "train loss:0.8072256058500134\n",
      "train loss:0.9479384775639933\n",
      "train loss:0.9795775298717628\n",
      "train loss:1.0204192501359686\n",
      "train loss:0.7836200591864754\n",
      "train loss:0.8273715153996717\n",
      "train loss:0.7929247907694933\n",
      "train loss:0.9860859457940835\n",
      "train loss:0.9546971856794749\n",
      "train loss:0.776222120173996\n",
      "train loss:0.8188577914196226\n",
      "train loss:0.8937584809087232\n",
      "train loss:0.9214770776986642\n",
      "train loss:0.8638688927494806\n",
      "train loss:0.9783779627162535\n",
      "train loss:0.7100126523273577\n",
      "train loss:1.0079294516180572\n",
      "train loss:0.9486382365998651\n",
      "train loss:1.021840281212607\n",
      "train loss:0.8259373500430889\n",
      "train loss:1.136395921598612\n",
      "train loss:0.9147405301187823\n",
      "train loss:0.853446091555901\n",
      "train loss:0.7344070355703258\n",
      "train loss:0.8573146028186259\n",
      "train loss:0.9539833097874616\n",
      "train loss:1.1542198118467821\n",
      "train loss:1.0783121383762897\n",
      "train loss:0.855239336282534\n",
      "train loss:0.9244023776579787\n",
      "train loss:0.7461393732126722\n",
      "train loss:0.8019006458228123\n",
      "train loss:0.7761885929391211\n",
      "train loss:0.8996032683505814\n",
      "train loss:0.7468765252368997\n",
      "train loss:1.0826563045652469\n",
      "train loss:0.9123697127256335\n",
      "train loss:0.9709036674463402\n",
      "train loss:0.7380213292455514\n",
      "train loss:0.7032605316059113\n",
      "train loss:0.835956047965158\n",
      "train loss:0.7195985054433222\n",
      "train loss:0.8326782344557593\n",
      "train loss:0.8123716823918357\n",
      "train loss:0.7712126144077809\n",
      "train loss:0.8065023905454641\n",
      "train loss:0.8124453415852194\n",
      "train loss:0.9202639066003974\n",
      "train loss:0.8725367459304355\n",
      "train loss:0.8319868939366378\n",
      "train loss:0.9228522052535257\n",
      "train loss:0.8480767233638806\n",
      "train loss:0.9171601431089342\n",
      "train loss:0.7953205601754116\n",
      "train loss:0.8525602663204469\n",
      "=== epoch:9, train acc:0.993, test acc:0.988 ===\n",
      "train loss:0.8970514447501823\n",
      "train loss:0.9474422211650534\n",
      "train loss:0.810617898632387\n",
      "train loss:1.0014192739762768\n",
      "train loss:0.996133293491414\n",
      "train loss:0.9811056945212454\n",
      "train loss:0.8983317181376346\n",
      "train loss:1.0050612000235628\n",
      "train loss:0.9649884600445218\n",
      "train loss:0.998212950944786\n",
      "train loss:0.8498097385395567\n",
      "train loss:0.9695902144299982\n",
      "train loss:0.9598679223187122\n",
      "train loss:0.9402286656700768\n",
      "train loss:0.9292801076474387\n",
      "train loss:0.9021083819143497\n",
      "train loss:0.9249606711499099\n",
      "train loss:0.9162807832950912\n",
      "train loss:1.034466204161971\n",
      "train loss:0.8475234179858836\n",
      "train loss:0.8821430584885712\n",
      "train loss:0.9780508073332959\n",
      "train loss:0.8464667084883333\n",
      "train loss:0.8474355828384357\n",
      "train loss:0.9690733721775021\n",
      "train loss:0.9917698616240653\n",
      "train loss:0.9238394709076377\n",
      "train loss:0.8824690280061079\n",
      "train loss:0.7720772993219326\n",
      "train loss:0.9706995036721285\n",
      "train loss:0.7777995482458359\n",
      "train loss:0.9662873602764696\n",
      "train loss:1.035450430147112\n",
      "train loss:0.9172828177848761\n",
      "train loss:0.8647012307807372\n",
      "train loss:0.9135318891405788\n",
      "train loss:1.0059056410197538\n",
      "train loss:0.6775670671204332\n",
      "train loss:0.9314337540705262\n",
      "train loss:0.9054999608520908\n",
      "train loss:0.9658573381466925\n",
      "train loss:0.8562550362890299\n",
      "train loss:0.8188225767202417\n",
      "train loss:0.8838101705058938\n",
      "train loss:1.0957211413650665\n",
      "train loss:0.836118772458794\n",
      "train loss:0.8970517346563339\n",
      "train loss:0.7726727425246803\n",
      "train loss:0.7663304372623226\n",
      "train loss:1.0782784372033065\n",
      "train loss:0.8287756934484801\n",
      "train loss:0.8482960946098724\n",
      "train loss:0.906892722818995\n",
      "train loss:0.7183042640789573\n",
      "train loss:0.931409975443874\n",
      "train loss:0.9229407292328503\n",
      "train loss:0.777180376783171\n",
      "train loss:0.9343778056433686\n",
      "train loss:0.8469834907809048\n",
      "train loss:0.8579343058415335\n",
      "train loss:0.9328234576990135\n",
      "train loss:1.0406883051766345\n",
      "train loss:0.7754788193642522\n",
      "train loss:0.9941692163320524\n",
      "train loss:0.8567399344712474\n",
      "train loss:0.8383045810436799\n",
      "train loss:0.9004188043426634\n",
      "train loss:0.8356144834052819\n",
      "train loss:0.9699903409524268\n",
      "train loss:0.9396316663265132\n",
      "train loss:0.9724650341370871\n",
      "train loss:0.9195970596765044\n",
      "train loss:0.9760834148903216\n",
      "train loss:0.8572119499263563\n",
      "train loss:0.9360340054420183\n",
      "train loss:0.848743941669771\n",
      "train loss:0.9050604274659326\n",
      "train loss:0.757610699413501\n",
      "train loss:1.0693651617629003\n",
      "train loss:1.004920519659839\n",
      "train loss:1.0296766692505965\n",
      "train loss:1.1592053229613923\n",
      "train loss:0.7817907120591048\n",
      "train loss:0.7891879063030212\n",
      "train loss:0.9017117945345288\n",
      "train loss:0.719870405444305\n",
      "train loss:0.9069644559177593\n",
      "train loss:0.8604217043588764\n",
      "train loss:0.8771641446141178\n",
      "train loss:0.8404025645994799\n",
      "train loss:0.8334529529634223\n",
      "train loss:1.1022383434728769\n",
      "train loss:0.9436955321893812\n",
      "train loss:0.834529603771378\n",
      "train loss:0.8852454249711066\n",
      "train loss:0.875265073377641\n",
      "train loss:1.143870567526667\n",
      "train loss:0.9286780370994968\n",
      "train loss:1.0040859612728712\n",
      "train loss:0.7529647705964676\n",
      "train loss:0.8963654342258965\n",
      "train loss:0.8672451835906255\n",
      "train loss:0.9396035102068955\n",
      "train loss:1.0740850655702134\n",
      "train loss:0.9885084186296699\n",
      "train loss:0.7738231477351769\n",
      "train loss:0.7952005946567171\n",
      "train loss:1.0033226071474446\n",
      "train loss:0.7657956916711502\n",
      "train loss:0.839179679793265\n",
      "train loss:0.9581887167530639\n",
      "train loss:0.7538347804059736\n",
      "train loss:0.8635332101008649\n",
      "train loss:0.9343104790630715\n",
      "train loss:0.8789120161302953\n",
      "train loss:0.9889061321783714\n",
      "train loss:0.8498177116064072\n",
      "train loss:0.9466884534747321\n",
      "train loss:0.8929020148097628\n",
      "train loss:0.7106655242824956\n",
      "train loss:0.8560915021790269\n",
      "train loss:0.8884352601015207\n",
      "train loss:0.9300655744608999\n",
      "train loss:1.1086661754282068\n",
      "train loss:0.98719113050929\n",
      "train loss:0.8381620493203837\n",
      "train loss:0.9180364594654017\n",
      "train loss:0.8890730843572149\n",
      "train loss:0.8745740642719234\n",
      "train loss:0.7265234495482743\n",
      "train loss:0.7144298297166061\n",
      "train loss:0.8429096069837653\n",
      "train loss:0.84686636484574\n",
      "train loss:0.9487381757417387\n",
      "train loss:0.7705350791481613\n",
      "train loss:1.0415293251268272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9740458219033045\n",
      "train loss:0.5827070552972966\n",
      "train loss:0.9419988028822821\n",
      "train loss:0.93350620676226\n",
      "train loss:0.7356852995386474\n",
      "train loss:0.9302938084144552\n",
      "train loss:0.8131573797061056\n",
      "train loss:0.8276250723187166\n",
      "train loss:0.8088514622519325\n",
      "train loss:0.8153616270898648\n",
      "train loss:0.8117806538373062\n",
      "train loss:0.8356669254913668\n",
      "train loss:0.8450084252261888\n",
      "train loss:0.9156774275364599\n",
      "train loss:0.7825027733624609\n",
      "train loss:1.046654819348759\n",
      "train loss:0.8830914609483416\n",
      "train loss:0.7041818945308893\n",
      "train loss:1.0022547871378789\n",
      "train loss:0.8196828291275833\n",
      "train loss:0.8298127546227324\n",
      "train loss:0.7198865803497455\n",
      "train loss:0.9634692513137267\n",
      "train loss:0.8063131408757528\n",
      "train loss:0.9991245753741205\n",
      "train loss:0.9180135574844279\n",
      "train loss:0.9228688999594894\n",
      "train loss:0.9111523919796389\n",
      "train loss:0.9728170200617899\n",
      "train loss:0.86706912223138\n",
      "train loss:0.9233796431045594\n",
      "train loss:1.0487696336811025\n",
      "train loss:0.9547106975308539\n",
      "train loss:0.8734847531433639\n",
      "train loss:0.7532793794803819\n",
      "train loss:0.8619458716663547\n",
      "train loss:0.944948857899091\n",
      "train loss:0.8430384146906924\n",
      "train loss:0.9678124179284932\n",
      "train loss:0.8943389713780259\n",
      "train loss:0.808598781247239\n",
      "train loss:0.8887813779824195\n",
      "train loss:0.7370947861969639\n",
      "train loss:1.0090822136416615\n",
      "train loss:0.8887225445382618\n",
      "train loss:0.9676987219232019\n",
      "train loss:0.9548368376663702\n",
      "train loss:0.7727820393544949\n",
      "train loss:0.5966698248431883\n",
      "train loss:0.8730052622454607\n",
      "train loss:0.9615056109118298\n",
      "train loss:0.8014081430465739\n",
      "train loss:0.9344114482244283\n",
      "train loss:0.9438574715242461\n",
      "train loss:0.697047564576046\n",
      "train loss:0.8071231319255986\n",
      "train loss:0.815595445031809\n",
      "train loss:0.8627811531669656\n",
      "train loss:0.7952555448301544\n",
      "train loss:1.0854785215125413\n",
      "train loss:0.9967804708454033\n",
      "train loss:0.9654750654951773\n",
      "train loss:0.9809137585377651\n",
      "train loss:0.7526342014495748\n",
      "train loss:0.9324292382167918\n",
      "train loss:0.7057827981198386\n",
      "train loss:0.7552128476276959\n",
      "train loss:0.8399283080839992\n",
      "train loss:0.8438113060187803\n",
      "train loss:1.0620259941937809\n",
      "train loss:0.7226081851886036\n",
      "train loss:0.8808441160708518\n",
      "train loss:0.895819870298601\n",
      "train loss:0.9620222388980989\n",
      "train loss:0.943511617726958\n",
      "train loss:0.9318521719705315\n",
      "train loss:1.0211391430215209\n",
      "train loss:0.9233700107040517\n",
      "train loss:0.7779919321450324\n",
      "train loss:0.8705001282496062\n",
      "train loss:0.8502328485699452\n",
      "train loss:0.829895016027827\n",
      "train loss:0.8967328648725738\n",
      "train loss:0.7315440359083919\n",
      "train loss:0.8839158669459621\n",
      "train loss:0.780279100650721\n",
      "train loss:0.8666131895772888\n",
      "train loss:0.758382622224032\n",
      "train loss:0.946774139124834\n",
      "train loss:0.9759234799961977\n",
      "train loss:0.8171473973356781\n",
      "train loss:0.9454701508384745\n",
      "train loss:0.8240812727436796\n",
      "train loss:0.8413503369137685\n",
      "train loss:0.762443746518208\n",
      "train loss:0.9907302628241965\n",
      "train loss:0.9262617375225808\n",
      "train loss:0.9848332839291232\n",
      "train loss:0.9062975914373912\n",
      "train loss:0.8600787723965957\n",
      "train loss:0.9724041269539205\n",
      "train loss:0.9291788716772835\n",
      "train loss:0.9628546858994877\n",
      "train loss:0.8339937835902147\n",
      "train loss:0.9412534202733037\n",
      "train loss:0.8653106830236555\n",
      "train loss:0.9231977939768196\n",
      "train loss:0.9541300427558113\n",
      "train loss:0.8629721668070134\n",
      "train loss:0.9378883972558857\n",
      "train loss:0.8153890168603688\n",
      "train loss:0.9118495891584854\n",
      "train loss:0.7964953314758171\n",
      "train loss:1.1399472084343532\n",
      "train loss:0.9918521315827101\n",
      "train loss:0.8384392684619086\n",
      "train loss:0.9195462347265991\n",
      "train loss:0.9377148624712562\n",
      "train loss:0.7680510279014972\n",
      "train loss:1.082697742166248\n",
      "train loss:0.863317488065815\n",
      "train loss:0.8507410194588536\n",
      "train loss:0.7189613510114231\n",
      "train loss:0.8416181105368247\n",
      "train loss:0.879411192598507\n",
      "train loss:0.8154573676152623\n",
      "train loss:0.9453298149578145\n",
      "train loss:0.9207453888432107\n",
      "train loss:0.7888700259875482\n",
      "train loss:0.7833259066683516\n",
      "train loss:0.7932480946946562\n",
      "train loss:0.768477752025269\n",
      "train loss:0.8182273592847854\n",
      "train loss:0.9453573115263361\n",
      "train loss:0.9875440083435728\n",
      "train loss:0.7951660439028495\n",
      "train loss:0.709753772162596\n",
      "train loss:1.0123915080206571\n",
      "train loss:0.8795200300613701\n",
      "train loss:0.8993995254223002\n",
      "train loss:0.7562911268863818\n",
      "train loss:0.7778133866986887\n",
      "train loss:0.7098405993486591\n",
      "train loss:0.850272662906371\n",
      "train loss:0.965241287562306\n",
      "train loss:0.8991629387584616\n",
      "train loss:0.7831934845016633\n",
      "train loss:0.8421291999291836\n",
      "train loss:0.6833185086023404\n",
      "train loss:0.9202084209666501\n",
      "train loss:0.8177972594763456\n",
      "train loss:0.8115487648042391\n",
      "train loss:0.8990874851080614\n",
      "train loss:0.7933110832056178\n",
      "train loss:1.0177567609936184\n",
      "train loss:1.153073579356112\n",
      "train loss:0.9079796064851364\n",
      "train loss:0.7558628130837002\n",
      "train loss:0.9001380421000792\n",
      "train loss:0.8151313950080636\n",
      "train loss:0.9422959195802518\n",
      "train loss:1.0528165593303387\n",
      "train loss:0.964144701409731\n",
      "train loss:0.9837170761335995\n",
      "train loss:0.7684382502707444\n",
      "train loss:0.8203426498959064\n",
      "train loss:0.58254647474804\n",
      "train loss:1.004655970665666\n",
      "train loss:1.0238837414160482\n",
      "train loss:1.042698908547073\n",
      "train loss:0.8613209381278404\n",
      "train loss:0.9775585799954755\n",
      "train loss:0.9693516271165171\n",
      "train loss:0.9214625224444672\n",
      "train loss:0.7674384182400311\n",
      "train loss:0.9607340837472543\n",
      "train loss:0.7944283154171218\n",
      "train loss:0.915804007377502\n",
      "train loss:0.8650963080346482\n",
      "train loss:0.9392346796829633\n",
      "train loss:0.7728134342774059\n",
      "train loss:0.9529374881541667\n",
      "train loss:1.070038049956066\n",
      "train loss:1.0138740543504803\n",
      "train loss:0.7982037014112536\n",
      "train loss:0.8091679490931378\n",
      "train loss:0.8262026212425502\n",
      "train loss:0.9837133170938138\n",
      "train loss:1.0627165539395502\n",
      "train loss:0.8439040534778822\n",
      "train loss:0.8626344354496677\n",
      "train loss:1.0330649776709289\n",
      "train loss:0.9710055432370632\n",
      "train loss:1.0074489975803285\n",
      "train loss:0.8009612934997189\n",
      "train loss:0.892609241096284\n",
      "train loss:0.9603136367871913\n",
      "train loss:1.022297336095705\n",
      "train loss:0.8700568353931992\n",
      "train loss:0.7029642378244847\n",
      "train loss:0.8136282617661946\n",
      "train loss:0.8745056983080687\n",
      "train loss:0.8087396409589487\n",
      "train loss:0.8884078817673925\n",
      "train loss:0.9567488939824368\n",
      "train loss:0.9276246522424308\n",
      "train loss:0.895850618462928\n",
      "train loss:0.8468766199375599\n",
      "train loss:0.9106776827788423\n",
      "train loss:0.8374163046713121\n",
      "train loss:0.9857609647795761\n",
      "train loss:0.9373104488426803\n",
      "train loss:0.8129449488276387\n",
      "train loss:0.9047575505245119\n",
      "train loss:0.9219255575149196\n",
      "train loss:0.8285129297196492\n",
      "train loss:0.8724067283014949\n",
      "train loss:0.9185347635567179\n",
      "train loss:0.8754835023954946\n",
      "train loss:0.8273888450527851\n",
      "train loss:0.9603567838429466\n",
      "train loss:0.9563839605536121\n",
      "train loss:0.9384479366292819\n",
      "train loss:0.8986939660416451\n",
      "train loss:0.9513655782247465\n",
      "train loss:0.8552539399504738\n",
      "train loss:0.736225823790988\n",
      "train loss:0.9948261705922817\n",
      "train loss:0.6037643545040676\n",
      "train loss:0.9147871627587182\n",
      "train loss:0.8426274142104618\n",
      "train loss:0.8744461210376919\n",
      "train loss:0.8746919293950353\n",
      "train loss:0.9737835786584488\n",
      "train loss:0.9220224216394408\n",
      "train loss:0.896379035249614\n",
      "train loss:0.7635306756948244\n",
      "train loss:0.868306297971194\n",
      "train loss:0.8767021330168636\n",
      "train loss:0.8427979596912766\n",
      "train loss:0.7586705954265044\n",
      "train loss:0.7793073331340122\n",
      "train loss:0.7465149506602603\n",
      "train loss:0.9659524006627203\n",
      "train loss:0.8232890005625434\n",
      "train loss:0.7684792409686514\n",
      "train loss:1.066020775740681\n",
      "train loss:0.8950223994631236\n",
      "train loss:0.9647314550297112\n",
      "train loss:0.8247271526803298\n",
      "train loss:0.8441298482401979\n",
      "train loss:0.9364175967351926\n",
      "train loss:1.0693712771359056\n",
      "train loss:0.8963802809201209\n",
      "train loss:0.7964657731273137\n",
      "train loss:0.962168817565247\n",
      "train loss:1.0530362794651598\n",
      "train loss:0.7639881867693089\n",
      "train loss:0.8473972954932678\n",
      "train loss:0.9494779101557183\n",
      "train loss:0.8801983104624435\n",
      "train loss:0.9859358235892963\n",
      "train loss:0.9095670099818901\n",
      "train loss:0.9096120115198012\n",
      "train loss:0.8691988338459479\n",
      "train loss:0.7267146966203266\n",
      "train loss:1.1167904885231308\n",
      "train loss:0.8668079666720587\n",
      "train loss:0.9097136400595768\n",
      "train loss:0.8158819553187818\n",
      "train loss:0.7878024318801039\n",
      "train loss:0.8677781633130075\n",
      "train loss:0.9290968571038545\n",
      "train loss:0.7792766057983762\n",
      "train loss:0.7910636382953339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7302481820257121\n",
      "train loss:0.8820840227759811\n",
      "train loss:0.9311717585849953\n",
      "train loss:0.9321503508986255\n",
      "train loss:0.8430232322805722\n",
      "train loss:0.8787407459426833\n",
      "train loss:0.8881378603819524\n",
      "train loss:0.7883327237218932\n",
      "train loss:0.7054250247078002\n",
      "train loss:0.8716230205796299\n",
      "train loss:0.8389202824870474\n",
      "train loss:0.8528318648803556\n",
      "train loss:0.8784851253910927\n",
      "train loss:1.1977116392868998\n",
      "train loss:0.8570582917671061\n",
      "train loss:0.876274070193495\n",
      "train loss:0.984701979581324\n",
      "train loss:0.8748363355253893\n",
      "train loss:0.8199771276603316\n",
      "train loss:0.991473350065031\n",
      "train loss:0.7805963237319525\n",
      "train loss:0.9149969009225543\n",
      "train loss:1.1318675528548803\n",
      "train loss:1.0590240983125083\n",
      "train loss:0.8480541630623415\n",
      "train loss:0.8258520659166619\n",
      "train loss:0.9568693659434377\n",
      "train loss:0.9449978560727363\n",
      "train loss:0.847679102866152\n",
      "train loss:0.9967343613101798\n",
      "train loss:0.7542067805313306\n",
      "train loss:0.9308231274088447\n",
      "train loss:0.7657946764871549\n",
      "train loss:0.7801985758118175\n",
      "train loss:0.9293368191131285\n",
      "train loss:0.9373455012574488\n",
      "train loss:0.8808878197760324\n",
      "train loss:0.8204642953019698\n",
      "train loss:0.7970748132239572\n",
      "train loss:1.0476071963725442\n",
      "train loss:1.059172217596086\n",
      "train loss:0.9283202658831736\n",
      "train loss:0.9537701318416739\n",
      "train loss:0.9178058945880201\n",
      "train loss:1.0040379150839913\n",
      "train loss:0.8512784046948874\n",
      "train loss:0.9930041934856609\n",
      "train loss:0.7791332804581205\n",
      "train loss:0.6918715706915504\n",
      "train loss:0.8771366639826393\n",
      "train loss:0.9498257105319502\n",
      "train loss:0.8645123499484341\n",
      "train loss:0.8311733589996696\n",
      "train loss:1.0175249661063988\n",
      "train loss:1.0407494344921047\n",
      "train loss:0.8161647855361369\n",
      "train loss:0.8036429870681147\n",
      "train loss:0.8322617970223368\n",
      "train loss:1.0164011532988875\n",
      "train loss:0.8065985741578495\n",
      "train loss:0.8258019860876464\n",
      "train loss:0.8719252063557837\n",
      "train loss:0.9713980476087979\n",
      "train loss:0.8053260105634453\n",
      "train loss:0.745663786116562\n",
      "train loss:0.808953766022489\n",
      "train loss:1.0205465528447455\n",
      "train loss:0.7388045431625614\n",
      "train loss:0.8711397423527468\n",
      "train loss:0.8498750497190872\n",
      "train loss:1.035332635112766\n",
      "train loss:1.044907257788485\n",
      "train loss:0.8366530508034583\n",
      "train loss:0.8268781870098322\n",
      "train loss:0.7874805705716392\n",
      "train loss:0.9512018480776431\n",
      "train loss:0.9407198383246955\n",
      "train loss:0.7259233849579134\n",
      "train loss:0.7619988678861415\n",
      "train loss:0.8112988464029465\n",
      "train loss:0.934511250677867\n",
      "train loss:1.0588184660018218\n",
      "train loss:0.9221328558682287\n",
      "train loss:0.9749500294248266\n",
      "train loss:1.0011660510946225\n",
      "train loss:0.7877800404791258\n",
      "train loss:0.8824682375729092\n",
      "train loss:0.7940836485748946\n",
      "train loss:0.8306462388671627\n",
      "train loss:0.8954957474668374\n",
      "train loss:0.8518703183930156\n",
      "train loss:0.9149718030622672\n",
      "train loss:1.0527584609253096\n",
      "train loss:0.8534224591508749\n",
      "train loss:0.86883882247461\n",
      "train loss:0.973362996545086\n",
      "train loss:0.8178685265786992\n",
      "train loss:0.7880952835142285\n",
      "train loss:1.0107293897214946\n",
      "train loss:0.9358173837291693\n",
      "train loss:0.8382461926385997\n",
      "train loss:0.8390174186461345\n",
      "train loss:0.9341345133572909\n",
      "train loss:0.9168853426942358\n",
      "train loss:0.8671626227092502\n",
      "train loss:0.8986774716110085\n",
      "train loss:0.9612115450991934\n",
      "train loss:0.9147169623786167\n",
      "train loss:0.9728550288226974\n",
      "train loss:0.8007954405093268\n",
      "train loss:0.7548473710942725\n",
      "train loss:0.9515647854829489\n",
      "train loss:0.8351865154216094\n",
      "train loss:0.7908833952001726\n",
      "train loss:0.9645164074191952\n",
      "train loss:1.1232815981320527\n",
      "train loss:0.8471354466180162\n",
      "train loss:0.9083829891839075\n",
      "train loss:0.9173071413958965\n",
      "train loss:0.7043168701722428\n",
      "train loss:0.8038549939201401\n",
      "train loss:0.8581727240341926\n",
      "train loss:1.0760733611958635\n",
      "train loss:1.029711643306178\n",
      "train loss:0.7685213689292685\n",
      "train loss:0.9392252639730151\n",
      "train loss:0.8963997021289748\n",
      "train loss:0.9113932584054113\n",
      "train loss:0.972135392427094\n",
      "train loss:0.8496808139954648\n",
      "train loss:0.8753246965418591\n",
      "train loss:0.7848991070731691\n",
      "train loss:0.9321982147027309\n",
      "train loss:1.0969715950553052\n",
      "train loss:0.9754668920131639\n",
      "train loss:0.809070399940454\n",
      "train loss:0.8916672292416117\n",
      "train loss:0.8270745020729383\n",
      "train loss:0.8019878417428146\n",
      "train loss:1.0961231316117803\n",
      "train loss:0.9802546293910855\n",
      "train loss:0.8469271662550927\n",
      "train loss:0.8363622838580592\n",
      "train loss:0.776013016237012\n",
      "train loss:1.0552298599957208\n",
      "train loss:0.8029216317830453\n",
      "train loss:0.872503355184922\n",
      "train loss:1.065828056482023\n",
      "train loss:0.923998638507334\n",
      "train loss:0.622918253088887\n",
      "train loss:0.9536149689639213\n",
      "train loss:0.912688826733003\n",
      "train loss:0.6944906057635936\n",
      "train loss:0.9741274125212107\n",
      "train loss:1.01175053670583\n",
      "train loss:0.7188644184686869\n",
      "train loss:1.0432097810095118\n",
      "train loss:0.9504518521933538\n",
      "train loss:0.9829389383119979\n",
      "train loss:0.864911528132578\n",
      "train loss:0.8266989600761641\n",
      "train loss:0.9589282388670882\n",
      "train loss:0.9216745565922162\n",
      "train loss:0.9814385230283517\n",
      "train loss:1.0874305152954622\n",
      "train loss:0.9024021216200627\n",
      "train loss:0.953115779076296\n",
      "train loss:0.7061253033727901\n",
      "train loss:0.9150188344908992\n",
      "train loss:0.87898204441422\n",
      "train loss:0.8418432889411147\n",
      "train loss:0.8653426489364183\n",
      "train loss:0.881526264126279\n",
      "train loss:0.966138839095117\n",
      "train loss:0.8502025642757937\n",
      "train loss:0.9142798013066978\n",
      "train loss:0.7390316938346051\n",
      "train loss:0.9952551267820492\n",
      "train loss:0.9856366579058053\n",
      "train loss:0.9097601109110621\n",
      "train loss:0.9096570747737052\n",
      "train loss:0.804339316932689\n",
      "train loss:0.7933626261519706\n",
      "train loss:1.1134918097890651\n",
      "train loss:0.7991037096823258\n",
      "train loss:0.8400603944795639\n",
      "train loss:0.7754085692840756\n",
      "train loss:0.915708901709942\n",
      "train loss:0.8146622198943194\n",
      "=== epoch:10, train acc:0.995, test acc:0.988 ===\n",
      "train loss:0.8296075439058563\n",
      "train loss:0.8569044695123296\n",
      "train loss:0.776531957497955\n",
      "train loss:0.8847228427767752\n",
      "train loss:0.859183674218267\n",
      "train loss:0.8851074982124154\n",
      "train loss:0.9006174382162672\n",
      "train loss:0.7318146695955499\n",
      "train loss:0.7997419970187362\n",
      "train loss:0.8045446671014269\n",
      "train loss:0.9715596307349011\n",
      "train loss:0.8923617261329229\n",
      "train loss:0.8004847345317241\n",
      "train loss:0.9630635156206754\n",
      "train loss:0.8572590852380813\n",
      "train loss:0.9211798309474217\n",
      "train loss:0.9182316533360999\n",
      "train loss:0.8783044119008117\n",
      "train loss:0.9488318062389841\n",
      "train loss:0.9332796608837693\n",
      "train loss:1.0689739704072454\n",
      "train loss:0.7533689222831422\n",
      "train loss:0.895936501336339\n",
      "train loss:0.8045583868435761\n",
      "train loss:0.9653072104499617\n",
      "train loss:0.8784151136301301\n",
      "train loss:0.9823676126360569\n",
      "train loss:0.8472217062827673\n",
      "train loss:0.9590098428081181\n",
      "train loss:0.7863231792024955\n",
      "train loss:0.9149110870641828\n",
      "train loss:0.8197979540060224\n",
      "train loss:0.697525367884227\n",
      "train loss:0.8239282414636068\n",
      "train loss:0.9002517533417894\n",
      "train loss:0.8608664904842677\n",
      "train loss:0.72732034690284\n",
      "train loss:0.8877902451026073\n",
      "train loss:0.9444758739918191\n",
      "train loss:0.8358577734824075\n",
      "train loss:0.818289890677205\n",
      "train loss:0.7318198201123396\n",
      "train loss:0.9670875735532546\n",
      "train loss:0.8823724382406408\n",
      "train loss:0.73951663034816\n",
      "train loss:0.8449744121926873\n",
      "train loss:1.0083819365686224\n",
      "train loss:0.8912832816035855\n",
      "train loss:0.743776291016388\n",
      "train loss:1.0872514770575854\n",
      "train loss:0.9669560650517158\n",
      "train loss:0.926669184029098\n",
      "train loss:0.9674613259857575\n",
      "train loss:0.7757528032068454\n",
      "train loss:0.7076043920613668\n",
      "train loss:0.7487189241529423\n",
      "train loss:0.8187202110346185\n",
      "train loss:0.9513399502174263\n",
      "train loss:1.0400850375531305\n",
      "train loss:0.8009891215730722\n",
      "train loss:1.0233774125213515\n",
      "train loss:1.0121707240977318\n",
      "train loss:0.7828175770515503\n",
      "train loss:0.9007063858610371\n",
      "train loss:0.8463443212612946\n",
      "train loss:0.783362701137422\n",
      "train loss:0.8191791312544129\n",
      "train loss:0.6874886619067182\n",
      "train loss:0.9156655123319644\n",
      "train loss:0.7701961288290201\n",
      "train loss:0.9672791656694792\n",
      "train loss:0.8838427346847135\n",
      "train loss:0.880074567679533\n",
      "train loss:0.8545040641133841\n",
      "train loss:0.9030993689970999\n",
      "train loss:0.8089476113066693\n",
      "train loss:0.8892572956998506\n",
      "train loss:0.8375217444916193\n",
      "train loss:0.8824104851663492\n",
      "train loss:0.9653408625738622\n",
      "train loss:0.7184848727534704\n",
      "train loss:0.8950601372769225\n",
      "train loss:0.9378141429161466\n",
      "train loss:0.9064246485023686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8895838159860348\n",
      "train loss:0.7950144153980565\n",
      "train loss:0.9124642935378736\n",
      "train loss:0.7302267459406244\n",
      "train loss:0.779484457486183\n",
      "train loss:0.7294985778855184\n",
      "train loss:0.8657967121730026\n",
      "train loss:0.7683035969350632\n",
      "train loss:0.9409564004650233\n",
      "train loss:0.8008659413373355\n",
      "train loss:0.8487975783330264\n",
      "train loss:0.7326484657753902\n",
      "train loss:0.8696951818206549\n",
      "train loss:0.8301323529214565\n",
      "train loss:0.7832781527663428\n",
      "train loss:0.7736858565138662\n",
      "train loss:0.9390758496241102\n",
      "train loss:0.9945816681177125\n",
      "train loss:0.8607032305187649\n",
      "train loss:0.9073144619330813\n",
      "train loss:0.9234239948006707\n",
      "train loss:0.7655714754414474\n",
      "train loss:0.9527288793318808\n",
      "train loss:0.707024432062636\n",
      "train loss:0.8067438819772005\n",
      "train loss:0.9126301393829808\n",
      "train loss:0.9889738353059663\n",
      "train loss:0.7002805989343757\n",
      "train loss:0.7918071677509302\n",
      "train loss:0.8533428480041553\n",
      "train loss:0.8919967139529412\n",
      "train loss:1.0901895765670708\n",
      "train loss:0.7641025009585924\n",
      "train loss:0.878932401888983\n",
      "train loss:0.8416348077951276\n",
      "train loss:0.8807638419775239\n",
      "train loss:1.1069110197154246\n",
      "train loss:0.8561201438424046\n",
      "train loss:0.809551485700373\n",
      "train loss:0.9229663783397407\n",
      "train loss:0.7572200021211392\n",
      "train loss:0.8168875048535709\n",
      "train loss:0.9697164140845359\n",
      "train loss:0.8510022746915467\n",
      "train loss:0.8115914408003374\n",
      "train loss:0.7604041043893885\n",
      "train loss:0.8147064779185065\n",
      "train loss:0.9656243952862522\n",
      "train loss:1.0772881321896328\n",
      "train loss:0.8418294622809261\n",
      "train loss:0.8728111247659861\n",
      "train loss:1.0221638177062113\n",
      "train loss:0.8363952032230816\n",
      "train loss:0.9190503599977916\n",
      "train loss:0.9791554145470595\n",
      "train loss:0.929567876132531\n",
      "train loss:0.8387299440616013\n",
      "train loss:1.075994757969203\n",
      "train loss:0.9580474943123889\n",
      "train loss:0.9198819363997456\n",
      "train loss:0.7952594794558676\n",
      "train loss:0.7433717097468796\n",
      "train loss:1.0367936629721044\n",
      "train loss:0.9983070584397566\n",
      "train loss:0.7074637700504317\n",
      "train loss:0.933947938718314\n",
      "train loss:0.6976588927920033\n",
      "train loss:0.8932895669988739\n",
      "train loss:0.7797481528460072\n",
      "train loss:0.8097610725885773\n",
      "train loss:0.8833953347533838\n",
      "train loss:0.7013641828253994\n",
      "train loss:0.737990416979347\n",
      "train loss:0.9378475795685651\n",
      "train loss:0.904350725141707\n",
      "train loss:0.867731364975884\n",
      "train loss:0.8176470837605595\n",
      "train loss:0.7719989548217582\n",
      "train loss:0.8254338016411117\n",
      "train loss:1.0109472212202961\n",
      "train loss:0.9412349411549011\n",
      "train loss:0.9695738037440251\n",
      "train loss:0.8500224665608243\n",
      "train loss:0.9587252131493597\n",
      "train loss:0.9379028689938675\n",
      "train loss:0.7981776536279471\n",
      "train loss:0.9843330889626836\n",
      "train loss:0.8855567131631631\n",
      "train loss:0.8152852107431717\n",
      "train loss:0.9957580621919729\n",
      "train loss:0.7999414348895377\n",
      "train loss:0.8769189335168567\n",
      "train loss:0.9249331159817454\n",
      "train loss:0.8061096600153297\n",
      "train loss:0.8765789628662374\n",
      "train loss:0.7827545229705006\n",
      "train loss:0.8529345641254419\n",
      "train loss:1.0486030323861555\n",
      "train loss:0.7639234139453778\n",
      "train loss:0.8706367286335154\n",
      "train loss:0.9132475326977344\n",
      "train loss:0.8952747013158173\n",
      "train loss:0.8393795077705535\n",
      "train loss:0.7889487467951561\n",
      "train loss:0.8408587136589384\n",
      "train loss:0.83805454796492\n",
      "train loss:0.8901812708712725\n",
      "train loss:0.9481003573126501\n",
      "train loss:0.8541648302613689\n",
      "train loss:0.8221952039360739\n",
      "train loss:0.9789278298922142\n",
      "train loss:0.929854273778479\n",
      "train loss:0.9336632773091037\n",
      "train loss:0.7981528682520407\n",
      "train loss:0.9901606584022473\n",
      "train loss:0.7913881532247143\n",
      "train loss:0.7651913552903444\n",
      "train loss:0.9725280817040134\n",
      "train loss:0.9508053840134736\n",
      "train loss:0.9162025081862104\n",
      "train loss:0.8584244116823889\n",
      "train loss:0.7296030292620423\n",
      "train loss:0.9561339603338707\n",
      "train loss:0.894153489228339\n",
      "train loss:0.7816869208733566\n",
      "train loss:0.8910047093062782\n",
      "train loss:0.930234285027645\n",
      "train loss:0.7957464266871251\n",
      "train loss:0.9591138135405568\n",
      "train loss:0.875073764273055\n",
      "train loss:0.8165157283178399\n",
      "train loss:0.9972763243345579\n",
      "train loss:0.8971301000306297\n",
      "train loss:0.8569437272116167\n",
      "train loss:0.9602281985249508\n",
      "train loss:0.8557565712032011\n",
      "train loss:0.6505357229690013\n",
      "train loss:1.0025705766069577\n",
      "train loss:0.7737128376023399\n",
      "train loss:0.9635032755801552\n",
      "train loss:1.0661354378245023\n",
      "train loss:0.6998081195895911\n",
      "train loss:0.9268047623095893\n",
      "train loss:0.9437102035834397\n",
      "train loss:0.8838712001979814\n",
      "train loss:0.8459148988128168\n",
      "train loss:0.9259094638774212\n",
      "train loss:0.9936702607680502\n",
      "train loss:0.8877667345503164\n",
      "train loss:0.9503508254139403\n",
      "train loss:0.8948141191175273\n",
      "train loss:0.8669493770492509\n",
      "train loss:0.9093892532530573\n",
      "train loss:0.8459361233430469\n",
      "train loss:0.8522861871511984\n",
      "train loss:0.78014039423443\n",
      "train loss:0.7797120707674198\n",
      "train loss:1.085891709538044\n",
      "train loss:0.6962622364781851\n",
      "train loss:0.8173703378599073\n",
      "train loss:0.8645925013613023\n",
      "train loss:0.8564209159769942\n",
      "train loss:0.8736894404500446\n",
      "train loss:0.8588704912458267\n",
      "train loss:0.8181205114441878\n",
      "train loss:0.8297807659756002\n",
      "train loss:1.0062326008099014\n",
      "train loss:0.6375254010351271\n",
      "train loss:0.9772161390177245\n",
      "train loss:0.827375664949917\n",
      "train loss:0.8263532475275549\n",
      "train loss:0.8953179126908072\n",
      "train loss:0.8784362214753305\n",
      "train loss:0.9291570017604336\n",
      "train loss:0.9187316899168636\n",
      "train loss:0.9498010458579756\n",
      "train loss:0.8088352499801492\n",
      "train loss:0.9405177674935987\n",
      "train loss:0.9063421167028862\n",
      "train loss:0.935557389086241\n",
      "train loss:0.7119382503802104\n",
      "train loss:0.8780137222377665\n",
      "train loss:0.8553462245232158\n",
      "train loss:0.9420563487191157\n",
      "train loss:0.8038848042895016\n",
      "train loss:0.9364085035201571\n",
      "train loss:0.792115087959963\n",
      "train loss:0.7699697407545822\n",
      "train loss:0.8398278494468489\n",
      "train loss:0.8604005030712514\n",
      "train loss:0.7687690705309403\n",
      "train loss:0.8433625564711363\n",
      "train loss:1.0337487144487991\n",
      "train loss:0.9074170991148585\n",
      "train loss:0.8060629377047492\n",
      "train loss:0.8037325449159674\n",
      "train loss:0.9190533933138053\n",
      "train loss:0.8694294041919934\n",
      "train loss:0.8262084774219915\n",
      "train loss:0.8868031217981559\n",
      "train loss:0.9066446507252013\n",
      "train loss:0.8418868523409218\n",
      "train loss:0.793636123994633\n",
      "train loss:0.9146377375908983\n",
      "train loss:0.9856017156914381\n",
      "train loss:0.7766125690803066\n",
      "train loss:0.7314432991863902\n",
      "train loss:0.8529392830536824\n",
      "train loss:0.8011558247460202\n",
      "train loss:0.8872673559852163\n",
      "train loss:0.9090223304503876\n",
      "train loss:1.0167318740847584\n",
      "train loss:0.8932091535000382\n",
      "train loss:0.686200203067735\n",
      "train loss:1.038659311035405\n",
      "train loss:0.8982790856569739\n",
      "train loss:0.7521071284493164\n",
      "train loss:0.9384786509387887\n",
      "train loss:0.8570691536072126\n",
      "train loss:0.974803449527351\n",
      "train loss:0.7656277678914516\n",
      "train loss:0.8921238841118844\n",
      "train loss:0.851526030581057\n",
      "train loss:0.843465033173841\n",
      "train loss:1.01848638513211\n",
      "train loss:0.8789659281485587\n",
      "train loss:0.8573206262194417\n",
      "train loss:0.7897595719789189\n",
      "train loss:0.8606470481995727\n",
      "train loss:0.903269037734042\n",
      "train loss:0.895049885689555\n",
      "train loss:0.917487248718715\n",
      "train loss:1.0788186372313986\n",
      "train loss:0.8550450023535192\n",
      "train loss:0.8879721453874686\n",
      "train loss:0.9683087357968947\n",
      "train loss:0.8791788973206489\n",
      "train loss:0.809457834269455\n",
      "train loss:0.7794108207760436\n",
      "train loss:0.763700088515174\n",
      "train loss:0.7563074799844397\n",
      "train loss:0.828274528299348\n",
      "train loss:0.8117801084769515\n",
      "train loss:0.8116638632594945\n",
      "train loss:0.8837872448472329\n",
      "train loss:0.8570745087496797\n",
      "train loss:0.9078800049897637\n",
      "train loss:0.9731373633243217\n",
      "train loss:0.7872947779503754\n",
      "train loss:0.9212896382028914\n",
      "train loss:0.8674716442084283\n",
      "train loss:0.9953054719514828\n",
      "train loss:0.9881303742921625\n",
      "train loss:1.0025707399109023\n",
      "train loss:0.8691466524939622\n",
      "train loss:0.8346125004422976\n",
      "train loss:0.8384670364998474\n",
      "train loss:0.9555855662168363\n",
      "train loss:1.019366820262321\n",
      "train loss:1.00005903905376\n",
      "train loss:0.9956411695363159\n",
      "train loss:0.7918035209932417\n",
      "train loss:0.9091235195500615\n",
      "train loss:0.8436259489921103\n",
      "train loss:1.0255070010758858\n",
      "train loss:0.8925830936881072\n",
      "train loss:0.6866118563937065\n",
      "train loss:0.8216035960263212\n",
      "train loss:0.8624796439629171\n",
      "train loss:0.7900575016957699\n",
      "train loss:0.8632285504118647\n",
      "train loss:0.9404413527657212\n",
      "train loss:0.8775180321262962\n",
      "train loss:1.010707695031621\n",
      "train loss:0.8005954832790723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8977128737399847\n",
      "train loss:0.7627787650995212\n",
      "train loss:0.8414314307572311\n",
      "train loss:0.8234645814140903\n",
      "train loss:1.0315253186187423\n",
      "train loss:0.9693995435727737\n",
      "train loss:1.0231999290659797\n",
      "train loss:0.8286017058307885\n",
      "train loss:0.9252567111606917\n",
      "train loss:0.8870289051112508\n",
      "train loss:0.8564767890357586\n",
      "train loss:0.9993989206687313\n",
      "train loss:0.8248706309182681\n",
      "train loss:0.9351234688245357\n",
      "train loss:0.9456611358513543\n",
      "train loss:0.9476467471493929\n",
      "train loss:0.9337196869017896\n",
      "train loss:0.7889047867640244\n",
      "train loss:0.894036259119133\n",
      "train loss:0.9846819118048825\n",
      "train loss:0.8317283967732944\n",
      "train loss:0.8912256805999305\n",
      "train loss:0.8326692406029198\n",
      "train loss:0.9133665220332545\n",
      "train loss:0.8708453883214304\n",
      "train loss:0.8789789205235289\n",
      "train loss:0.9706027225316322\n",
      "train loss:0.5533896051735462\n",
      "train loss:0.9388429767111398\n",
      "train loss:0.8889995974104556\n",
      "train loss:0.8542066277187916\n",
      "train loss:0.857570775028687\n",
      "train loss:0.7906615105332164\n",
      "train loss:1.0214810003564807\n",
      "train loss:0.8895174021110935\n",
      "train loss:0.8136379632971256\n",
      "train loss:0.7881886620083364\n",
      "train loss:0.8147586724091492\n",
      "train loss:0.8801189412572795\n",
      "train loss:0.902329212991402\n",
      "train loss:0.9295023727111156\n",
      "train loss:0.9096828370681129\n",
      "train loss:0.9588562099915596\n",
      "train loss:0.866457920192151\n",
      "train loss:0.8111314470657299\n",
      "train loss:0.7642251226044362\n",
      "train loss:0.827050257556954\n",
      "train loss:0.9627606747823659\n",
      "train loss:0.9858369969243094\n",
      "train loss:0.8474204798593751\n",
      "train loss:0.8084742918886004\n",
      "train loss:0.8589617981715602\n",
      "train loss:0.6681240256486207\n",
      "train loss:0.6670728259000019\n",
      "train loss:1.0180964517151403\n",
      "train loss:0.9312994754975192\n",
      "train loss:1.0669804870002697\n",
      "train loss:0.9745961614467943\n",
      "train loss:0.9374738899695971\n",
      "train loss:0.7896559046495808\n",
      "train loss:0.7915976753702826\n",
      "train loss:0.9321693375653866\n",
      "train loss:0.9761625632032032\n",
      "train loss:1.0143448921295373\n",
      "train loss:0.9052328189056549\n",
      "train loss:0.9294955596032887\n",
      "train loss:0.8301627715093878\n",
      "train loss:0.8922237264801808\n",
      "train loss:0.8202881012768775\n",
      "train loss:0.9112951050434687\n",
      "train loss:0.7573428762937211\n",
      "train loss:0.8179591940717735\n",
      "train loss:0.9100641185837914\n",
      "train loss:0.9217438316869473\n",
      "train loss:0.9388335170765144\n",
      "train loss:0.9602683615685603\n",
      "train loss:0.8655096754604175\n",
      "train loss:0.9484565943400101\n",
      "train loss:0.8653374670631151\n",
      "train loss:0.8087956382845652\n",
      "train loss:0.808716707299901\n",
      "train loss:0.875018190787212\n",
      "train loss:1.0215371650010185\n",
      "train loss:0.9726800435401995\n",
      "train loss:0.8117746473189692\n",
      "train loss:0.9288463595413987\n",
      "train loss:0.7548463464869929\n",
      "train loss:0.8862692794515534\n",
      "train loss:0.7748503971517567\n",
      "train loss:0.9497671826450842\n",
      "train loss:0.7761725762550856\n",
      "train loss:0.6833965616968739\n",
      "train loss:0.9481239641464179\n",
      "train loss:0.9835972591175959\n",
      "train loss:0.8259362023876115\n",
      "train loss:0.8159983080878583\n",
      "train loss:0.8549075424849495\n",
      "train loss:0.8297612049571478\n",
      "train loss:1.0301999151823396\n",
      "train loss:0.8577255292017489\n",
      "train loss:0.861283906155229\n",
      "train loss:0.8440269835717139\n",
      "train loss:0.76258894271433\n",
      "train loss:0.8649704644371594\n",
      "train loss:0.8911081495310388\n",
      "train loss:1.02440950142004\n",
      "train loss:0.8415954464479769\n",
      "train loss:0.8753015699815674\n",
      "train loss:0.8023668170742927\n",
      "train loss:0.8470015226246542\n",
      "train loss:0.6641183266473124\n",
      "train loss:0.7742849888558875\n",
      "train loss:0.840374327712859\n",
      "train loss:0.7903815477006306\n",
      "train loss:0.769873360962693\n",
      "train loss:0.9475219404901817\n",
      "train loss:0.834129369638111\n",
      "train loss:0.9243455776627094\n",
      "train loss:0.9941987337269715\n",
      "train loss:1.014462838122013\n",
      "train loss:0.812416074902721\n",
      "train loss:0.7994727876921555\n",
      "train loss:0.765507710515456\n",
      "train loss:0.9984539323052113\n",
      "train loss:0.9610845840557494\n",
      "train loss:0.8421012863003231\n",
      "train loss:1.0996745030698265\n",
      "train loss:1.0146048286317688\n",
      "train loss:0.8718644476526943\n",
      "train loss:0.9165502196842226\n",
      "train loss:0.9263602545273146\n",
      "train loss:0.8822585616671544\n",
      "train loss:0.9193106913988628\n",
      "train loss:0.934267282145807\n",
      "train loss:0.9112765651638272\n",
      "train loss:0.9354677009381915\n",
      "train loss:0.7490277216228338\n",
      "train loss:0.7404712260824817\n",
      "train loss:0.8360520611372505\n",
      "train loss:0.8345843784281157\n",
      "train loss:0.807458900569169\n",
      "train loss:0.7423876733492019\n",
      "train loss:0.6334717762480642\n",
      "train loss:0.9327147501687297\n",
      "train loss:0.8521786869532935\n",
      "train loss:0.7356326212411274\n",
      "train loss:0.7618269555931869\n",
      "train loss:0.9089612502669834\n",
      "train loss:0.9031497986593756\n",
      "train loss:0.8922847662808212\n",
      "train loss:0.8365470695344748\n",
      "train loss:0.9181330851919597\n",
      "train loss:0.8465482379368038\n",
      "train loss:0.8393651104601986\n",
      "train loss:0.8565326587799836\n",
      "train loss:0.9260249302391651\n",
      "train loss:0.9478511342300163\n",
      "train loss:0.7707863901378712\n",
      "train loss:0.8438860747913928\n",
      "train loss:0.8446529218639088\n",
      "train loss:0.7954652789220539\n",
      "train loss:0.9254626078561384\n",
      "train loss:0.9110841548837133\n",
      "train loss:0.8050547138109624\n",
      "train loss:0.7857797960372724\n",
      "train loss:0.8282481879942014\n",
      "train loss:0.9353412856613926\n",
      "train loss:0.9562372815449259\n",
      "train loss:0.9031660457014509\n",
      "train loss:0.9571764845286631\n",
      "train loss:0.8473159490739265\n",
      "train loss:0.9490576449245053\n",
      "train loss:0.8083076122915687\n",
      "train loss:0.7139188201178809\n",
      "train loss:0.7483004282916674\n",
      "train loss:0.9161220765860781\n",
      "train loss:0.8201401695939662\n",
      "train loss:0.9493447060840284\n",
      "train loss:1.0297402891209237\n",
      "train loss:0.8173177903261427\n",
      "train loss:0.9736271339844711\n",
      "train loss:0.9415162877411543\n",
      "train loss:0.9319112859000154\n",
      "train loss:1.1535199098729925\n",
      "train loss:0.7838803094396398\n",
      "train loss:0.9840934729064108\n",
      "train loss:0.7297580042112024\n",
      "train loss:0.8926872076308652\n",
      "train loss:0.9230878391087087\n",
      "train loss:0.8176429180215243\n",
      "train loss:0.8370978030295165\n",
      "train loss:0.9882430589614573\n",
      "train loss:0.928014528967846\n",
      "train loss:0.8953842426037858\n",
      "train loss:0.8915167643892654\n",
      "train loss:0.8081345009532183\n",
      "train loss:0.7753197799787899\n",
      "train loss:0.8316707899998914\n",
      "train loss:0.7285306476138663\n",
      "train loss:0.9786671338652846\n",
      "train loss:0.7919953776846014\n",
      "train loss:0.8150792602368534\n",
      "train loss:0.9350397512947404\n",
      "train loss:1.0407786614040138\n",
      "train loss:0.7746903127497877\n",
      "train loss:0.8036057248452082\n",
      "train loss:0.8733042748372379\n",
      "train loss:0.9577834843705884\n",
      "train loss:1.001945621223277\n",
      "train loss:0.7943975597787823\n",
      "train loss:1.046854215623005\n",
      "train loss:0.9638554163551479\n",
      "train loss:0.9859576659297467\n",
      "train loss:0.9976950465520497\n",
      "train loss:0.8562460918065442\n",
      "train loss:1.0285716745507507\n",
      "train loss:0.8220797394253723\n",
      "train loss:0.8439627705811011\n",
      "train loss:0.9476754616663028\n",
      "train loss:1.0380124925199545\n",
      "train loss:0.9305660102863031\n",
      "train loss:0.8864990362812531\n",
      "train loss:0.7181150144286803\n",
      "train loss:0.9145333020070544\n",
      "train loss:0.9113249837115899\n",
      "train loss:0.8308458325244251\n",
      "train loss:0.8661824792856898\n",
      "train loss:1.1356997645358613\n",
      "train loss:0.6890519807019857\n",
      "train loss:0.888703013171893\n",
      "train loss:0.8668149263053095\n",
      "train loss:0.9936683713113352\n",
      "train loss:0.9084583189278524\n",
      "train loss:0.7605298553231732\n",
      "train loss:0.8537916244625291\n",
      "train loss:0.9180116099162561\n",
      "train loss:0.7168090143821803\n",
      "train loss:0.9523018057357548\n",
      "train loss:0.860799978859275\n",
      "train loss:0.8959904660358012\n",
      "train loss:0.9586144429655548\n",
      "=== epoch:11, train acc:0.991, test acc:0.987 ===\n",
      "train loss:1.0470543217913935\n",
      "train loss:1.024104529435433\n",
      "train loss:0.9653196116645526\n",
      "train loss:0.8366562114486336\n",
      "train loss:1.0716278646481754\n",
      "train loss:0.832352754919708\n",
      "train loss:0.7275912609998748\n",
      "train loss:0.8325573574937948\n",
      "train loss:0.9155002779408282\n",
      "train loss:0.70378289993495\n",
      "train loss:0.8547740744648291\n",
      "train loss:0.975475720032007\n",
      "train loss:0.794595625261746\n",
      "train loss:0.7105031741791066\n",
      "train loss:0.8007839741025155\n",
      "train loss:0.837721070764987\n",
      "train loss:0.8495700304634792\n",
      "train loss:0.8853743749525826\n",
      "train loss:0.9109474189753444\n",
      "train loss:0.9923421490921868\n",
      "train loss:0.9733056524824589\n",
      "train loss:0.9506718422271434\n",
      "train loss:0.803769277799621\n",
      "train loss:0.9412358737953973\n",
      "train loss:0.9727596283661647\n",
      "train loss:0.8994310594175947\n",
      "train loss:1.049190753081062\n",
      "train loss:0.7723199684247516\n",
      "train loss:0.9959900546471364\n",
      "train loss:0.912705040774964\n",
      "train loss:0.8047797397560162\n",
      "train loss:0.9100058362850872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.880663461735099\n",
      "train loss:0.8227827666172786\n",
      "train loss:1.0419008887763632\n",
      "train loss:0.7715543795563217\n",
      "train loss:0.7879583148480751\n",
      "train loss:0.8922668374003031\n",
      "train loss:0.8747453604948354\n",
      "train loss:0.9228214383947985\n",
      "train loss:0.8367057983579953\n",
      "train loss:0.8425624326705368\n",
      "train loss:0.833659810386365\n",
      "train loss:1.026353724309175\n",
      "train loss:0.9814067634977272\n",
      "train loss:0.7458104114980477\n",
      "train loss:0.8236207046146586\n",
      "train loss:0.9305579651345697\n",
      "train loss:0.9891419588424345\n",
      "train loss:0.9893366233985804\n",
      "train loss:0.8080511662997659\n",
      "train loss:0.9826000186522008\n",
      "train loss:0.9529074148059976\n",
      "train loss:0.9157114001313934\n",
      "train loss:0.8434211324276594\n",
      "train loss:0.858467496170493\n",
      "train loss:0.8772641972887213\n",
      "train loss:0.7541763915116924\n",
      "train loss:0.8870224670137635\n",
      "train loss:0.7593385502507597\n",
      "train loss:0.8711100134165206\n",
      "train loss:0.8564543783582776\n",
      "train loss:0.8265921706514306\n",
      "train loss:0.7976370043074346\n",
      "train loss:0.7549223912156273\n",
      "train loss:0.8304812435786681\n",
      "train loss:0.8344607695025407\n",
      "train loss:0.7685405281264859\n",
      "train loss:0.8812647983751749\n",
      "train loss:0.9544550566965471\n",
      "train loss:1.0285871015481158\n",
      "train loss:0.8461947890951871\n",
      "train loss:0.9219151357735156\n",
      "train loss:1.0729642132363193\n",
      "train loss:1.0585647162405412\n",
      "train loss:0.7905653121927478\n",
      "train loss:0.8157523552946988\n",
      "train loss:1.019108781255609\n",
      "train loss:1.027688131907851\n",
      "train loss:0.8916916637192704\n",
      "train loss:0.8671701208471531\n",
      "train loss:0.8454201264174082\n",
      "train loss:0.9108226649433872\n",
      "train loss:0.933465050768705\n",
      "train loss:1.0239576920436257\n",
      "train loss:0.9131830435725462\n",
      "train loss:0.7559901767015346\n",
      "train loss:0.808292532351875\n",
      "train loss:0.9572732953767946\n",
      "train loss:0.881539519551627\n",
      "train loss:0.8418732077466595\n",
      "train loss:0.7343747005908182\n",
      "train loss:0.7218958195555915\n",
      "train loss:1.011205963678951\n",
      "train loss:0.9463163077317683\n",
      "train loss:0.9323203715465557\n",
      "train loss:0.7967729280125918\n",
      "train loss:0.8273330942341751\n",
      "train loss:0.7827867869042819\n",
      "train loss:0.7981088660340657\n",
      "train loss:0.8190174388034293\n",
      "train loss:0.7026965156707383\n",
      "train loss:1.0015816066204049\n",
      "train loss:0.7597091224267739\n",
      "train loss:0.8909285485474395\n",
      "train loss:0.7625070707921097\n",
      "train loss:1.0953953134551508\n",
      "train loss:0.9238607745421871\n",
      "train loss:0.7507505416085769\n",
      "train loss:0.9434877488810556\n",
      "train loss:0.9383219150119332\n",
      "train loss:1.0033591906275245\n",
      "train loss:0.7910860007990398\n",
      "train loss:0.7972933461237776\n",
      "train loss:0.8768643959961575\n",
      "train loss:0.9794414920759945\n",
      "train loss:1.0613107827682828\n",
      "train loss:1.0392615086970678\n",
      "train loss:0.948630967921148\n",
      "train loss:0.9423412580057531\n",
      "train loss:0.8557575957982496\n",
      "train loss:0.9667697214996569\n",
      "train loss:0.8978189636263337\n",
      "train loss:0.8172262940028339\n",
      "train loss:0.9634360001140816\n",
      "train loss:0.9197994307350994\n",
      "train loss:0.7529070975381846\n",
      "train loss:0.8394127867931972\n",
      "train loss:1.002343638127828\n",
      "train loss:0.8953688543881674\n",
      "train loss:0.8970376924842521\n",
      "train loss:0.8694524019289094\n",
      "train loss:0.7423217878179694\n",
      "train loss:0.89907950235175\n",
      "train loss:0.8979451396783068\n",
      "train loss:0.887064744637651\n",
      "train loss:0.8794820967951338\n",
      "train loss:0.9305867404679695\n",
      "train loss:1.0637210993591182\n",
      "train loss:0.8558285988760046\n",
      "train loss:0.907344904845511\n",
      "train loss:0.7224974505687409\n",
      "train loss:0.8419110614478484\n",
      "train loss:1.025765691906915\n",
      "train loss:1.0377782994769034\n",
      "train loss:0.8266193582760422\n",
      "train loss:0.9698251919102242\n",
      "train loss:0.844203512985888\n",
      "train loss:0.9768584907929374\n",
      "train loss:0.7847945068232995\n",
      "train loss:0.7471003323954382\n",
      "train loss:0.7246513460339101\n",
      "train loss:0.8682989185728744\n",
      "train loss:0.7847846053609381\n",
      "train loss:0.8416241923838104\n",
      "train loss:0.9893354088311601\n",
      "train loss:0.7804503314972843\n",
      "train loss:0.8118800059977461\n",
      "train loss:0.8509005665263986\n",
      "train loss:0.8432539204032681\n",
      "train loss:0.7615547869469534\n",
      "train loss:0.9408156014001083\n",
      "train loss:0.9633522037429921\n",
      "train loss:0.8084620507339884\n",
      "train loss:0.729949781050017\n",
      "train loss:0.7768303582721968\n",
      "train loss:0.9163380013504429\n",
      "train loss:0.944619662947125\n",
      "train loss:0.8493259284759753\n",
      "train loss:0.7740348340049783\n",
      "train loss:1.029291145913363\n",
      "train loss:1.0351073350099445\n",
      "train loss:0.8421904841220339\n",
      "train loss:0.8493134691682502\n",
      "train loss:0.8538167372655114\n",
      "train loss:0.8698942466506068\n",
      "train loss:0.8368092426381695\n",
      "train loss:0.9462231450638353\n",
      "train loss:0.8052392682425676\n",
      "train loss:0.8455188618673535\n",
      "train loss:0.9229231493147205\n",
      "train loss:0.877867084939323\n",
      "train loss:0.9594585495524153\n",
      "train loss:0.8153748740272251\n",
      "train loss:0.7633818608249944\n",
      "train loss:0.8668233370549523\n",
      "train loss:0.7272843833833561\n",
      "train loss:1.0393161492777865\n",
      "train loss:0.8322418945245651\n",
      "train loss:0.9692629392301652\n",
      "train loss:0.9916087736262068\n",
      "train loss:0.7102161059000339\n",
      "train loss:0.7862773419836883\n",
      "train loss:0.9053408664666297\n",
      "train loss:0.8104261696412979\n",
      "train loss:0.7769795673830171\n",
      "train loss:0.8034414548647736\n",
      "train loss:0.8484733960405723\n",
      "train loss:0.7748961776661396\n",
      "train loss:0.9231563162346688\n",
      "train loss:1.1039544376930508\n",
      "train loss:1.0754792588847195\n",
      "train loss:0.9357471177743686\n",
      "train loss:0.9147924705344147\n",
      "train loss:0.8978277368290093\n",
      "train loss:0.7992639319701081\n",
      "train loss:0.7864684066505968\n",
      "train loss:0.8532936787578561\n",
      "train loss:0.8072119295214594\n",
      "train loss:0.847481349744263\n",
      "train loss:1.04382878161198\n",
      "train loss:0.7794851726871128\n",
      "train loss:0.8437191722542886\n",
      "train loss:0.8274323282149167\n",
      "train loss:0.9547264499212909\n",
      "train loss:0.9392775721646625\n",
      "train loss:0.9557069744377195\n",
      "train loss:0.9028469022732358\n",
      "train loss:0.798653887760673\n",
      "train loss:0.8976455172742942\n",
      "train loss:0.7889942362950753\n",
      "train loss:0.8865826365131597\n",
      "train loss:0.7741731192232014\n",
      "train loss:0.9676688565689109\n",
      "train loss:0.7997123505609527\n",
      "train loss:0.9273496512333307\n",
      "train loss:0.8737935999628273\n",
      "train loss:0.7890260456638035\n",
      "train loss:1.0607049711114553\n",
      "train loss:0.9050937954264549\n",
      "train loss:0.8507049365069134\n",
      "train loss:0.8767481720177253\n",
      "train loss:0.8254714092319994\n",
      "train loss:0.88474258863678\n",
      "train loss:0.8929864504631656\n",
      "train loss:0.9818082681423833\n",
      "train loss:0.7736103722089763\n",
      "train loss:0.9114979308557655\n",
      "train loss:0.8885734562198373\n",
      "train loss:1.0191339082754176\n",
      "train loss:0.8799926017125281\n",
      "train loss:0.9613343545253437\n",
      "train loss:0.8095165848480486\n",
      "train loss:1.0058527462758622\n",
      "train loss:0.8155394465275974\n",
      "train loss:0.9187202700010358\n",
      "train loss:0.8920097192643764\n",
      "train loss:0.8832012287214909\n",
      "train loss:0.7944965881177052\n",
      "train loss:0.854720114782685\n",
      "train loss:0.8427935489946836\n",
      "train loss:0.9179903995934088\n",
      "train loss:0.8536863668129692\n",
      "train loss:0.7283516053342229\n",
      "train loss:0.8093660136526262\n",
      "train loss:1.0029742782550357\n",
      "train loss:0.8291552498454695\n",
      "train loss:0.8100871528457272\n",
      "train loss:0.9444581004515004\n",
      "train loss:0.8414887885207308\n",
      "train loss:0.9341125817080921\n",
      "train loss:0.7285631494147428\n",
      "train loss:0.9144794393666025\n",
      "train loss:0.83508457770115\n",
      "train loss:0.6969420453375933\n",
      "train loss:1.0575215888217107\n",
      "train loss:0.7866659331773168\n",
      "train loss:0.9256341795306194\n",
      "train loss:0.7944716703262233\n",
      "train loss:0.8812717844954361\n",
      "train loss:0.7567066782063087\n",
      "train loss:0.9203233934205304\n",
      "train loss:0.8943735335637026\n",
      "train loss:0.8747199570703533\n",
      "train loss:0.850877267916397\n",
      "train loss:1.0052348575357586\n",
      "train loss:0.9222112210334886\n",
      "train loss:0.8865692999458571\n",
      "train loss:0.8517205657986548\n",
      "train loss:0.8918284656214877\n",
      "train loss:0.9609908673836931\n",
      "train loss:0.9851474799776905\n",
      "train loss:0.8828377789419874\n",
      "train loss:0.8963521263006325\n",
      "train loss:0.81263401306129\n",
      "train loss:0.8533296701772324\n",
      "train loss:1.040425626831512\n",
      "train loss:0.9107635463916068\n",
      "train loss:1.0350984886656287\n",
      "train loss:0.8992576550733488\n",
      "train loss:0.8850006897227537\n",
      "train loss:0.8988799869569205\n",
      "train loss:0.8768792062566004\n",
      "train loss:0.8060063768060146\n",
      "train loss:0.945626768884037\n",
      "train loss:0.8766373247993954\n",
      "train loss:0.7404921676935288\n",
      "train loss:0.9464807853445947\n",
      "train loss:1.1690402847433692\n",
      "train loss:1.0159148234193345\n",
      "train loss:0.9445301354309761\n",
      "train loss:0.954718274094407\n",
      "train loss:0.9667574178668571\n",
      "train loss:0.8260237081875647\n",
      "train loss:0.9091805965150769\n",
      "train loss:0.8619702596952231\n",
      "train loss:0.8121170234613424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7622821418432362\n",
      "train loss:0.9400194352240279\n",
      "train loss:1.091182601313444\n",
      "train loss:0.7737150566966376\n",
      "train loss:0.9714645984470966\n",
      "train loss:0.8503356217284883\n",
      "train loss:0.7783853617690801\n",
      "train loss:0.8097167449905375\n",
      "train loss:0.7498809125240126\n",
      "train loss:0.7038757379736923\n",
      "train loss:0.8673478780488385\n",
      "train loss:0.9360989742745681\n",
      "train loss:0.7385054884844542\n",
      "train loss:0.887682552268725\n",
      "train loss:0.9643759045918914\n",
      "train loss:0.9846244930568965\n",
      "train loss:1.0579359681148637\n",
      "train loss:0.8123700383101168\n",
      "train loss:0.7794464814089305\n",
      "train loss:0.7656388713223555\n",
      "train loss:0.8404419874018219\n",
      "train loss:0.9283752779413704\n",
      "train loss:0.7462085249805916\n",
      "train loss:0.8727045893305814\n",
      "train loss:0.9600465635040739\n",
      "train loss:0.710562041030079\n",
      "train loss:1.0551431011100727\n",
      "train loss:0.9526618000877548\n",
      "train loss:0.9404254151585514\n",
      "train loss:0.9979422264782117\n",
      "train loss:1.0177701125203937\n",
      "train loss:0.9671664499374022\n",
      "train loss:1.0085385482770166\n",
      "train loss:0.8347949501004415\n",
      "train loss:0.8960592055152798\n",
      "train loss:0.8696570437485096\n",
      "train loss:0.9903235750482172\n",
      "train loss:0.8625041361006228\n",
      "train loss:0.8274867738367212\n",
      "train loss:0.7996831265510405\n",
      "train loss:0.9241049451316806\n",
      "train loss:1.0854629065781423\n",
      "train loss:0.8782029606908286\n",
      "train loss:0.7129979420591199\n",
      "train loss:0.9203908949984121\n",
      "train loss:1.0777922340150186\n",
      "train loss:0.7597707858481105\n",
      "train loss:1.006440930829842\n",
      "train loss:0.8717896102842739\n",
      "train loss:0.87833700740242\n",
      "train loss:0.8748063684792318\n",
      "train loss:0.8792208269087614\n",
      "train loss:0.8883830878569077\n",
      "train loss:0.7528531617446166\n",
      "train loss:0.7094850244996016\n",
      "train loss:0.9211823835520534\n",
      "train loss:0.825941098067981\n",
      "train loss:0.9170745756575063\n",
      "train loss:0.8192563918030383\n",
      "train loss:0.9446908785654736\n",
      "train loss:0.7783715037780788\n",
      "train loss:0.9861453283353521\n",
      "train loss:1.0309185958184086\n",
      "train loss:0.9129382823782397\n",
      "train loss:1.0505106650962996\n",
      "train loss:0.9442794251487494\n",
      "train loss:0.8956046657243388\n",
      "train loss:0.9718266543828227\n",
      "train loss:0.8222797269166271\n",
      "train loss:0.75403746010973\n",
      "train loss:0.7930959130441678\n",
      "train loss:0.736072693798673\n",
      "train loss:0.8791997893130301\n",
      "train loss:0.7171747829880014\n",
      "train loss:0.9753821041512518\n",
      "train loss:0.868452812335804\n",
      "train loss:1.097957745477805\n",
      "train loss:0.8939005024483145\n",
      "train loss:0.7798679271537782\n",
      "train loss:0.809870119367216\n",
      "train loss:0.9058585900270745\n",
      "train loss:0.7687732711238142\n",
      "train loss:0.8643003918063827\n",
      "train loss:0.9107754087127095\n",
      "train loss:0.842491843555357\n",
      "train loss:1.070483179641535\n",
      "train loss:0.7358890163556407\n",
      "train loss:1.0240910136658412\n",
      "train loss:0.8666112709788767\n",
      "train loss:0.7878943516488031\n",
      "train loss:0.9071862632839535\n",
      "train loss:1.0329805406971218\n",
      "train loss:0.8701335942706545\n",
      "train loss:0.8664001558080194\n",
      "train loss:1.0037253243030648\n",
      "train loss:0.8564625394529678\n",
      "train loss:0.8692380844571106\n",
      "train loss:0.922011355743039\n",
      "train loss:0.8100629569326807\n",
      "train loss:0.9876034945750091\n",
      "train loss:0.7939578014902031\n",
      "train loss:0.9847520614481756\n",
      "train loss:0.8179052471918508\n",
      "train loss:0.801010783106596\n",
      "train loss:0.7749353972396158\n",
      "train loss:0.7378139480726073\n",
      "train loss:0.9135843117329671\n",
      "train loss:0.8704226560447537\n",
      "train loss:0.9198526566930064\n",
      "train loss:0.8458590352722456\n",
      "train loss:0.8957121740196604\n",
      "train loss:0.8235225616156976\n",
      "train loss:0.8715316451353027\n",
      "train loss:0.9069232785852968\n",
      "train loss:0.8606482612958309\n",
      "train loss:0.931190723420394\n",
      "train loss:0.923262728096819\n",
      "train loss:0.9397776294629265\n",
      "train loss:0.7571750989854816\n",
      "train loss:0.874550979679056\n",
      "train loss:0.7606826513602509\n",
      "train loss:0.9364507831003056\n",
      "train loss:1.010386013506229\n",
      "train loss:0.9177130441467911\n",
      "train loss:0.8562588023008476\n",
      "train loss:0.7373015950967171\n",
      "train loss:1.0307823717369293\n",
      "train loss:0.9936870153670333\n",
      "train loss:0.7555208846293273\n",
      "train loss:0.900406787678003\n",
      "train loss:1.030526915374088\n",
      "train loss:0.8545860054650302\n",
      "train loss:0.9182933190931638\n",
      "train loss:0.7362996491117171\n",
      "train loss:0.9939519658449454\n",
      "train loss:0.8107501313445468\n",
      "train loss:0.9696971547949039\n",
      "train loss:0.98426946911314\n",
      "train loss:0.9188647292905823\n",
      "train loss:1.0432802860338592\n",
      "train loss:0.984752875178016\n",
      "train loss:0.9283799348846182\n",
      "train loss:0.7533730059031961\n",
      "train loss:0.8186919059649261\n",
      "train loss:0.7877427855829322\n",
      "train loss:0.8463432902525185\n",
      "train loss:0.8377643434386574\n",
      "train loss:0.799594007586614\n",
      "train loss:0.8244366936288339\n",
      "train loss:0.8495538149526887\n",
      "train loss:0.7744392570521836\n",
      "train loss:0.9350215173501526\n",
      "train loss:0.819703926927401\n",
      "train loss:0.7954887166323117\n",
      "train loss:0.9186309616729538\n",
      "train loss:0.910813705500766\n",
      "train loss:0.8769023702563782\n",
      "train loss:0.8317359839874527\n",
      "train loss:0.7864588730860741\n",
      "train loss:0.8400546836821862\n",
      "train loss:0.8895944741487942\n",
      "train loss:0.6654277761891279\n",
      "train loss:0.8686984045940034\n",
      "train loss:0.7986767119160068\n",
      "train loss:0.7931088873483028\n",
      "train loss:0.9322210103202043\n",
      "train loss:0.8820574498274943\n",
      "train loss:0.8172916054243339\n",
      "train loss:0.8104697280878712\n",
      "train loss:0.852402525564576\n",
      "train loss:1.0321020578581337\n",
      "train loss:1.0126355023240234\n",
      "train loss:0.8884515443885144\n",
      "train loss:0.8782376237467188\n",
      "train loss:0.7738048993401279\n",
      "train loss:0.8675831269381236\n",
      "train loss:0.8360448949237497\n",
      "train loss:1.0452035131248416\n",
      "train loss:0.7909461521578237\n",
      "train loss:0.9810435293501544\n",
      "train loss:0.9419578030889393\n",
      "train loss:0.8652260149646699\n",
      "train loss:0.8364432881222535\n",
      "train loss:0.8827996011889506\n",
      "train loss:0.798683379914805\n",
      "train loss:0.9662721030095056\n",
      "train loss:0.9196639646804178\n",
      "train loss:1.0052098061114254\n",
      "train loss:0.827334923649528\n",
      "train loss:0.866668529806371\n",
      "train loss:0.9104602445847992\n",
      "train loss:0.8843438392692293\n",
      "train loss:0.988271130303708\n",
      "train loss:0.942977297585477\n",
      "train loss:0.9686399199037418\n",
      "train loss:1.0803027870333464\n",
      "train loss:0.8737324233127736\n",
      "train loss:0.8492397091979305\n",
      "train loss:0.9511248338344275\n",
      "train loss:0.8679500890680864\n",
      "train loss:0.9632545225161525\n",
      "train loss:0.8762465220981379\n",
      "train loss:0.9940830476820277\n",
      "train loss:0.9472510367808404\n",
      "train loss:0.920228674535591\n",
      "train loss:0.8815668951033786\n",
      "train loss:0.9134769881927066\n",
      "train loss:0.9181543814075322\n",
      "train loss:1.0725984865597975\n",
      "train loss:0.8685706502830489\n",
      "train loss:1.0559509826074769\n",
      "train loss:0.7669806288462323\n",
      "train loss:1.068328395677062\n",
      "train loss:0.9029199151442733\n",
      "train loss:0.8879447525826913\n",
      "train loss:0.9141953720723592\n",
      "train loss:0.9294852382537414\n",
      "train loss:1.014025661264116\n",
      "train loss:1.0248966393944479\n",
      "train loss:1.087639276186945\n",
      "train loss:0.9630702202943026\n",
      "train loss:0.9701543025089039\n",
      "train loss:0.9859687695072532\n",
      "train loss:0.9381827463227004\n",
      "train loss:0.7821145050922279\n",
      "train loss:0.9573761201197274\n",
      "train loss:0.9092826718450457\n",
      "train loss:0.750867064640755\n",
      "train loss:0.7698639615517245\n",
      "train loss:0.8181510340973505\n",
      "train loss:0.9134846537365773\n",
      "train loss:0.9667211457689834\n",
      "train loss:0.8916779057854582\n",
      "train loss:0.8580583278568311\n",
      "train loss:0.8446799308803707\n",
      "train loss:0.8975123850854753\n",
      "train loss:0.9812873044899303\n",
      "train loss:0.7748948109977395\n",
      "train loss:0.8675366314166382\n",
      "train loss:0.9709014566520651\n",
      "train loss:0.949498709044563\n",
      "train loss:0.8546048180575854\n",
      "train loss:0.6800558465019522\n",
      "train loss:0.8289516401318986\n",
      "train loss:0.863564460277126\n",
      "train loss:0.9348401358374292\n",
      "train loss:0.9156105592989097\n",
      "train loss:0.9199790482329233\n",
      "train loss:0.9008594571935756\n",
      "train loss:0.9655223160877299\n",
      "train loss:0.8413075271470671\n",
      "train loss:0.8308342854021942\n",
      "train loss:1.0754584180150453\n",
      "train loss:0.9755701346920399\n",
      "train loss:0.9422414133147414\n",
      "train loss:1.0573657474739575\n",
      "train loss:1.0341464695041407\n",
      "train loss:0.9125839635641617\n",
      "train loss:0.9070452168967857\n",
      "train loss:0.8364772606063329\n",
      "train loss:0.895410719476357\n",
      "train loss:0.9608510034940353\n",
      "train loss:0.8142437698032964\n",
      "train loss:0.9338545214719438\n",
      "train loss:0.8190475567782756\n",
      "train loss:0.9653924786611559\n",
      "train loss:0.8786859791001314\n",
      "train loss:0.8123276438150253\n",
      "train loss:1.0166066985192377\n",
      "train loss:0.8459831224982274\n",
      "train loss:0.9635479711107986\n",
      "train loss:1.0238182079407074\n",
      "train loss:1.0643993426899088\n",
      "train loss:0.8923141190622332\n",
      "train loss:0.8689263732459551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9471184673578528\n",
      "train loss:0.8725825081438866\n",
      "train loss:0.8396085203587446\n",
      "train loss:0.9251862913650684\n",
      "train loss:0.9598664708899399\n",
      "train loss:0.739356646895294\n",
      "train loss:0.9015189583719965\n",
      "train loss:0.9042352662700479\n",
      "train loss:0.8656227679203955\n",
      "train loss:0.6910898293275928\n",
      "train loss:0.9286016117143866\n",
      "train loss:0.930894540532694\n",
      "train loss:0.8689975979157782\n",
      "train loss:0.936513227167731\n",
      "train loss:0.8853834552849648\n",
      "train loss:0.8802623988372376\n",
      "train loss:0.9028308530027448\n",
      "train loss:0.95442258064807\n",
      "=== epoch:12, train acc:0.994, test acc:0.989 ===\n",
      "train loss:0.734975010874877\n",
      "train loss:1.1365550730804281\n",
      "train loss:0.7722058609965596\n",
      "train loss:0.7341452992820617\n",
      "train loss:0.9283129948265468\n",
      "train loss:0.84383807041426\n",
      "train loss:0.8398107291851707\n",
      "train loss:0.9336178612998637\n",
      "train loss:0.7025254982854373\n",
      "train loss:0.9073516707460559\n",
      "train loss:0.944887692720246\n",
      "train loss:0.7825534615100992\n",
      "train loss:0.8747466750550831\n",
      "train loss:0.7924777680555836\n",
      "train loss:0.7309136411744138\n",
      "train loss:0.8374223949507225\n",
      "train loss:0.9500511233826484\n",
      "train loss:0.7502408746173826\n",
      "train loss:1.0231769815585547\n",
      "train loss:0.8416427315410253\n",
      "train loss:1.0009761938152086\n",
      "train loss:0.9195403225812112\n",
      "train loss:0.8266823450442803\n",
      "train loss:0.8554317312724826\n",
      "train loss:1.008746601439277\n",
      "train loss:0.9426241146397277\n",
      "train loss:0.8916661386775675\n",
      "train loss:0.9339676279674469\n",
      "train loss:0.847296965657275\n",
      "train loss:1.0372851368107643\n",
      "train loss:0.9159574291611006\n",
      "train loss:0.8204392805259505\n",
      "train loss:0.793492233090321\n",
      "train loss:0.8728433080534046\n",
      "train loss:0.7181155605477895\n",
      "train loss:0.8803893644476856\n",
      "train loss:0.9516792147150567\n",
      "train loss:0.8212857502438636\n",
      "train loss:0.8679976592594018\n",
      "train loss:0.9090935849053655\n",
      "train loss:0.9485229745543287\n",
      "train loss:0.9197454814374285\n",
      "train loss:0.8922211796088323\n",
      "train loss:0.8693867134841975\n",
      "train loss:0.6922515125234702\n",
      "train loss:1.0241009324408759\n",
      "train loss:0.8385983374982056\n",
      "train loss:0.9983254331031304\n",
      "train loss:0.9535339816751034\n",
      "train loss:0.8859226275591118\n",
      "train loss:0.8434198209791159\n",
      "train loss:0.729642311644634\n",
      "train loss:0.7467339604635099\n",
      "train loss:0.6876253450907039\n",
      "train loss:0.7331888701586289\n",
      "train loss:0.8319875412538594\n",
      "train loss:0.8882019818665191\n",
      "train loss:1.0486778664378698\n",
      "train loss:0.8963547730531751\n",
      "train loss:0.8168383078853707\n",
      "train loss:0.7922814174736617\n",
      "train loss:0.965608411554972\n",
      "train loss:0.7261381701674986\n",
      "train loss:0.8875164765104764\n",
      "train loss:0.9843102398691507\n",
      "train loss:0.8347995682477369\n",
      "train loss:1.0928512617996144\n",
      "train loss:0.9568275424369628\n",
      "train loss:0.7540190451886967\n",
      "train loss:0.9311828779637112\n",
      "train loss:0.9480760230743595\n",
      "train loss:0.8326179407972961\n",
      "train loss:0.8293607915313614\n",
      "train loss:0.9349399835435895\n",
      "train loss:1.0061634789148066\n",
      "train loss:0.7152816502748327\n",
      "train loss:0.8686657934031049\n",
      "train loss:0.7585024206121392\n",
      "train loss:0.8396584285218174\n",
      "train loss:0.7624091327100451\n",
      "train loss:0.8822153338711793\n",
      "train loss:0.8016209601315731\n",
      "train loss:0.913051328413602\n",
      "train loss:0.8330204522246539\n",
      "train loss:0.9431496347233528\n",
      "train loss:0.8333572267274417\n",
      "train loss:0.8440309941513803\n",
      "train loss:0.9205107434708681\n",
      "train loss:1.0130939884331418\n",
      "train loss:0.8956395424369913\n",
      "train loss:0.8486767010837277\n",
      "train loss:0.9000121637008063\n",
      "train loss:0.8937843372808121\n",
      "train loss:0.8139085119237786\n",
      "train loss:0.8913441319972507\n",
      "train loss:0.6814229326132266\n",
      "train loss:0.7991001930572851\n",
      "train loss:0.8245819651836335\n",
      "train loss:0.7281551983192418\n",
      "train loss:1.0489860415171182\n",
      "train loss:0.7932667600571419\n",
      "train loss:0.8569344276579584\n",
      "train loss:0.727331642847862\n",
      "train loss:0.8123188806044621\n",
      "train loss:1.0002155590025361\n",
      "train loss:0.6900985943128483\n",
      "train loss:0.8928573600627436\n",
      "train loss:0.7877829351880034\n",
      "train loss:1.0538051924429828\n",
      "train loss:1.0240918926937335\n",
      "train loss:0.8331353408069707\n",
      "train loss:0.6899059663644442\n",
      "train loss:0.9340874543070886\n",
      "train loss:0.9179575434116678\n",
      "train loss:1.028781321561633\n",
      "train loss:0.9609246711298689\n",
      "train loss:0.8732955143368344\n",
      "train loss:1.0185181876469245\n",
      "train loss:0.9501983894596229\n",
      "train loss:0.7901545215616145\n",
      "train loss:0.8477692742787708\n",
      "train loss:0.8865935330904464\n",
      "train loss:0.8143197866309001\n",
      "train loss:0.9140127173890275\n",
      "train loss:0.8477125569584888\n",
      "train loss:0.8987452550568572\n",
      "train loss:0.9552666750209879\n",
      "train loss:0.9086552686690255\n",
      "train loss:0.9465054204736384\n",
      "train loss:0.7187748517363732\n",
      "train loss:0.8118608239298442\n",
      "train loss:0.9098794465824845\n",
      "train loss:0.9991473718799391\n",
      "train loss:0.8544791082187599\n",
      "train loss:0.7794321750498027\n",
      "train loss:0.952733850798129\n",
      "train loss:0.8595664160938871\n",
      "train loss:0.835418874651557\n",
      "train loss:0.7964228410698165\n",
      "train loss:0.8665458876094282\n",
      "train loss:1.034037569544828\n",
      "train loss:0.9721037946037839\n",
      "train loss:0.9449172771287294\n",
      "train loss:1.0675823754445335\n",
      "train loss:0.8588505963132476\n",
      "train loss:0.8524783762542443\n",
      "train loss:0.7636349623316145\n",
      "train loss:0.8385420578723264\n",
      "train loss:0.86981203760492\n",
      "train loss:0.6470729432541431\n",
      "train loss:0.8841951141784284\n",
      "train loss:0.9508380157880173\n",
      "train loss:0.834062340214979\n",
      "train loss:0.7748293584048637\n",
      "train loss:0.8952946784953764\n",
      "train loss:0.7986907702781875\n",
      "train loss:0.7816002344731529\n",
      "train loss:0.9362121254257442\n",
      "train loss:0.931853077223743\n",
      "train loss:0.8711609142188661\n",
      "train loss:0.9524292083070576\n",
      "train loss:0.9192312700650984\n",
      "train loss:0.6711792002251156\n",
      "train loss:0.9376481482845747\n",
      "train loss:0.8015855300657883\n",
      "train loss:0.9764869638276451\n",
      "train loss:0.6732616082658435\n",
      "train loss:0.6737107240545577\n",
      "train loss:0.9568122964702682\n",
      "train loss:0.9305481761208462\n",
      "train loss:0.8653529973333086\n",
      "train loss:0.7840635116040449\n",
      "train loss:0.848559678432754\n",
      "train loss:0.8136767305608436\n",
      "train loss:0.8751012022701462\n",
      "train loss:1.0464227357747868\n",
      "train loss:0.7416691822454541\n",
      "train loss:0.934557653964932\n",
      "train loss:0.8446641366544347\n",
      "train loss:0.8936985993338147\n",
      "train loss:0.7064758238978374\n",
      "train loss:0.7744637207568499\n",
      "train loss:0.8790804736321314\n",
      "train loss:0.7173850279846247\n",
      "train loss:0.964668030614816\n",
      "train loss:0.8555174195365594\n",
      "train loss:0.8052515045459004\n",
      "train loss:0.8823652452320618\n",
      "train loss:0.8663228416385215\n",
      "train loss:0.942395579221614\n",
      "train loss:0.8370809241921003\n",
      "train loss:0.732044387618535\n",
      "train loss:0.8879343505274698\n",
      "train loss:0.8610672603023931\n",
      "train loss:1.0537517616051575\n",
      "train loss:0.9028859420877805\n",
      "train loss:0.9687751304304423\n",
      "train loss:0.7728394830200075\n",
      "train loss:0.9714331948141773\n",
      "train loss:0.715048804402467\n",
      "train loss:0.9760597206220916\n",
      "train loss:0.7753818029692893\n",
      "train loss:0.8555032822429327\n",
      "train loss:1.018372349089151\n",
      "train loss:0.8434967455645445\n",
      "train loss:1.1455180735478316\n",
      "train loss:1.058623233935436\n",
      "train loss:0.7860949339097073\n",
      "train loss:0.8589912307381691\n",
      "train loss:0.7633720697359654\n",
      "train loss:0.6839626921953296\n",
      "train loss:0.758792501029219\n",
      "train loss:1.1289900730923472\n",
      "train loss:0.8485002250090371\n",
      "train loss:0.7421544845952517\n",
      "train loss:0.9622868576650718\n",
      "train loss:0.9518633430435659\n",
      "train loss:0.9062670060959553\n",
      "train loss:1.0438540753437011\n",
      "train loss:0.9325531555875753\n",
      "train loss:0.9160938933419343\n",
      "train loss:0.9569488481784056\n",
      "train loss:0.9707476031325912\n",
      "train loss:0.910528724498397\n",
      "train loss:0.7510286298829848\n",
      "train loss:0.87008844463641\n",
      "train loss:0.9462479201730757\n",
      "train loss:0.887673850464637\n",
      "train loss:0.8965372151671351\n",
      "train loss:0.8197657801868499\n",
      "train loss:0.7301900303229146\n",
      "train loss:0.7591329752453296\n",
      "train loss:0.83508876868334\n",
      "train loss:0.8982711624526648\n",
      "train loss:1.0357493340647383\n",
      "train loss:0.8135627151946392\n",
      "train loss:1.017460010033066\n",
      "train loss:0.8659343936160316\n",
      "train loss:0.9191767386988171\n",
      "train loss:1.0183028427363543\n",
      "train loss:0.9278687292629577\n",
      "train loss:0.908358301887285\n",
      "train loss:0.9027732377445576\n",
      "train loss:1.0016428346577755\n",
      "train loss:1.0205828722992891\n",
      "train loss:0.8741026001235572\n",
      "train loss:0.8079574359252235\n",
      "train loss:0.9770059883598162\n",
      "train loss:0.7737439730253353\n",
      "train loss:0.8356826356621787\n",
      "train loss:0.8388854503671359\n",
      "train loss:1.0910845355875864\n",
      "train loss:0.8707129779189613\n",
      "train loss:0.8812451317762935\n",
      "train loss:0.8519521290390203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8260637102733642\n",
      "train loss:0.9310941368457826\n",
      "train loss:0.8140903276060295\n",
      "train loss:0.8605504865839022\n",
      "train loss:0.8102943399501696\n",
      "train loss:0.9817197912510852\n",
      "train loss:0.6862755682307646\n",
      "train loss:0.9320752182250845\n",
      "train loss:0.9772495038030289\n",
      "train loss:1.083497928555019\n",
      "train loss:0.8437664318168315\n",
      "train loss:0.8942196189861705\n",
      "train loss:0.7728392772056688\n",
      "train loss:0.8245451632050045\n",
      "train loss:1.0274768412017448\n",
      "train loss:0.8432532588054523\n",
      "train loss:0.9671841259792768\n",
      "train loss:0.9285411641389709\n",
      "train loss:0.8339350700871383\n",
      "train loss:0.9095537131853046\n",
      "train loss:0.7910153696686466\n",
      "train loss:0.8653106188316118\n",
      "train loss:0.9555844452967392\n",
      "train loss:0.8611316094410971\n",
      "train loss:0.8755358685851362\n",
      "train loss:0.7551283368998721\n",
      "train loss:0.7511996110481506\n",
      "train loss:0.7766443578404213\n",
      "train loss:0.9163748386261227\n",
      "train loss:1.006246061429674\n",
      "train loss:0.7806579800478782\n",
      "train loss:0.8867633888695459\n",
      "train loss:0.9374356784824159\n",
      "train loss:0.8892150717998433\n",
      "train loss:0.8637966397002839\n",
      "train loss:0.812667233073195\n",
      "train loss:0.8771516179439938\n",
      "train loss:0.9307457244482902\n",
      "train loss:0.8803417514210071\n",
      "train loss:0.8420413823785019\n",
      "train loss:0.9435272958892255\n",
      "train loss:0.9435364452970325\n",
      "train loss:0.998018958362465\n",
      "train loss:0.994081863005257\n",
      "train loss:1.056362674893762\n",
      "train loss:0.9040625903369701\n",
      "train loss:0.7879318446300649\n",
      "train loss:0.7619112790409451\n",
      "train loss:0.9048513024523279\n",
      "train loss:0.8818684675227486\n",
      "train loss:0.8488964872495158\n",
      "train loss:0.6890813176424408\n",
      "train loss:0.85213456196386\n",
      "train loss:0.9920863161393281\n",
      "train loss:0.8370476519791488\n",
      "train loss:0.7116721838820923\n",
      "train loss:0.9295908156393662\n",
      "train loss:0.8324410334799169\n",
      "train loss:0.8063603323262702\n",
      "train loss:1.0838043909730857\n",
      "train loss:0.8203028701830881\n",
      "train loss:0.9058568357399097\n",
      "train loss:0.9231972669023686\n",
      "train loss:0.8520584806362842\n",
      "train loss:0.9017928404565078\n",
      "train loss:0.7262162211851897\n",
      "train loss:0.9893827700790103\n",
      "train loss:0.9161448895787078\n",
      "train loss:0.7438406846591188\n",
      "train loss:0.9521661347881749\n",
      "train loss:0.8424450299378027\n",
      "train loss:0.8152121641861629\n",
      "train loss:0.8928751333303652\n",
      "train loss:0.772222081335609\n",
      "train loss:0.8693064756598227\n",
      "train loss:0.6827786642764078\n",
      "train loss:0.9164648465583499\n",
      "train loss:0.8572672102515279\n",
      "train loss:0.8102406731275182\n",
      "train loss:0.8458694490497212\n",
      "train loss:0.97999038256159\n",
      "train loss:0.90832852273611\n",
      "train loss:1.0128308115374132\n",
      "train loss:0.8714118300400058\n",
      "train loss:0.9462788320197449\n",
      "train loss:0.6964324621308734\n",
      "train loss:1.006781573433961\n",
      "train loss:0.8538158819144255\n",
      "train loss:0.8940254842306959\n",
      "train loss:0.9120844029437225\n",
      "train loss:0.8819242252531176\n",
      "train loss:0.7404474209013161\n",
      "train loss:0.9530468829395982\n",
      "train loss:0.7478749095238362\n",
      "train loss:0.7667450275709433\n",
      "train loss:0.990944904588719\n",
      "train loss:1.0068788681889542\n",
      "train loss:0.8918235261534072\n",
      "train loss:0.9172131815423262\n",
      "train loss:0.8709899561773963\n",
      "train loss:0.7281099360982776\n",
      "train loss:0.8379822623534215\n",
      "train loss:1.1212944983265378\n",
      "train loss:0.9160260305495068\n",
      "train loss:0.6838869203983471\n",
      "train loss:0.920293532994419\n",
      "train loss:0.7429432928920214\n",
      "train loss:0.870783436130787\n",
      "train loss:0.9129376665616842\n",
      "train loss:0.8072573469722443\n",
      "train loss:0.785614397326683\n",
      "train loss:0.685114136964153\n",
      "train loss:0.9261029868526468\n",
      "train loss:0.8066809680666439\n",
      "train loss:0.8785969929811773\n",
      "train loss:0.9054528095046264\n",
      "train loss:0.8650847834210685\n",
      "train loss:0.7996492554235094\n",
      "train loss:0.8886143240839965\n",
      "train loss:0.7276611252377079\n",
      "train loss:0.779077779324563\n",
      "train loss:0.8676378187066516\n",
      "train loss:0.8529914779386201\n",
      "train loss:0.9979502440103638\n",
      "train loss:1.0117792796045475\n",
      "train loss:0.8191179128080567\n",
      "train loss:0.9332176957703773\n",
      "train loss:0.8492368494624452\n",
      "train loss:0.8887501657745641\n",
      "train loss:0.7826650755025054\n",
      "train loss:0.8511547081483706\n",
      "train loss:0.8965758451224706\n",
      "train loss:0.8469676133799731\n",
      "train loss:0.7320896495812766\n",
      "train loss:0.8942882755612378\n",
      "train loss:0.8860960127187544\n",
      "train loss:0.9733710334481452\n",
      "train loss:0.8436504454410861\n",
      "train loss:0.7605858706947879\n",
      "train loss:0.8525289897273833\n",
      "train loss:0.7658763851137792\n",
      "train loss:0.7360489786790454\n",
      "train loss:0.887309412679727\n",
      "train loss:0.8900239526255621\n",
      "train loss:0.8770945167264114\n",
      "train loss:0.8551677168764448\n",
      "train loss:1.0039904520474758\n",
      "train loss:0.8247379613358298\n",
      "train loss:0.782788715672358\n",
      "train loss:0.7410530646524655\n",
      "train loss:1.0116596644242082\n",
      "train loss:0.8863777390674753\n",
      "train loss:0.739766547569101\n",
      "train loss:0.942244459008437\n",
      "train loss:0.8944757990037\n",
      "train loss:0.9103711272547926\n",
      "train loss:0.8044959715428598\n",
      "train loss:0.8374957337488269\n",
      "train loss:1.031171666581289\n",
      "train loss:0.8563637533031246\n",
      "train loss:0.9520554794723366\n",
      "train loss:0.9011307322525941\n",
      "train loss:0.8294086169495413\n",
      "train loss:0.8552943402078489\n",
      "train loss:1.0156101824484296\n",
      "train loss:0.8216232742967378\n",
      "train loss:0.8213273637801635\n",
      "train loss:0.8901795732802049\n",
      "train loss:0.9681840935607007\n",
      "train loss:0.9979239832576904\n",
      "train loss:0.7680811946623872\n",
      "train loss:0.8542411882948103\n",
      "train loss:0.7118477848966953\n",
      "train loss:0.8661637460258944\n",
      "train loss:0.8710951361976176\n",
      "train loss:0.9849704559477486\n",
      "train loss:1.1348798890836012\n",
      "train loss:0.8121102310223614\n",
      "train loss:0.9138285104756873\n",
      "train loss:0.8129027412302174\n",
      "train loss:1.059031362127705\n",
      "train loss:0.8180237321133756\n",
      "train loss:0.8381361029060388\n",
      "train loss:0.9776977063649669\n",
      "train loss:0.8766474816741691\n",
      "train loss:0.9090072687368433\n",
      "train loss:0.843196572419851\n",
      "train loss:0.8821610138479216\n",
      "train loss:0.8629327062995782\n",
      "train loss:0.836428195094454\n",
      "train loss:0.8684486492882675\n",
      "train loss:0.7523967395222593\n",
      "train loss:1.028020245331601\n",
      "train loss:0.8129016596120016\n",
      "train loss:0.9261578968389802\n",
      "train loss:1.0277347310757272\n",
      "train loss:0.8841401895205498\n",
      "train loss:1.0026322161545864\n",
      "train loss:0.9240777760125745\n",
      "train loss:0.7816103745252788\n",
      "train loss:0.8600542010754441\n",
      "train loss:0.7011872590348301\n",
      "train loss:0.8396047580604961\n",
      "train loss:0.8316367658574473\n",
      "train loss:0.9536008232111939\n",
      "train loss:0.7982473075050313\n",
      "train loss:0.7558653367394444\n",
      "train loss:0.8802137889087844\n",
      "train loss:0.8622071283218244\n",
      "train loss:1.0163028270524002\n",
      "train loss:0.9257773006298889\n",
      "train loss:0.8433099811240383\n",
      "train loss:0.8037288763173683\n",
      "train loss:0.8110320400270403\n",
      "train loss:0.8061953020791865\n",
      "train loss:0.8112501812750296\n",
      "train loss:0.7450816159921985\n",
      "train loss:0.8640344829667558\n",
      "train loss:0.8600855340838066\n",
      "train loss:0.9314599916470314\n",
      "train loss:0.9326815957027326\n",
      "train loss:0.8048200052161718\n",
      "train loss:0.8291696090005368\n",
      "train loss:0.7583109225510595\n",
      "train loss:0.7773388442640932\n",
      "train loss:0.8602205248559762\n",
      "train loss:0.8054220488471863\n",
      "train loss:0.8732081332550437\n",
      "train loss:0.8095535427054501\n",
      "train loss:0.9972461851447008\n",
      "train loss:0.9774447919565603\n",
      "train loss:0.873561671350243\n",
      "train loss:0.9685173253230377\n",
      "train loss:0.6918090420571992\n",
      "train loss:0.8016934043890225\n",
      "train loss:0.7138308492112648\n",
      "train loss:0.9881120958631715\n",
      "train loss:0.8031077830737766\n",
      "train loss:0.6774660309795092\n",
      "train loss:0.896356682974703\n",
      "train loss:0.9335347920653712\n",
      "train loss:0.7553971461491676\n",
      "train loss:0.7791671416839457\n",
      "train loss:0.9413567576643014\n",
      "train loss:0.8717600240124739\n",
      "train loss:0.9718287265271813\n",
      "train loss:0.9193389819390088\n",
      "train loss:0.8007836875868282\n",
      "train loss:0.8749200571854585\n",
      "train loss:0.9699099095100244\n",
      "train loss:0.8240027836392275\n",
      "train loss:0.6912166040520017\n",
      "train loss:0.8708521116296492\n",
      "train loss:0.8376376512237154\n",
      "train loss:0.703437145828413\n",
      "train loss:0.8075963253613158\n",
      "train loss:0.9527855836318504\n",
      "train loss:0.7826006024792725\n",
      "train loss:1.0092730187625845\n",
      "train loss:0.8769372907161089\n",
      "train loss:0.8526681727760108\n",
      "train loss:0.8589338367677464\n",
      "train loss:1.0370764594518416\n",
      "train loss:0.9266633443187664\n",
      "train loss:0.8643243611239575\n",
      "train loss:0.791313092137496\n",
      "train loss:0.8446042657726796\n",
      "train loss:0.841991426742815\n",
      "train loss:0.8708544794206413\n",
      "train loss:0.9796896718570237\n",
      "train loss:0.9477590408219416\n",
      "train loss:1.085156592567493\n",
      "train loss:0.9468522985576432\n",
      "train loss:0.8992280794029938\n",
      "train loss:0.9592408117769515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.907990793003379\n",
      "train loss:0.865495630933409\n",
      "train loss:0.8267132864792771\n",
      "train loss:0.8228074450086389\n",
      "train loss:1.1030191586814213\n",
      "train loss:0.7805951237604668\n",
      "train loss:0.9424490042854162\n",
      "train loss:0.8717188232129276\n",
      "train loss:0.9623528920864927\n",
      "train loss:0.826232445620536\n",
      "train loss:0.9748519130672437\n",
      "train loss:0.8225406653910404\n",
      "train loss:0.9120668886862235\n",
      "train loss:0.8697967406547353\n",
      "train loss:0.7107902582810145\n",
      "train loss:0.9090877292101933\n",
      "train loss:0.9549200694483001\n",
      "train loss:0.8342492656040027\n",
      "train loss:0.8576640966003722\n",
      "train loss:1.0044652246893166\n",
      "train loss:0.925780780890589\n",
      "train loss:0.6977253279136033\n",
      "train loss:0.7813453446934854\n",
      "train loss:0.937883372914264\n",
      "train loss:0.8842173730974777\n",
      "train loss:0.8831509647887971\n",
      "train loss:0.7665450822564055\n",
      "train loss:0.8067011885369172\n",
      "train loss:0.9650295659275986\n",
      "train loss:0.8226129562638311\n",
      "train loss:0.9614117855259876\n",
      "train loss:0.835938316022339\n",
      "train loss:0.9116331039467583\n",
      "train loss:0.7825974480801716\n",
      "train loss:0.8944986108671611\n",
      "train loss:0.8049809783075116\n",
      "train loss:1.0625195962136882\n",
      "train loss:0.9950063504406883\n",
      "train loss:0.8277225967747108\n",
      "train loss:0.8341720505594498\n",
      "train loss:0.9198199519493852\n",
      "train loss:0.8482667426999998\n",
      "train loss:0.7431134204961518\n",
      "train loss:0.8582505138151049\n",
      "train loss:0.8545989783427876\n",
      "train loss:0.995536437515013\n",
      "train loss:0.8340097381328205\n",
      "train loss:0.7733002314154304\n",
      "train loss:0.8476435666340761\n",
      "train loss:1.016775759742583\n",
      "train loss:0.8634355559158645\n",
      "train loss:0.8780690618658038\n",
      "train loss:0.8797787419142712\n",
      "train loss:1.0224283792370246\n",
      "train loss:0.8833780860786221\n",
      "train loss:0.8640773036499679\n",
      "train loss:0.8422184279906003\n",
      "train loss:0.9944934519975785\n",
      "train loss:0.8685516611773484\n",
      "train loss:0.831566120587861\n",
      "train loss:0.818694971121064\n",
      "train loss:0.9457244471471098\n",
      "train loss:1.0204295077351884\n",
      "train loss:0.979000922341259\n",
      "train loss:0.9128327232363793\n",
      "train loss:0.7758768278494371\n",
      "train loss:0.792343736228074\n",
      "train loss:0.939866919686431\n",
      "train loss:0.8347695204218101\n",
      "train loss:0.8730686934220858\n",
      "=== epoch:13, train acc:0.999, test acc:0.992 ===\n",
      "train loss:0.6983340655809657\n",
      "train loss:0.9028203173447795\n",
      "train loss:0.8586372567568087\n",
      "train loss:0.8939204524684914\n",
      "train loss:0.7669386630877313\n",
      "train loss:0.7498056007823416\n",
      "train loss:0.8234396027902829\n",
      "train loss:0.9643667255623241\n",
      "train loss:0.9113031298502164\n",
      "train loss:0.7354276303943186\n",
      "train loss:0.9303470085367651\n",
      "train loss:0.8088024665526489\n",
      "train loss:0.8894765672066528\n",
      "train loss:0.850192476056342\n",
      "train loss:0.9022557563638866\n",
      "train loss:1.0119611596693086\n",
      "train loss:0.8651427765563696\n",
      "train loss:0.8639963155600239\n",
      "train loss:0.9650156664242283\n",
      "train loss:0.7561297219895999\n",
      "train loss:0.798592563826\n",
      "train loss:0.8400820261046944\n",
      "train loss:0.7572049597193794\n",
      "train loss:0.7732802931558108\n",
      "train loss:0.8090821870719733\n",
      "train loss:1.0204817463314335\n",
      "train loss:0.8692938057430921\n",
      "train loss:0.8280395963041794\n",
      "train loss:0.8125679829033049\n",
      "train loss:0.7925966191007965\n",
      "train loss:0.9344668885835449\n",
      "train loss:0.9057943589809936\n",
      "train loss:0.7780336342142027\n",
      "train loss:0.9807152084893512\n",
      "train loss:0.8662806239691241\n",
      "train loss:0.8869107617607834\n",
      "train loss:0.7984632061332165\n",
      "train loss:0.8451614169684782\n",
      "train loss:0.7945138867258773\n",
      "train loss:0.9342205635825087\n",
      "train loss:0.9082835335265949\n",
      "train loss:0.8986925502233817\n",
      "train loss:0.8862269300009133\n",
      "train loss:0.9184084066284512\n",
      "train loss:1.07775673745163\n",
      "train loss:0.9082903715722779\n",
      "train loss:0.8735525618008968\n",
      "train loss:0.8781067191832954\n",
      "train loss:0.9512415379325231\n",
      "train loss:0.8751525698930134\n",
      "train loss:0.9174299093458385\n",
      "train loss:0.9410186505349319\n",
      "train loss:0.8286057417768644\n",
      "train loss:0.7887068260703768\n",
      "train loss:0.9113775693557373\n",
      "train loss:0.9814584250527113\n",
      "train loss:0.7020906810442894\n",
      "train loss:0.907520449636839\n",
      "train loss:0.9731556943118097\n",
      "train loss:0.933625264421556\n",
      "train loss:0.8102225110357887\n",
      "train loss:0.8675835243126078\n",
      "train loss:0.8873677128441376\n",
      "train loss:0.9401122037953417\n",
      "train loss:0.8847589266009108\n",
      "train loss:0.9373275031331403\n",
      "train loss:0.8689010797134599\n",
      "train loss:1.0573732477648177\n",
      "train loss:0.8779828708180178\n",
      "train loss:0.8517779700541566\n",
      "train loss:0.9312613976184038\n",
      "train loss:0.8412237399662097\n",
      "train loss:0.6785085766839393\n",
      "train loss:0.776195666738804\n",
      "train loss:0.8725359487083502\n",
      "train loss:0.9382925897863548\n",
      "train loss:0.9474327573606012\n",
      "train loss:0.8312610158164788\n",
      "train loss:1.0886252722940006\n",
      "train loss:0.9501931670133282\n",
      "train loss:0.7493170065323046\n",
      "train loss:0.9847440179391515\n",
      "train loss:0.8464186154403904\n",
      "train loss:1.024665491868895\n",
      "train loss:0.8297569716613696\n",
      "train loss:0.8025746818887187\n",
      "train loss:0.913945391329976\n",
      "train loss:0.8542947296995641\n",
      "train loss:0.863054424775881\n",
      "train loss:0.7587151195551383\n",
      "train loss:0.9400689843620914\n",
      "train loss:0.8915634265620365\n",
      "train loss:0.7771262112393168\n",
      "train loss:0.9095291208632402\n",
      "train loss:0.7968267267500206\n",
      "train loss:0.9149334431013046\n",
      "train loss:0.8653669189419096\n",
      "train loss:0.7529256350051425\n",
      "train loss:0.7787406543782981\n",
      "train loss:0.8921590548046562\n",
      "train loss:0.765110313991444\n",
      "train loss:0.9417330349418891\n",
      "train loss:0.746612749599668\n",
      "train loss:0.8232791606433761\n",
      "train loss:0.9391847985444014\n",
      "train loss:0.915686226318591\n",
      "train loss:0.9067834613056376\n",
      "train loss:0.8816713131878855\n",
      "train loss:0.8425781278921924\n",
      "train loss:0.8164618180174402\n",
      "train loss:0.9205701205399923\n",
      "train loss:1.0618344098023116\n",
      "train loss:0.6878994879918217\n",
      "train loss:0.9437985095154179\n",
      "train loss:0.8179433429189613\n",
      "train loss:0.9973021445015868\n",
      "train loss:1.0130406317759932\n",
      "train loss:0.8940528059288081\n",
      "train loss:0.9017845280733785\n",
      "train loss:1.1029167993845446\n",
      "train loss:0.9758330743634392\n",
      "train loss:0.8842780627718285\n",
      "train loss:0.8776999358401024\n",
      "train loss:0.818304932248298\n",
      "train loss:0.8797899595800629\n",
      "train loss:1.040374719330068\n",
      "train loss:1.0775607059259653\n",
      "train loss:0.8320475709584855\n",
      "train loss:0.8713157959298422\n",
      "train loss:0.823080459703048\n",
      "train loss:0.8204030446480634\n",
      "train loss:0.8096290931048955\n",
      "train loss:0.7450972299293127\n",
      "train loss:0.8762559166667393\n",
      "train loss:0.893824355236093\n",
      "train loss:0.9129800543752548\n",
      "train loss:0.8146695116490945\n",
      "train loss:0.9261583865826748\n",
      "train loss:0.9655733558093987\n",
      "train loss:0.9443838746869462\n",
      "train loss:0.8120369693829583\n",
      "train loss:0.7070538856232355\n",
      "train loss:0.9922676633908495\n",
      "train loss:0.7643839623628901\n",
      "train loss:1.1035148555646839\n",
      "train loss:0.7505191371525293\n",
      "train loss:0.9284779177885701\n",
      "train loss:0.8892265576293081\n",
      "train loss:0.7926201240915638\n",
      "train loss:0.9620877305235269\n",
      "train loss:0.8309515257991065\n",
      "train loss:0.9675101803073436\n",
      "train loss:0.8199699009564162\n",
      "train loss:0.7757891365992299\n",
      "train loss:0.778213081468571\n",
      "train loss:0.9614254561343709\n",
      "train loss:0.7348371790419157\n",
      "train loss:0.8313949185038421\n",
      "train loss:0.8476678776619683\n",
      "train loss:0.8569098253198097\n",
      "train loss:0.9822414122078743\n",
      "train loss:0.8684976430881101\n",
      "train loss:0.9582302729714871\n",
      "train loss:0.8396489429643934\n",
      "train loss:0.9545196638943473\n",
      "train loss:0.9214363487514047\n",
      "train loss:0.8894998393571654\n",
      "train loss:0.6806458737279648\n",
      "train loss:0.8182273643365954\n",
      "train loss:0.9874919760799417\n",
      "train loss:0.9132964249657296\n",
      "train loss:0.7826995298341408\n",
      "train loss:0.8639724389286608\n",
      "train loss:0.8881466370679901\n",
      "train loss:0.7208995656957415\n",
      "train loss:0.9686665253257314\n",
      "train loss:0.7275136999349838\n",
      "train loss:0.8232100686568156\n",
      "train loss:0.8196952581957082\n",
      "train loss:0.8347109672013744\n",
      "train loss:0.9253262403677439\n",
      "train loss:0.908948255759415\n",
      "train loss:1.0308108605333195\n",
      "train loss:0.7777962190691694\n",
      "train loss:0.7540485294785527\n",
      "train loss:0.7685281593461246\n",
      "train loss:0.9200856225111497\n",
      "train loss:0.8434638078123073\n",
      "train loss:0.7796547690582156\n",
      "train loss:0.8106117964880576\n",
      "train loss:0.8519547569788546\n",
      "train loss:0.7421451092792605\n",
      "train loss:0.9478152887294626\n",
      "train loss:0.8130353498432892\n",
      "train loss:0.8088381497898108\n",
      "train loss:0.851519698285227\n",
      "train loss:0.9020863470475362\n",
      "train loss:0.8821194828768333\n",
      "train loss:0.8624181969291063\n",
      "train loss:0.8582088115465645\n",
      "train loss:0.9530951096485584\n",
      "train loss:1.0222399216052442\n",
      "train loss:1.012251981906219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0127077883504787\n",
      "train loss:0.9384484010576785\n",
      "train loss:1.1261630817124217\n",
      "train loss:0.8699337583215643\n",
      "train loss:0.8248372041604044\n",
      "train loss:0.906656627282505\n",
      "train loss:0.8447304042190492\n",
      "train loss:0.8059812382072233\n",
      "train loss:0.8592915088832436\n",
      "train loss:0.8780830186360501\n",
      "train loss:0.9308513247292641\n",
      "train loss:0.9351004566783381\n",
      "train loss:0.766919315236258\n",
      "train loss:0.99496642428389\n",
      "train loss:0.9701970735312596\n",
      "train loss:0.9867378120059733\n",
      "train loss:0.7168376370356586\n",
      "train loss:0.9196435576400048\n",
      "train loss:0.957561032529928\n",
      "train loss:0.8898784358119957\n",
      "train loss:0.9671762117761595\n",
      "train loss:1.1692802651366625\n",
      "train loss:1.010066202513225\n",
      "train loss:0.8432554758261149\n",
      "train loss:0.9642012872494253\n",
      "train loss:0.8139267723587739\n",
      "train loss:0.942328138530732\n",
      "train loss:0.8616431477383862\n",
      "train loss:1.1553530891339656\n",
      "train loss:0.858988248212481\n",
      "train loss:0.8892249931670082\n",
      "train loss:0.9791295616177674\n",
      "train loss:0.8577181230538286\n",
      "train loss:0.6736752069615902\n",
      "train loss:0.837884789693727\n",
      "train loss:0.9686747354711643\n",
      "train loss:0.770566285560364\n",
      "train loss:0.8519273423907616\n",
      "train loss:0.697322661052387\n",
      "train loss:0.7970601224338081\n",
      "train loss:0.8814333173586831\n",
      "train loss:0.8333544616355708\n",
      "train loss:0.7292792544674511\n",
      "train loss:0.926655086297497\n",
      "train loss:0.9678319855667306\n",
      "train loss:0.9440875941484822\n",
      "train loss:0.9862982121722906\n",
      "train loss:0.8472454933567959\n",
      "train loss:0.78014476623626\n",
      "train loss:1.0621333009515237\n",
      "train loss:0.8869911110184348\n",
      "train loss:0.6747049524081222\n",
      "train loss:0.8218730487272776\n",
      "train loss:0.7684608031259521\n",
      "train loss:0.9463985258221373\n",
      "train loss:0.9257226304965209\n",
      "train loss:0.954123604032695\n",
      "train loss:1.0848762003109613\n",
      "train loss:0.8546890142405417\n",
      "train loss:0.8222392187956639\n",
      "train loss:0.9235349193287715\n",
      "train loss:0.8012205778466551\n",
      "train loss:1.0811624152056938\n",
      "train loss:0.8571577714966925\n",
      "train loss:0.7436992601033977\n",
      "train loss:0.8122366867196769\n",
      "train loss:0.9383430333731363\n",
      "train loss:0.7733940772487365\n",
      "train loss:0.8044680725443364\n",
      "train loss:0.8728704163494106\n",
      "train loss:0.8606383863053071\n",
      "train loss:0.9367767693035302\n",
      "train loss:0.6708338147707343\n",
      "train loss:0.7366434193857441\n",
      "train loss:0.8455844451464886\n",
      "train loss:0.7963290358815557\n",
      "train loss:0.8885348598199052\n",
      "train loss:0.8624630428117003\n",
      "train loss:0.9384734065676907\n",
      "train loss:0.8504990717690837\n",
      "train loss:0.7914736312686417\n",
      "train loss:0.936454044896959\n",
      "train loss:0.81325198056101\n",
      "train loss:0.8484291221056387\n",
      "train loss:0.8852221134044299\n",
      "train loss:0.7302768855144715\n",
      "train loss:0.8650135956472443\n",
      "train loss:0.7584886908596035\n",
      "train loss:0.9534753261920206\n",
      "train loss:1.0837570504402227\n",
      "train loss:0.7068171513580309\n",
      "train loss:0.8086230731210755\n",
      "train loss:1.0246375831431709\n",
      "train loss:0.7764123161212663\n",
      "train loss:0.8930833581205949\n",
      "train loss:0.9555801822484016\n",
      "train loss:0.8443620601276868\n",
      "train loss:1.1566650629833541\n",
      "train loss:0.8840825956274734\n",
      "train loss:0.7987153136330539\n",
      "train loss:0.9520889207180283\n",
      "train loss:0.8319940378684564\n",
      "train loss:0.8715547204908574\n",
      "train loss:1.020753683554204\n",
      "train loss:0.7424407955466212\n",
      "train loss:0.9919589977293102\n",
      "train loss:1.125197485015449\n",
      "train loss:0.7232404376250724\n",
      "train loss:0.8454905194810552\n",
      "train loss:0.7184122332615247\n",
      "train loss:0.8580684863614764\n",
      "train loss:0.7403613008399462\n",
      "train loss:0.7955918462135889\n",
      "train loss:0.6638409774708502\n",
      "train loss:0.8584394540720052\n",
      "train loss:0.9413240956814154\n",
      "train loss:1.0259160779990837\n",
      "train loss:0.7137099632719875\n",
      "train loss:0.8463585537015994\n",
      "train loss:0.8326636075840195\n",
      "train loss:0.8638537200363544\n",
      "train loss:0.9100524464392575\n",
      "train loss:0.8999576481724094\n",
      "train loss:0.8241518748597225\n",
      "train loss:1.0058698545017473\n",
      "train loss:0.9413193607565618\n",
      "train loss:1.008947073744808\n",
      "train loss:0.9357998449856187\n",
      "train loss:0.981050010480401\n",
      "train loss:0.756893323982579\n",
      "train loss:0.8017029975874653\n",
      "train loss:0.812821301673179\n",
      "train loss:0.8058797188204322\n",
      "train loss:0.9738938557925136\n",
      "train loss:0.8508192081003757\n",
      "train loss:0.8105222982332336\n",
      "train loss:1.0445149758222907\n",
      "train loss:0.8869644475038989\n",
      "train loss:0.7506276797624697\n",
      "train loss:0.9369732162716509\n",
      "train loss:0.8453581642679859\n",
      "train loss:0.8564932762891101\n",
      "train loss:0.7380109824367992\n",
      "train loss:0.9092644588730785\n",
      "train loss:0.6468985174684456\n",
      "train loss:1.010074205016855\n",
      "train loss:0.9559657191529588\n",
      "train loss:0.9921445733508963\n",
      "train loss:0.9394577452826129\n",
      "train loss:0.8111097208539974\n",
      "train loss:0.9313066340580233\n",
      "train loss:0.9246788087674562\n",
      "train loss:0.8269375905086919\n",
      "train loss:0.9186931787086359\n",
      "train loss:0.8792642699452883\n",
      "train loss:0.8218254184921733\n",
      "train loss:1.0476684412550354\n",
      "train loss:0.9388777468314116\n",
      "train loss:0.8735808491259646\n",
      "train loss:0.811744139208268\n",
      "train loss:0.8163727259213318\n",
      "train loss:0.666488607791803\n",
      "train loss:0.8270838378609645\n",
      "train loss:0.8421651294810131\n",
      "train loss:0.9477703937729528\n",
      "train loss:0.840152630962842\n",
      "train loss:0.8500372656775673\n",
      "train loss:0.8650399518711016\n",
      "train loss:0.7725775491462599\n",
      "train loss:0.8807790044007311\n",
      "train loss:0.950900054003153\n",
      "train loss:0.9412350405775899\n",
      "train loss:0.8039107400730976\n",
      "train loss:0.8291609537346173\n",
      "train loss:0.8668273006854613\n",
      "train loss:0.8700445013435172\n",
      "train loss:0.7847863576670422\n",
      "train loss:0.9072669456565932\n",
      "train loss:0.8679529335294797\n",
      "train loss:0.9994170870557209\n",
      "train loss:0.8756904154614511\n",
      "train loss:0.9006820437163596\n",
      "train loss:0.901377651201642\n",
      "train loss:0.6433404539958958\n",
      "train loss:0.846032042549748\n",
      "train loss:0.9108705087945026\n",
      "train loss:0.8573366694124563\n",
      "train loss:0.7840544955932477\n",
      "train loss:0.7225993066231098\n",
      "train loss:0.8331651597551425\n",
      "train loss:1.0461551391007262\n",
      "train loss:0.8789753014064025\n",
      "train loss:1.0541319899218593\n",
      "train loss:0.8712311408117006\n",
      "train loss:0.7451740898429451\n",
      "train loss:0.8776478680190632\n",
      "train loss:0.9240380732650485\n",
      "train loss:0.8197460345652833\n",
      "train loss:0.7570022738620213\n",
      "train loss:0.7669657596507743\n",
      "train loss:0.7680810627406889\n",
      "train loss:0.8019478862721054\n",
      "train loss:0.8907819481029884\n",
      "train loss:0.9953149515056573\n",
      "train loss:0.9359443338580923\n",
      "train loss:0.9554703146362246\n",
      "train loss:0.8366861507199478\n",
      "train loss:0.7607941939754204\n",
      "train loss:0.8637272089772012\n",
      "train loss:0.9736950223320155\n",
      "train loss:0.9750235711354782\n",
      "train loss:0.8275928953299934\n",
      "train loss:0.870590354596006\n",
      "train loss:1.1084360972648402\n",
      "train loss:0.8426727029795537\n",
      "train loss:0.861793964859282\n",
      "train loss:0.8763939062593523\n",
      "train loss:0.7537584466118703\n",
      "train loss:0.8354535489865615\n",
      "train loss:0.7279488775485196\n",
      "train loss:0.9748757865388571\n",
      "train loss:0.9804408112837585\n",
      "train loss:0.7580079833204426\n",
      "train loss:0.9525081138187591\n",
      "train loss:0.8401431622661992\n",
      "train loss:0.752134266553623\n",
      "train loss:0.9423136242342283\n",
      "train loss:0.8372984488926448\n",
      "train loss:0.8351070846643901\n",
      "train loss:0.7859875613533319\n",
      "train loss:0.9940373817876929\n",
      "train loss:0.9746627966477512\n",
      "train loss:0.8341095298578761\n",
      "train loss:0.9754954647595627\n",
      "train loss:0.8367550899983917\n",
      "train loss:0.6833411729905693\n",
      "train loss:0.855663194628508\n",
      "train loss:0.903903521140185\n",
      "train loss:0.8069591569653864\n",
      "train loss:0.9983286110160142\n",
      "train loss:0.8684281533481785\n",
      "train loss:0.7864006209996957\n",
      "train loss:0.9615487089497641\n",
      "train loss:0.8232066074455979\n",
      "train loss:1.0336619884962834\n",
      "train loss:0.8523700026174277\n",
      "train loss:0.9170671418922669\n",
      "train loss:0.8464467174064839\n",
      "train loss:0.8698929745786923\n",
      "train loss:0.8681087508245895\n",
      "train loss:0.8363888817007828\n",
      "train loss:0.8393470654568311\n",
      "train loss:1.0919989588769632\n",
      "train loss:0.8250421871354138\n",
      "train loss:0.7301876420152741\n",
      "train loss:1.0902534854645358\n",
      "train loss:0.8386968869978365\n",
      "train loss:0.7161858866049343\n",
      "train loss:0.9675508658296448\n",
      "train loss:0.7299466867751991\n",
      "train loss:0.8799384356635171\n",
      "train loss:0.7976647895288405\n",
      "train loss:0.9113327937889134\n",
      "train loss:0.9975103117757744\n",
      "train loss:0.9543914731764369\n",
      "train loss:0.9615709988103117\n",
      "train loss:0.940681963261795\n",
      "train loss:0.9681510871166503\n",
      "train loss:0.9422806990648445\n",
      "train loss:0.958341933200819\n",
      "train loss:0.8897100567233661\n",
      "train loss:0.9176546405167414\n",
      "train loss:0.8436004739287397\n",
      "train loss:0.6891487176245369\n",
      "train loss:0.9011594478620798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7225615805128527\n",
      "train loss:0.7976663383877236\n",
      "train loss:0.887942848108295\n",
      "train loss:0.9739696191318995\n",
      "train loss:0.8270097655797136\n",
      "train loss:0.7705943767477699\n",
      "train loss:0.9862025381801897\n",
      "train loss:0.928433598991106\n",
      "train loss:0.8864595940569348\n",
      "train loss:0.9079174617402406\n",
      "train loss:0.8550765599265233\n",
      "train loss:0.7118489315148099\n",
      "train loss:0.7847031958010685\n",
      "train loss:0.9913985871986851\n",
      "train loss:0.8766856008273187\n",
      "train loss:1.0113655358850218\n",
      "train loss:0.9192739834623892\n",
      "train loss:0.7526681419439025\n",
      "train loss:0.7546087358630932\n",
      "train loss:0.9935922727649843\n",
      "train loss:0.9613460056753526\n",
      "train loss:0.8080198473996194\n",
      "train loss:0.9222228240014405\n",
      "train loss:0.9091766194106531\n",
      "train loss:0.8871406553697337\n",
      "train loss:0.8487585373027318\n",
      "train loss:0.9535515008322258\n",
      "train loss:0.8576151919328094\n",
      "train loss:0.9816663900944717\n",
      "train loss:0.9029566219766245\n",
      "train loss:0.8284955509038334\n",
      "train loss:0.7352178816112506\n",
      "train loss:0.9309459302519886\n",
      "train loss:0.7438991535396297\n",
      "train loss:0.9905505141531797\n",
      "train loss:0.8952290129749655\n",
      "train loss:1.1300651544232856\n",
      "train loss:0.8789589212000639\n",
      "train loss:0.8611603778976975\n",
      "train loss:0.8078757918440104\n",
      "train loss:0.8832207309859131\n",
      "train loss:0.905320389234692\n",
      "train loss:0.9126511112562875\n",
      "train loss:0.9522920615138291\n",
      "train loss:0.9032719671879643\n",
      "train loss:0.8337250792453992\n",
      "train loss:0.8845514718430362\n",
      "train loss:0.9904637294787031\n",
      "train loss:0.8124292740141849\n",
      "train loss:0.9260078478452186\n",
      "train loss:0.9188102784710632\n",
      "train loss:0.9946845423345629\n",
      "train loss:0.7907597006988583\n",
      "train loss:0.8800249390067824\n",
      "train loss:0.9405326143108579\n",
      "train loss:0.9179574872371086\n",
      "train loss:0.8855529611307188\n",
      "train loss:0.7649019852224589\n",
      "train loss:0.8437794200895852\n",
      "train loss:0.8457880253272865\n",
      "train loss:0.9600517273939808\n",
      "train loss:0.8772812545257607\n",
      "train loss:0.78209317283679\n",
      "train loss:0.9082343997012989\n",
      "train loss:0.9752524510895086\n",
      "train loss:0.9354569139889509\n",
      "train loss:0.776299558400033\n",
      "train loss:0.7592340950943459\n",
      "train loss:0.9986212273125915\n",
      "train loss:0.7165259857308327\n",
      "train loss:0.844760651882791\n",
      "train loss:0.8495180839704013\n",
      "train loss:0.9183128048543365\n",
      "train loss:0.8955049425073792\n",
      "train loss:0.8631155899610871\n",
      "train loss:1.1253146772712423\n",
      "train loss:0.9457843910238747\n",
      "train loss:1.079816600935785\n",
      "train loss:0.9732472488921508\n",
      "train loss:1.0163561249503532\n",
      "train loss:0.7963076961431014\n",
      "train loss:0.868527612033012\n",
      "train loss:0.9664501103897658\n",
      "train loss:1.0345517658354502\n",
      "train loss:0.859295225149428\n",
      "train loss:0.8197626992678706\n",
      "train loss:0.9861359023922885\n",
      "train loss:0.8825934609055947\n",
      "train loss:0.7394753606836194\n",
      "train loss:0.970284854984422\n",
      "train loss:0.7995189302887512\n",
      "train loss:0.8912064919760446\n",
      "train loss:0.8282569970085905\n",
      "train loss:0.9842556133223554\n",
      "train loss:0.8336904244853769\n",
      "train loss:0.7755647272206113\n",
      "train loss:0.9742070989677959\n",
      "train loss:0.8550952303253082\n",
      "train loss:1.0414767223037713\n",
      "train loss:0.7662784088096654\n",
      "train loss:0.9389940550871061\n",
      "train loss:0.8329794998382226\n",
      "train loss:0.8675324426520555\n",
      "train loss:0.9440828535489361\n",
      "train loss:0.7094469958110206\n",
      "train loss:0.9795900112680666\n",
      "train loss:0.9454737492543113\n",
      "train loss:0.9673284892907387\n",
      "train loss:0.8398381218607542\n",
      "train loss:0.7827015967161327\n",
      "train loss:0.902834143235873\n",
      "train loss:1.0312429049134992\n",
      "train loss:0.9342655451771552\n",
      "train loss:0.8311165595704167\n",
      "train loss:0.7225381083349178\n",
      "train loss:0.9677279528343614\n",
      "train loss:0.9521683097891604\n",
      "train loss:0.8747401009973413\n",
      "train loss:0.9109657478751779\n",
      "train loss:0.9411362972896469\n",
      "train loss:0.8963598620656225\n",
      "train loss:0.9479071449300173\n",
      "=== epoch:14, train acc:0.994, test acc:0.994 ===\n",
      "train loss:0.8127578061053119\n",
      "train loss:0.7900021564074163\n",
      "train loss:0.6782098166527112\n",
      "train loss:0.8407983672708681\n",
      "train loss:1.10499209101419\n",
      "train loss:1.106503144800345\n",
      "train loss:0.6533377244170963\n",
      "train loss:1.004348900481478\n",
      "train loss:0.8145138668372474\n",
      "train loss:0.8468102191961131\n",
      "train loss:0.8812486288869618\n",
      "train loss:0.8829243559362823\n",
      "train loss:0.8767394844506715\n",
      "train loss:0.9538143501394915\n",
      "train loss:0.9573766693132897\n",
      "train loss:0.8033176428552394\n",
      "train loss:0.7234962503077292\n",
      "train loss:0.6796341006640512\n",
      "train loss:0.977255357660048\n",
      "train loss:0.8405050870862426\n",
      "train loss:0.6944400966602408\n",
      "train loss:0.7475398748396569\n",
      "train loss:0.8863484040364731\n",
      "train loss:0.8942754515726551\n",
      "train loss:0.9996763503156384\n",
      "train loss:0.7159102918591208\n",
      "train loss:0.8815315661527137\n",
      "train loss:0.8630926303531785\n",
      "train loss:0.937579066087207\n",
      "train loss:0.8361986510663225\n",
      "train loss:0.8375907086477504\n",
      "train loss:0.8373921599287955\n",
      "train loss:0.9690666549876203\n",
      "train loss:0.8458109569473404\n",
      "train loss:0.8848851078555141\n",
      "train loss:0.8403055857875805\n",
      "train loss:0.8943623206022397\n",
      "train loss:0.6644224208276904\n",
      "train loss:0.9754155201130533\n",
      "train loss:0.8715613851847186\n",
      "train loss:0.9853435980367037\n",
      "train loss:0.9022719518315561\n",
      "train loss:0.9525637679627433\n",
      "train loss:0.8417013759764815\n",
      "train loss:0.795888117820359\n",
      "train loss:0.8975759567155001\n",
      "train loss:0.8113412173854104\n",
      "train loss:0.738977834953457\n",
      "train loss:1.00730387011275\n",
      "train loss:0.8920356208664108\n",
      "train loss:0.8484391742012085\n",
      "train loss:0.8100939451754321\n",
      "train loss:0.8494985980610754\n",
      "train loss:1.000836563711447\n",
      "train loss:0.7151989797575621\n",
      "train loss:0.8727020408996963\n",
      "train loss:0.8357267791287493\n",
      "train loss:0.881733902497446\n",
      "train loss:0.8171835888617313\n",
      "train loss:1.0559097390182421\n",
      "train loss:0.8282589365846309\n",
      "train loss:0.9345848362867403\n",
      "train loss:0.9530677282681154\n",
      "train loss:0.8497424393735308\n",
      "train loss:0.8987242392453587\n",
      "train loss:0.6800114211159033\n",
      "train loss:0.9641613676122265\n",
      "train loss:0.9209858914613133\n",
      "train loss:0.8638383809216836\n",
      "train loss:0.7619344260193707\n",
      "train loss:0.8430924160309636\n",
      "train loss:0.9709902828152593\n",
      "train loss:0.9443854896873755\n",
      "train loss:0.8512136825499412\n",
      "train loss:0.9163054644330818\n",
      "train loss:0.835144826104154\n",
      "train loss:0.8303491296415347\n",
      "train loss:0.9372143372384872\n",
      "train loss:0.8222938736705544\n",
      "train loss:0.8064727052059062\n",
      "train loss:1.0101521806023397\n",
      "train loss:0.8551114383318721\n",
      "train loss:0.7684857609855226\n",
      "train loss:0.8519751106580778\n",
      "train loss:0.7747973522824858\n",
      "train loss:0.9317315725938571\n",
      "train loss:0.7771359518584401\n",
      "train loss:0.761201819260808\n",
      "train loss:0.8424239849562113\n",
      "train loss:0.916210216906299\n",
      "train loss:1.0413173448070756\n",
      "train loss:0.878590378113538\n",
      "train loss:0.8800607817027537\n",
      "train loss:0.8792132531465933\n",
      "train loss:0.9714989576896216\n",
      "train loss:0.7632604307286686\n",
      "train loss:0.8814273356706954\n",
      "train loss:0.8563598922212634\n",
      "train loss:0.9371443021596139\n",
      "train loss:0.8408462938650528\n",
      "train loss:0.7817675757135996\n",
      "train loss:0.8464309654826526\n",
      "train loss:0.875141058532406\n",
      "train loss:0.9931312853712151\n",
      "train loss:0.8495809985260082\n",
      "train loss:0.8635951505932397\n",
      "train loss:0.747051291848228\n",
      "train loss:0.9226393940841973\n",
      "train loss:0.7533510350956437\n",
      "train loss:0.8709333906345829\n",
      "train loss:0.78908981554232\n",
      "train loss:0.7585331245192374\n",
      "train loss:0.8586541439568575\n",
      "train loss:1.0041003135144388\n",
      "train loss:0.9417093869495115\n",
      "train loss:0.8373490249138132\n",
      "train loss:0.7848076342139759\n",
      "train loss:0.8303207951782037\n",
      "train loss:0.9352487996965273\n",
      "train loss:0.8618108273845715\n",
      "train loss:0.7934851973265566\n",
      "train loss:0.8760111147673082\n",
      "train loss:0.8692416053128976\n",
      "train loss:0.811741103544986\n",
      "train loss:0.7201980581906505\n",
      "train loss:1.0222368750369974\n",
      "train loss:0.9643079629851496\n",
      "train loss:0.8081771202325886\n",
      "train loss:0.8943678805236825\n",
      "train loss:0.9949460171299314\n",
      "train loss:0.8074290721756221\n",
      "train loss:0.9245303168508577\n",
      "train loss:1.054002139306325\n",
      "train loss:0.9259905128288918\n",
      "train loss:0.8814903630465983\n",
      "train loss:0.8551331507518019\n",
      "train loss:0.7104650576439786\n",
      "train loss:0.819564365536491\n",
      "train loss:1.041188495001277\n",
      "train loss:0.8151166610033098\n",
      "train loss:0.9105965128107643\n",
      "train loss:0.8776656605975502\n",
      "train loss:0.7715016546370532\n",
      "train loss:0.8624584990031512\n",
      "train loss:1.1591652903209961\n",
      "train loss:0.8291199782855544\n",
      "train loss:0.955880763461247\n",
      "train loss:0.9675496950691402\n",
      "train loss:0.9892756607148278\n",
      "train loss:0.6926430728629757\n",
      "train loss:0.9337025825260424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8468599798614197\n",
      "train loss:0.9604985547494543\n",
      "train loss:0.8834905941191689\n",
      "train loss:0.8385495969954713\n",
      "train loss:0.9535682907558205\n",
      "train loss:0.8633583445762865\n",
      "train loss:0.8982029397135176\n",
      "train loss:0.7908496694309473\n",
      "train loss:0.8473597379552187\n",
      "train loss:0.839284342147623\n",
      "train loss:0.8203636367599974\n",
      "train loss:0.8408525838945082\n",
      "train loss:0.7367254992871843\n",
      "train loss:0.754195278853905\n",
      "train loss:0.8806905372849583\n",
      "train loss:0.8902677581728422\n",
      "train loss:0.7945213338777327\n",
      "train loss:0.831567713490928\n",
      "train loss:0.7627243937269554\n",
      "train loss:0.8845536429756911\n",
      "train loss:0.9043216833427618\n",
      "train loss:0.9210113554230449\n",
      "train loss:0.9285900655050601\n",
      "train loss:0.9252547770788468\n",
      "train loss:0.8826759984665961\n",
      "train loss:0.7309722091301663\n",
      "train loss:0.6642615675826938\n",
      "train loss:0.8389813779765596\n",
      "train loss:0.9339487829707253\n",
      "train loss:0.9820681845337178\n",
      "train loss:0.8601117380510591\n",
      "train loss:0.8433253764991998\n",
      "train loss:0.9222579642407304\n",
      "train loss:0.8127913761451638\n",
      "train loss:0.9124636794029602\n",
      "train loss:0.9893056717384623\n",
      "train loss:0.8941552591780167\n",
      "train loss:0.8154295017041671\n",
      "train loss:0.8274296359167385\n",
      "train loss:0.9852814917294944\n",
      "train loss:0.6928054881793428\n",
      "train loss:0.9089929601763999\n",
      "train loss:0.6611130608927153\n",
      "train loss:1.003577304304917\n",
      "train loss:0.9486807577027284\n",
      "train loss:0.6738433214445864\n",
      "train loss:0.8896953553771069\n",
      "train loss:1.0167152065185767\n",
      "train loss:0.8054173225953614\n",
      "train loss:0.8820388945179378\n",
      "train loss:0.9909294992428456\n",
      "train loss:0.8656159304135947\n",
      "train loss:0.9357908108061214\n",
      "train loss:0.8960976216930884\n",
      "train loss:0.6354196169371442\n",
      "train loss:0.8477562864904464\n",
      "train loss:0.8662878977439729\n",
      "train loss:0.8877787137868108\n",
      "train loss:0.8991041100432802\n",
      "train loss:0.7528168766662807\n",
      "train loss:0.9389565392681452\n",
      "train loss:0.9250333319481823\n",
      "train loss:0.7743049997327647\n",
      "train loss:0.9434709686806932\n",
      "train loss:0.8932046052201424\n",
      "train loss:0.9234922897153892\n",
      "train loss:0.7623888844942037\n",
      "train loss:0.8846629766475412\n",
      "train loss:0.9038978771027766\n",
      "train loss:0.9404567678110359\n",
      "train loss:0.8725158468178327\n",
      "train loss:0.8884766126039128\n",
      "train loss:0.9744941142511547\n",
      "train loss:0.8759182627464728\n",
      "train loss:0.8190733819499549\n",
      "train loss:0.9866288481302985\n",
      "train loss:0.8662385709683319\n",
      "train loss:0.9323404394615121\n",
      "train loss:0.8550718967332602\n",
      "train loss:0.8578763910212192\n",
      "train loss:0.9752547175328834\n",
      "train loss:1.0072227959151132\n",
      "train loss:0.9370184365724061\n",
      "train loss:0.8935620926426852\n",
      "train loss:0.7249738427622432\n",
      "train loss:0.8827745116440612\n",
      "train loss:0.8021705441890781\n",
      "train loss:0.8973852010245004\n",
      "train loss:0.8805468954758489\n",
      "train loss:0.8417207775184068\n",
      "train loss:0.9716323791302655\n",
      "train loss:0.8040087924848602\n",
      "train loss:0.8071239603302246\n",
      "train loss:0.8470210819392705\n",
      "train loss:0.737797045878371\n",
      "train loss:0.8951011466201774\n",
      "train loss:0.8470185192322139\n",
      "train loss:0.7905092662450709\n",
      "train loss:0.946368692526675\n",
      "train loss:0.7434866408758605\n",
      "train loss:0.7993191797393457\n",
      "train loss:0.9143050638080679\n",
      "train loss:1.0217146976735867\n",
      "train loss:0.9942134276887269\n",
      "train loss:0.8852273004359212\n",
      "train loss:0.9066803033259742\n",
      "train loss:0.800781407507376\n",
      "train loss:0.8044028698999063\n",
      "train loss:0.877100071159527\n",
      "train loss:0.9591988690803316\n",
      "train loss:0.8302991799972219\n",
      "train loss:0.8661860596183587\n",
      "train loss:0.9799414620598221\n",
      "train loss:0.7778217795867363\n",
      "train loss:0.650846724465344\n",
      "train loss:0.8621599064140285\n",
      "train loss:0.8231226765859455\n",
      "train loss:0.9117259674267966\n",
      "train loss:0.7331689033095293\n",
      "train loss:0.8111152521399674\n",
      "train loss:0.9346322185420992\n",
      "train loss:0.8110824524245643\n",
      "train loss:0.7723591188505224\n",
      "train loss:0.7445903215023296\n",
      "train loss:0.881856970396988\n",
      "train loss:0.8619007067914911\n",
      "train loss:0.7801692712297583\n",
      "train loss:0.6963574327583341\n",
      "train loss:0.8754112252665616\n",
      "train loss:0.8392317813527456\n",
      "train loss:0.8477290733607725\n",
      "train loss:0.8605017877605896\n",
      "train loss:0.9087869291477719\n",
      "train loss:0.905448051584002\n",
      "train loss:1.0027634024728942\n",
      "train loss:0.8797915008098568\n",
      "train loss:0.8581590493328914\n",
      "train loss:0.87267301549165\n",
      "train loss:0.8174192518275811\n",
      "train loss:1.0036332096868323\n",
      "train loss:0.9249793590128956\n",
      "train loss:0.8390251335514728\n",
      "train loss:0.9986750326649247\n",
      "train loss:0.9655374735835663\n",
      "train loss:0.9046914373363079\n",
      "train loss:0.7774141200153322\n",
      "train loss:0.735845029505512\n",
      "train loss:0.8624863443197648\n",
      "train loss:0.8389194549038599\n",
      "train loss:0.9698435604463017\n",
      "train loss:0.987079426963624\n",
      "train loss:0.9030629983928655\n",
      "train loss:0.8076704397420218\n",
      "train loss:0.9277961405214689\n",
      "train loss:1.0590581260302148\n",
      "train loss:0.7584135085097163\n",
      "train loss:0.770766328543088\n",
      "train loss:0.8754733373344576\n",
      "train loss:0.730721272376966\n",
      "train loss:0.8120542789897556\n",
      "train loss:0.9259578752941221\n",
      "train loss:0.9927410023995058\n",
      "train loss:0.8863576856467436\n",
      "train loss:0.8686648768340761\n",
      "train loss:0.9896984787271782\n",
      "train loss:0.8966571030435052\n",
      "train loss:0.7453716594362325\n",
      "train loss:0.7503006045505463\n",
      "train loss:0.8856490713086458\n",
      "train loss:0.7816636324382639\n",
      "train loss:0.8727232693730922\n",
      "train loss:0.8718872574609161\n",
      "train loss:0.7387126904278657\n",
      "train loss:0.7403310002724074\n",
      "train loss:0.8455585711233371\n",
      "train loss:0.8404134167448758\n",
      "train loss:0.8491808140149425\n",
      "train loss:0.9906914972238086\n",
      "train loss:0.8909098407976797\n",
      "train loss:0.8126442630782629\n",
      "train loss:0.8504245411988767\n",
      "train loss:0.9256906127285492\n",
      "train loss:0.7193001653850699\n",
      "train loss:0.7650280270056145\n",
      "train loss:0.9601449276064302\n",
      "train loss:1.012946292708907\n",
      "train loss:0.8701631054581865\n",
      "train loss:0.8185404403313737\n",
      "train loss:1.0251644504030502\n",
      "train loss:0.8349352227442651\n",
      "train loss:0.8706865517403215\n",
      "train loss:0.8965678000894237\n",
      "train loss:0.711754858339246\n",
      "train loss:0.8530408459317822\n",
      "train loss:0.695267259308551\n",
      "train loss:0.7844221731596588\n",
      "train loss:0.8827783772329089\n",
      "train loss:0.945771871284677\n",
      "train loss:0.8091902797273857\n",
      "train loss:0.7410136706377847\n",
      "train loss:0.8104312347790353\n",
      "train loss:1.0155187136686599\n",
      "train loss:0.9179735917389267\n",
      "train loss:0.948041202725618\n",
      "train loss:0.895218589346551\n",
      "train loss:0.8735633025211587\n",
      "train loss:0.9967171931714064\n",
      "train loss:0.8879211845061892\n",
      "train loss:0.9748837477737585\n",
      "train loss:0.6626416298348518\n",
      "train loss:0.9312810222635085\n",
      "train loss:0.8793111781239038\n",
      "train loss:0.8892701196922725\n",
      "train loss:1.0558085240759991\n",
      "train loss:0.994148278295952\n",
      "train loss:0.7772157038685212\n",
      "train loss:0.7144148616994589\n",
      "train loss:0.8640573458231693\n",
      "train loss:0.7322287572681613\n",
      "train loss:0.7420483248717695\n",
      "train loss:0.7865097365784496\n",
      "train loss:1.12390061218904\n",
      "train loss:1.0323194979858885\n",
      "train loss:0.7991937438957062\n",
      "train loss:0.8332605344663021\n",
      "train loss:0.9633884413838159\n",
      "train loss:0.7989867055793468\n",
      "train loss:0.8866150297668625\n",
      "train loss:0.7364838302525666\n",
      "train loss:0.9550451325323236\n",
      "train loss:0.8232743297644903\n",
      "train loss:0.8627197421173782\n",
      "train loss:0.8375860009508953\n",
      "train loss:0.7412496494396169\n",
      "train loss:0.9028244624007319\n",
      "train loss:0.8127457894978706\n",
      "train loss:0.7561217487004791\n",
      "train loss:0.8691242060833149\n",
      "train loss:0.8548788156782494\n",
      "train loss:0.8336621168430477\n",
      "train loss:1.107993626151814\n",
      "train loss:0.8435114047341311\n",
      "train loss:0.9051224395930498\n",
      "train loss:0.9207708853297146\n",
      "train loss:0.7893653978302885\n",
      "train loss:0.9032655361802382\n",
      "train loss:0.8339397582625377\n",
      "train loss:0.825178532038429\n",
      "train loss:0.8915839615120688\n",
      "train loss:0.9080939834842892\n",
      "train loss:0.6880100123578782\n",
      "train loss:0.861229217807887\n",
      "train loss:0.9249405210776384\n",
      "train loss:0.8419884468327556\n",
      "train loss:0.7599617183904838\n",
      "train loss:0.7691449659330186\n",
      "train loss:0.8451222085791329\n",
      "train loss:1.0401972276447216\n",
      "train loss:1.0631942357961859\n",
      "train loss:0.696647713342891\n",
      "train loss:0.9108188137372686\n",
      "train loss:0.8702750029047824\n",
      "train loss:0.91427426655582\n",
      "train loss:0.9189297458027204\n",
      "train loss:1.1299068179890674\n",
      "train loss:0.6992622367244636\n",
      "train loss:0.873829597650766\n",
      "train loss:0.9507630431879237\n",
      "train loss:0.9435905382767052\n",
      "train loss:0.810254505332021\n",
      "train loss:0.7965268130026506\n",
      "train loss:0.7369668710958004\n",
      "train loss:0.706926720153403\n",
      "train loss:0.9430492720738117\n",
      "train loss:0.8769829829276133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.895040695613622\n",
      "train loss:1.010951718131123\n",
      "train loss:1.0430112214646383\n",
      "train loss:0.8728539576768215\n",
      "train loss:1.0301178667306494\n",
      "train loss:1.003629277328494\n",
      "train loss:0.7745208007601855\n",
      "train loss:0.7365606492115857\n",
      "train loss:0.8171651408379579\n",
      "train loss:0.7370288057453773\n",
      "train loss:0.9480741881474235\n",
      "train loss:0.7628926693726065\n",
      "train loss:1.0651685454303341\n",
      "train loss:0.9057617500602326\n",
      "train loss:0.8821364113802268\n",
      "train loss:0.8842869663956355\n",
      "train loss:0.8309964785079292\n",
      "train loss:0.9937113502474044\n",
      "train loss:0.873701616479931\n",
      "train loss:0.8263532327605312\n",
      "train loss:0.9188350994189168\n",
      "train loss:0.6704251588333545\n",
      "train loss:1.0498381612367573\n",
      "train loss:0.9232435151523791\n",
      "train loss:0.9840631865476407\n",
      "train loss:0.8384738929029167\n",
      "train loss:0.8626058636667484\n",
      "train loss:0.8630999003254872\n",
      "train loss:0.8531344943629281\n",
      "train loss:1.0060298798189007\n",
      "train loss:0.8594422004760238\n",
      "train loss:0.8947543785078013\n",
      "train loss:0.8329695606013153\n",
      "train loss:0.7217373914095888\n",
      "train loss:0.8929759805856454\n",
      "train loss:0.941166626929685\n",
      "train loss:0.9025842715747173\n",
      "train loss:0.8791525427780627\n",
      "train loss:0.8815579643972358\n",
      "train loss:0.8840007161344282\n",
      "train loss:0.7919993480244334\n",
      "train loss:0.724417499138346\n",
      "train loss:0.7866506866295425\n",
      "train loss:0.999004211781548\n",
      "train loss:0.7860088369000896\n",
      "train loss:0.903783397323562\n",
      "train loss:0.80514895454939\n",
      "train loss:0.8291251484139427\n",
      "train loss:1.0169768098230487\n",
      "train loss:0.7678482717848847\n",
      "train loss:0.8676558670603535\n",
      "train loss:0.7556326328076882\n",
      "train loss:0.8807456455302055\n",
      "train loss:0.9729742930468251\n",
      "train loss:0.867522511843662\n",
      "train loss:0.7076570692885411\n",
      "train loss:0.8888263046041104\n",
      "train loss:0.7463367050261166\n",
      "train loss:0.8981979235013359\n",
      "train loss:1.0364599420584293\n",
      "train loss:0.9214776595414476\n",
      "train loss:0.7296898779487525\n",
      "train loss:0.8575277565087873\n",
      "train loss:0.7957560337129247\n",
      "train loss:0.9071288081386574\n",
      "train loss:0.9233276014653089\n",
      "train loss:0.8698251474452385\n",
      "train loss:0.783589098264507\n",
      "train loss:0.9936196050532863\n",
      "train loss:0.8186615230274971\n",
      "train loss:0.889148013691912\n",
      "train loss:0.8333487936756286\n",
      "train loss:0.8841466580289185\n",
      "train loss:0.8425892915068302\n",
      "train loss:0.8128379836584991\n",
      "train loss:0.810702749261007\n",
      "train loss:0.7011598009825813\n",
      "train loss:0.900427035755341\n",
      "train loss:0.7520264325006955\n",
      "train loss:0.8582636830734693\n",
      "train loss:0.7540839271108659\n",
      "train loss:0.9249363245428907\n",
      "train loss:0.8624900256256874\n",
      "train loss:0.859723149557606\n",
      "train loss:0.8860018260644879\n",
      "train loss:0.836466412400948\n",
      "train loss:0.7511334271371524\n",
      "train loss:0.7934397933716559\n",
      "train loss:0.9497564092534156\n",
      "train loss:0.8400740551757008\n",
      "train loss:0.8177583317204312\n",
      "train loss:1.0495870333116266\n",
      "train loss:0.7881098063386729\n",
      "train loss:0.7989135470507199\n",
      "train loss:0.7297971431336636\n",
      "train loss:0.9746221046063659\n",
      "train loss:0.9430463292360599\n",
      "train loss:0.9454511881691247\n",
      "train loss:0.8539234571444299\n",
      "train loss:0.7915331509948915\n",
      "train loss:0.9379192050497571\n",
      "train loss:0.9414381981180462\n",
      "train loss:0.9385564442496772\n",
      "train loss:0.9859162019770062\n",
      "train loss:0.739135848098669\n",
      "train loss:0.8859367694439364\n",
      "train loss:0.9671425791996557\n",
      "train loss:0.8616477508007466\n",
      "train loss:0.8308358731645855\n",
      "train loss:0.9716356980255374\n",
      "train loss:0.8879304278522677\n",
      "train loss:0.8354326918738423\n",
      "train loss:0.7653860207967234\n",
      "train loss:0.7734639693301117\n",
      "train loss:0.7030816788712122\n",
      "train loss:0.8662859273844491\n",
      "train loss:0.8992403808658793\n",
      "train loss:1.0030314159544653\n",
      "train loss:0.7829062666518618\n",
      "train loss:0.9696940761947829\n",
      "train loss:0.8894043041293374\n",
      "train loss:0.9626217241712374\n",
      "train loss:0.9267813497482409\n",
      "train loss:0.9596851432488477\n",
      "train loss:0.7851564388452578\n",
      "train loss:0.711838401216898\n",
      "train loss:0.8259909490911663\n",
      "train loss:1.02314677314767\n",
      "train loss:0.9723265666475751\n",
      "train loss:1.015739173366925\n",
      "train loss:0.9047336587652304\n",
      "train loss:0.8789008792456088\n",
      "train loss:0.8682094301038298\n",
      "train loss:0.8828523949066188\n",
      "train loss:0.9182042691183817\n",
      "train loss:0.8026050762514157\n",
      "train loss:0.9069450829079436\n",
      "train loss:0.7668957636870801\n",
      "train loss:0.895809486135426\n",
      "train loss:0.8559418089205083\n",
      "train loss:0.7077597508133269\n",
      "train loss:0.9975148552399387\n",
      "train loss:0.7833278055694932\n",
      "train loss:0.8284255385067857\n",
      "train loss:0.9021534580483439\n",
      "train loss:0.958853106866222\n",
      "train loss:0.8438383411732231\n",
      "train loss:0.899594615442728\n",
      "train loss:1.0190499313201444\n",
      "train loss:0.9152189161259768\n",
      "train loss:0.8413857986443971\n",
      "train loss:0.7216506352532442\n",
      "train loss:0.7281792811070656\n",
      "train loss:0.8102633554615296\n",
      "train loss:0.9843679379113229\n",
      "train loss:0.8656543790915155\n",
      "train loss:0.8166687019217287\n",
      "train loss:0.9529913532281599\n",
      "train loss:0.9125637549835385\n",
      "train loss:0.9138144279737445\n",
      "train loss:0.891918142069608\n",
      "train loss:0.7774364991881582\n",
      "train loss:0.895203131997221\n",
      "train loss:0.7399870239362016\n",
      "train loss:0.8033623626488554\n",
      "train loss:0.9233298508802429\n",
      "train loss:0.8049825394123473\n",
      "train loss:0.8379358657546269\n",
      "train loss:0.8383365184500268\n",
      "train loss:0.8150990218226941\n",
      "train loss:0.8674114313705865\n",
      "train loss:0.8145869105317038\n",
      "train loss:0.9096347027465989\n",
      "train loss:0.8132285040671431\n",
      "=== epoch:15, train acc:0.993, test acc:0.991 ===\n",
      "train loss:0.7355399066723639\n",
      "train loss:0.8462854216415322\n",
      "train loss:1.0665858705924536\n",
      "train loss:0.6919213854301266\n",
      "train loss:0.9442933113937848\n",
      "train loss:0.8785725808932893\n",
      "train loss:0.7141157078933479\n",
      "train loss:0.8467786295584757\n",
      "train loss:0.7734528288572966\n",
      "train loss:0.8215034011980427\n",
      "train loss:0.9610891647660644\n",
      "train loss:0.8308715539310968\n",
      "train loss:0.6629191785297864\n",
      "train loss:0.8405402914791307\n",
      "train loss:0.921939877743091\n",
      "train loss:0.7282277872030629\n",
      "train loss:0.7153143375642042\n",
      "train loss:0.8181110631037736\n",
      "train loss:0.8204760862429681\n",
      "train loss:1.0037376885293947\n",
      "train loss:0.7710088491949186\n",
      "train loss:0.8710142695932208\n",
      "train loss:0.915587149146091\n",
      "train loss:0.8027833710530523\n",
      "train loss:0.8393393992864517\n",
      "train loss:0.8909718284681162\n",
      "train loss:0.9388996789102939\n",
      "train loss:0.9769670848575253\n",
      "train loss:0.9430115971821291\n",
      "train loss:0.7303514419874848\n",
      "train loss:0.8746022327857045\n",
      "train loss:0.7887672339699506\n",
      "train loss:1.056004052384706\n",
      "train loss:0.8813476382936415\n",
      "train loss:0.7509551938645416\n",
      "train loss:0.7898211953593459\n",
      "train loss:0.8520829999671036\n",
      "train loss:0.8704624170709877\n",
      "train loss:0.8046966046667677\n",
      "train loss:0.8246708010868674\n",
      "train loss:0.7954950245853323\n",
      "train loss:0.7054504031022666\n",
      "train loss:1.078215125966772\n",
      "train loss:0.9391205124302688\n",
      "train loss:0.8368902301775701\n",
      "train loss:0.8611122440918428\n",
      "train loss:0.9537572339061233\n",
      "train loss:0.9687711019692331\n",
      "train loss:0.8571048499794992\n",
      "train loss:0.812449620542444\n",
      "train loss:0.8588881396480952\n",
      "train loss:0.8827815384798252\n",
      "train loss:0.6944571763404808\n",
      "train loss:0.8573511934157766\n",
      "train loss:0.7559639192437705\n",
      "train loss:0.8815568770164509\n",
      "train loss:0.8579111598414139\n",
      "train loss:0.7409338233608864\n",
      "train loss:0.8087676520519516\n",
      "train loss:0.9575177959143646\n",
      "train loss:0.9093707302453053\n",
      "train loss:0.8262556818614369\n",
      "train loss:0.876406591300988\n",
      "train loss:0.833129783038757\n",
      "train loss:0.9189630365631022\n",
      "train loss:0.747115875865765\n",
      "train loss:0.9139063607672929\n",
      "train loss:0.8169931250211805\n",
      "train loss:0.9919694573483163\n",
      "train loss:0.7505048868753598\n",
      "train loss:0.9627862782589938\n",
      "train loss:0.8276550765688433\n",
      "train loss:0.7856674016820867\n",
      "train loss:0.8742353532486337\n",
      "train loss:0.9408162503678966\n",
      "train loss:0.9846234812087695\n",
      "train loss:1.0538999770524162\n",
      "train loss:0.8032344917709454\n",
      "train loss:0.9534934978807834\n",
      "train loss:0.6310422240767438\n",
      "train loss:0.8930593571649412\n",
      "train loss:0.8481352408298493\n",
      "train loss:0.9194046107438747\n",
      "train loss:0.9623387006849726\n",
      "train loss:0.6500502463492449\n",
      "train loss:0.9151821325234366\n",
      "train loss:0.6881086742323574\n",
      "train loss:0.8129792220191365\n",
      "train loss:0.7575100197779373\n",
      "train loss:0.9974887441828852\n",
      "train loss:0.9139052778937901\n",
      "train loss:0.8629752818853291\n",
      "train loss:0.8152463430709819\n",
      "train loss:0.7681174950710434\n",
      "train loss:0.9575264093147385\n",
      "train loss:0.7953032430834801\n",
      "train loss:0.9483044157257998\n",
      "train loss:1.0319108988459773\n",
      "train loss:0.7827573420808714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9339507618524991\n",
      "train loss:0.7644244383304907\n",
      "train loss:0.7720839498942317\n",
      "train loss:0.87946807277468\n",
      "train loss:0.8688288631940736\n",
      "train loss:0.8416788218719313\n",
      "train loss:0.9387919989405225\n",
      "train loss:0.8353629016311973\n",
      "train loss:0.7900197047823105\n",
      "train loss:0.7529876608620196\n",
      "train loss:0.9669442588834339\n",
      "train loss:0.8994921672667071\n",
      "train loss:0.8631547484055179\n",
      "train loss:0.9113807778837055\n",
      "train loss:1.0496376139623578\n",
      "train loss:0.9634754114289179\n",
      "train loss:0.8149613610335865\n",
      "train loss:0.8526429847751094\n",
      "train loss:0.8914328086038583\n",
      "train loss:0.830707943814542\n",
      "train loss:0.787007015499935\n",
      "train loss:1.0465410108533635\n",
      "train loss:1.0028199090149945\n",
      "train loss:0.8264981843599288\n",
      "train loss:0.7353352032406852\n",
      "train loss:0.9019616806933284\n",
      "train loss:0.9295819982101176\n",
      "train loss:0.8151033307362101\n",
      "train loss:0.9388304660831733\n",
      "train loss:0.7897268098407885\n",
      "train loss:0.9149692287513096\n",
      "train loss:0.966005658932326\n",
      "train loss:0.8073058366048858\n",
      "train loss:0.9459682114696801\n",
      "train loss:0.8960513314964773\n",
      "train loss:0.8828180014988548\n",
      "train loss:0.886034102697076\n",
      "train loss:0.7832171714665691\n",
      "train loss:0.9494985115437561\n",
      "train loss:0.9004578002369962\n",
      "train loss:1.066347116916317\n",
      "train loss:0.9792844142050109\n",
      "train loss:0.8504145898931728\n",
      "train loss:0.9096430404336807\n",
      "train loss:0.9001647164000224\n",
      "train loss:0.8753840981109582\n",
      "train loss:0.8448145165546866\n",
      "train loss:0.7547197091609874\n",
      "train loss:0.7292279133941457\n",
      "train loss:0.9624303051633762\n",
      "train loss:0.8879189583362067\n",
      "train loss:0.7965249591093918\n",
      "train loss:0.842161453388503\n",
      "train loss:0.9371476456138106\n",
      "train loss:0.8391502559492328\n",
      "train loss:0.8945983846098028\n",
      "train loss:0.8967412844701478\n",
      "train loss:0.8279521332763241\n",
      "train loss:0.798682977466606\n",
      "train loss:0.9342671238979627\n",
      "train loss:0.8091450736001788\n",
      "train loss:0.8653176570398792\n",
      "train loss:0.9759394793093271\n",
      "train loss:0.8967596914104117\n",
      "train loss:0.929398318431932\n",
      "train loss:0.8121502884782593\n",
      "train loss:0.8285995484182708\n",
      "train loss:0.992674803218576\n",
      "train loss:0.8302536571374258\n",
      "train loss:0.8748906234238077\n",
      "train loss:0.8801959937822305\n",
      "train loss:0.8843460158640171\n",
      "train loss:1.0714092140675664\n",
      "train loss:0.9622316284051823\n",
      "train loss:0.8415959748781553\n",
      "train loss:0.8926828605519646\n",
      "train loss:0.8606863439606625\n",
      "train loss:0.9783428087015702\n",
      "train loss:0.8138827139452965\n",
      "train loss:0.8992957512549776\n",
      "train loss:0.8901456611073012\n",
      "train loss:0.8818937354533567\n",
      "train loss:0.7767016434865123\n",
      "train loss:0.7884627881695514\n",
      "train loss:0.9019239923795381\n",
      "train loss:0.8753755955790603\n",
      "train loss:0.9029070766340468\n",
      "train loss:0.8630887029960428\n",
      "train loss:0.9755153134575804\n",
      "train loss:0.8615073643513805\n",
      "train loss:0.7507113314317339\n",
      "train loss:0.7791646371456507\n",
      "train loss:0.9522159541686768\n",
      "train loss:0.8769297628329835\n",
      "train loss:0.9334662243959674\n",
      "train loss:0.7805365635734934\n",
      "train loss:0.7742765212474393\n",
      "train loss:1.0920179002667978\n",
      "train loss:0.7928024918654301\n",
      "train loss:0.8481252284699078\n",
      "train loss:0.7820776319303774\n",
      "train loss:0.7951734235882999\n",
      "train loss:0.8739606629422678\n",
      "train loss:0.8434511159914913\n",
      "train loss:0.8507258906634501\n",
      "train loss:0.8781335123083716\n",
      "train loss:0.817730923886062\n",
      "train loss:0.8833661549481482\n",
      "train loss:0.8344779594667848\n",
      "train loss:0.9836874158955614\n",
      "train loss:0.8272348826449519\n",
      "train loss:0.8071030449695027\n",
      "train loss:0.9417328692755332\n",
      "train loss:0.7361525846694971\n",
      "train loss:0.8046710199573145\n",
      "train loss:0.8041655405174896\n",
      "train loss:0.9037462351287072\n",
      "train loss:0.8772960888174179\n",
      "train loss:0.8909512692196655\n",
      "train loss:0.8616454327612366\n",
      "train loss:0.8595689403817297\n",
      "train loss:0.9364301626621457\n",
      "train loss:0.9770288293931745\n",
      "train loss:1.0166243956831769\n",
      "train loss:0.6383864043782456\n",
      "train loss:0.85440925868748\n",
      "train loss:0.9668664191468385\n",
      "train loss:0.866205958986724\n",
      "train loss:1.1037965213159744\n",
      "train loss:1.060918489277169\n",
      "train loss:0.8079904200955178\n",
      "train loss:0.8241522213045134\n",
      "train loss:0.8446402968709619\n",
      "train loss:0.8106195248538315\n",
      "train loss:0.8471523388973081\n",
      "train loss:0.8200279682070364\n",
      "train loss:0.7748082970213317\n",
      "train loss:1.0775804508004005\n",
      "train loss:0.8245278082919947\n",
      "train loss:0.9273188648979511\n",
      "train loss:1.0043692378723297\n",
      "train loss:0.8531038951014014\n",
      "train loss:0.8705723673744693\n",
      "train loss:0.9564132921874742\n",
      "train loss:0.8904935330914671\n",
      "train loss:0.9997922556549801\n",
      "train loss:0.9376477863827928\n",
      "train loss:0.9081910452300247\n",
      "train loss:0.7564953046514469\n",
      "train loss:0.7989002841726931\n",
      "train loss:0.9139319150263718\n",
      "train loss:0.8361456131639011\n",
      "train loss:0.8093986307994504\n",
      "train loss:0.8895701857898622\n",
      "train loss:0.9656911556884975\n",
      "train loss:0.7338554323215308\n",
      "train loss:0.7945802807436975\n",
      "train loss:1.1256319500658045\n",
      "train loss:0.7161416385795439\n",
      "train loss:0.8968354204907328\n",
      "train loss:1.1245791712447342\n",
      "train loss:0.8608770534430034\n",
      "train loss:0.7638099607755306\n",
      "train loss:0.8382527576000411\n",
      "train loss:0.9252496325498258\n",
      "train loss:0.7666332373708916\n",
      "train loss:0.8230512483916584\n",
      "train loss:0.791330110292897\n",
      "train loss:0.787451358021357\n",
      "train loss:0.8199964878063187\n",
      "train loss:0.8526580382360126\n",
      "train loss:0.738926865595744\n",
      "train loss:0.8659383777224053\n",
      "train loss:0.7862185595095229\n",
      "train loss:0.8395147380710065\n",
      "train loss:0.9063635404539744\n",
      "train loss:0.9204189245798636\n",
      "train loss:0.945150457291399\n",
      "train loss:0.8302626167018426\n",
      "train loss:1.048481577940209\n",
      "train loss:0.8713239151688876\n",
      "train loss:0.8353626482532605\n",
      "train loss:0.8401499172145701\n",
      "train loss:0.9207907658881647\n",
      "train loss:1.0072682128581818\n",
      "train loss:0.8901216746477241\n",
      "train loss:0.8347174720226517\n",
      "train loss:0.8806238379241546\n",
      "train loss:0.5321055581266453\n",
      "train loss:0.9522172988851625\n",
      "train loss:0.912838020280322\n",
      "train loss:0.8001061098242946\n",
      "train loss:0.8974855311313459\n",
      "train loss:0.8232982758620159\n",
      "train loss:0.9078306326415087\n",
      "train loss:0.808534371324595\n",
      "train loss:0.8911394054396778\n",
      "train loss:0.9593371536234828\n",
      "train loss:0.95055063819655\n",
      "train loss:1.02837996159314\n",
      "train loss:0.8239645868361882\n",
      "train loss:1.0539553271339044\n",
      "train loss:0.8557302145360357\n",
      "train loss:0.6869881974787745\n",
      "train loss:0.9968238359917803\n",
      "train loss:1.0366415058707477\n",
      "train loss:0.8891082501937048\n",
      "train loss:0.7046193341200548\n",
      "train loss:0.8067740810412325\n",
      "train loss:0.8637732557717485\n",
      "train loss:0.8340726978747547\n",
      "train loss:0.859839235222061\n",
      "train loss:0.8427021069746933\n",
      "train loss:1.0148172258532775\n",
      "train loss:0.942000445063417\n",
      "train loss:0.8948502159437624\n",
      "train loss:0.8692916424024466\n",
      "train loss:0.9640879012349863\n",
      "train loss:0.7625067843243387\n",
      "train loss:0.9266349614435027\n",
      "train loss:0.7701943784611308\n",
      "train loss:0.7614746721042686\n",
      "train loss:0.8156757574601573\n",
      "train loss:0.8067944688092914\n",
      "train loss:0.7196302718657179\n",
      "train loss:0.8589478878524889\n",
      "train loss:0.9013851475006518\n",
      "train loss:0.7874896636458117\n",
      "train loss:0.753013358913791\n",
      "train loss:0.9006687424389829\n",
      "train loss:0.9499662082248039\n",
      "train loss:0.9049955180656266\n",
      "train loss:0.9775079149329211\n",
      "train loss:0.841871611430689\n",
      "train loss:0.7268156717138935\n",
      "train loss:0.7994087039723387\n",
      "train loss:0.9108772101995557\n",
      "train loss:0.7914762235044212\n",
      "train loss:0.9263248393094756\n",
      "train loss:1.1291761851856732\n",
      "train loss:0.8750533645106608\n",
      "train loss:0.8085743370531613\n",
      "train loss:0.94493509456328\n",
      "train loss:0.8790217439690596\n",
      "train loss:0.962993022309028\n",
      "train loss:0.7220430334325556\n",
      "train loss:0.8602529711544249\n",
      "train loss:0.9868591880066095\n",
      "train loss:0.8481633748749792\n",
      "train loss:0.842899281382575\n",
      "train loss:0.7926067668938463\n",
      "train loss:0.885730678943502\n",
      "train loss:0.7733223490438296\n",
      "train loss:0.6965634180751229\n",
      "train loss:0.7553791687699162\n",
      "train loss:0.7958483624357648\n",
      "train loss:0.8848071430785056\n",
      "train loss:0.9071670242920895\n",
      "train loss:0.7460450658453701\n",
      "train loss:0.7677230742588479\n",
      "train loss:0.9069599873804922\n",
      "train loss:0.8412617563626292\n",
      "train loss:0.8252059029622646\n",
      "train loss:0.959026635687937\n",
      "train loss:0.9604350809628461\n",
      "train loss:0.78227899720419\n",
      "train loss:0.7423006737326926\n",
      "train loss:0.9726152708267543\n",
      "train loss:0.7646477077468155\n",
      "train loss:0.7984538258334374\n",
      "train loss:0.8652643198525942\n",
      "train loss:0.8041836514596237\n",
      "train loss:0.8720454789504339\n",
      "train loss:0.8600390643786067\n",
      "train loss:0.825339209203622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8995654874852606\n",
      "train loss:0.9324664206915629\n",
      "train loss:0.8767834599877642\n",
      "train loss:0.8774396072586687\n",
      "train loss:0.8925366810109777\n",
      "train loss:0.9632253368471986\n",
      "train loss:0.8763464366731972\n",
      "train loss:0.8423478521196409\n",
      "train loss:0.8062944792153637\n",
      "train loss:0.7541596211821031\n",
      "train loss:0.84817278952242\n",
      "train loss:0.9664603780887241\n",
      "train loss:0.9255468795600887\n",
      "train loss:0.8875647675849769\n",
      "train loss:0.8803013540178791\n",
      "train loss:0.9043764158247256\n",
      "train loss:0.7264903540870532\n",
      "train loss:0.9696723652696135\n",
      "train loss:0.7495820784713352\n",
      "train loss:0.8018714029835239\n",
      "train loss:0.7900805128524385\n",
      "train loss:0.8828938474437972\n",
      "train loss:0.9279810983584547\n",
      "train loss:0.7907161553514956\n",
      "train loss:0.6237765857327057\n",
      "train loss:0.905572866364831\n",
      "train loss:0.8163929765537772\n",
      "train loss:0.8761344306622721\n",
      "train loss:0.8295362841899799\n",
      "train loss:0.877931775514528\n",
      "train loss:0.9020922199803776\n",
      "train loss:0.866618329224476\n",
      "train loss:0.6402506740761228\n",
      "train loss:0.8181991721144481\n",
      "train loss:0.7617073121344775\n",
      "train loss:0.9200420446151801\n",
      "train loss:0.7258462625233782\n",
      "train loss:0.7373449582112095\n",
      "train loss:0.7276150317143332\n",
      "train loss:0.95902667667445\n",
      "train loss:0.8921759507536186\n",
      "train loss:0.9115397127506587\n",
      "train loss:0.781270154940759\n",
      "train loss:0.8381255987744897\n",
      "train loss:1.0494713770046487\n",
      "train loss:0.7288365425829662\n",
      "train loss:0.7785731348622589\n",
      "train loss:0.7408790441515269\n",
      "train loss:0.8178821777860715\n",
      "train loss:0.7270755211087679\n",
      "train loss:0.9607501587543688\n",
      "train loss:0.7971160754486496\n",
      "train loss:0.8913513073891892\n",
      "train loss:1.0048714956507447\n",
      "train loss:0.8598443984594241\n",
      "train loss:0.8081058266530172\n",
      "train loss:0.9492280666513824\n",
      "train loss:0.8433997404386087\n",
      "train loss:0.8750127242234171\n",
      "train loss:0.9485606322637757\n",
      "train loss:0.8160467210991924\n",
      "train loss:0.9561199459154092\n",
      "train loss:0.7778771995437501\n",
      "train loss:0.9663913322835204\n",
      "train loss:0.7705365640899585\n",
      "train loss:0.7851421514709296\n",
      "train loss:0.7955511655599625\n",
      "train loss:0.9690088334890745\n",
      "train loss:0.8897417812416445\n",
      "train loss:0.8129445901333796\n",
      "train loss:0.8136938860158286\n",
      "train loss:0.8878036842448435\n",
      "train loss:0.8183618061945501\n",
      "train loss:0.9079887003758411\n",
      "train loss:0.9253797927535012\n",
      "train loss:0.8150238831910186\n",
      "train loss:0.9412671943897994\n",
      "train loss:0.8635901399426115\n",
      "train loss:0.7685224083710196\n",
      "train loss:0.9271453028857221\n",
      "train loss:0.7868618498694819\n",
      "train loss:0.8548122277774184\n",
      "train loss:0.7679889394332434\n",
      "train loss:0.9261016363739512\n",
      "train loss:0.7939241159536035\n",
      "train loss:0.8751974906091405\n",
      "train loss:0.9558243471434724\n",
      "train loss:0.8276546702706022\n",
      "train loss:0.6907685200962018\n",
      "train loss:0.9815886562612675\n",
      "train loss:0.7605500013686993\n",
      "train loss:0.7625492418946267\n",
      "train loss:0.9652402242492374\n",
      "train loss:0.9678100420662952\n",
      "train loss:0.8601762385874429\n",
      "train loss:0.8027048405542889\n",
      "train loss:0.9092027705359562\n",
      "train loss:0.7098511031970925\n",
      "train loss:0.9802339803969697\n",
      "train loss:0.8375780542794696\n",
      "train loss:0.751749378614085\n",
      "train loss:0.8640070076906301\n",
      "train loss:0.9175674920706942\n",
      "train loss:0.8497972684409208\n",
      "train loss:0.9790543077654832\n",
      "train loss:0.8988414983258786\n",
      "train loss:0.7888969959809554\n",
      "train loss:0.9495206282238138\n",
      "train loss:0.8172610168131206\n",
      "train loss:0.839112663169161\n",
      "train loss:0.6996965388926492\n",
      "train loss:0.7445619839497575\n",
      "train loss:0.9428352612758265\n",
      "train loss:0.8642202299982883\n",
      "train loss:0.9123527896996069\n",
      "train loss:0.8215305636036396\n",
      "train loss:0.9764478642477621\n",
      "train loss:0.8352290870939987\n",
      "train loss:0.9194324506299927\n",
      "train loss:0.8983094194609716\n",
      "train loss:0.9385017253806057\n",
      "train loss:0.8851902919658657\n",
      "train loss:0.728546528577619\n",
      "train loss:0.8541557894992856\n",
      "train loss:1.1108017802485026\n",
      "train loss:0.8760000438873164\n",
      "train loss:0.9571898534207657\n",
      "train loss:0.9029875532607433\n",
      "train loss:1.0184409160275782\n",
      "train loss:0.9121080341165835\n",
      "train loss:0.8462775097104501\n",
      "train loss:0.9216067726295711\n",
      "train loss:0.7774632118721196\n",
      "train loss:0.8269750655997421\n",
      "train loss:0.8587602338277063\n",
      "train loss:0.9942951056437311\n",
      "train loss:0.9197630873696298\n",
      "train loss:0.7396635088378096\n",
      "train loss:0.9286863336857426\n",
      "train loss:0.7857453885363319\n",
      "train loss:0.9076647869521923\n",
      "train loss:0.8005123475571101\n",
      "train loss:0.7706227649873074\n",
      "train loss:0.7409382078141062\n",
      "train loss:0.9644740870875421\n",
      "train loss:0.9057413241521033\n",
      "train loss:0.8963251128431813\n",
      "train loss:0.8553208991545465\n",
      "train loss:0.6830225666284184\n",
      "train loss:0.9750703981074446\n",
      "train loss:0.8085293536275726\n",
      "train loss:0.9406565128564801\n",
      "train loss:0.748930719785411\n",
      "train loss:0.9966867120117767\n",
      "train loss:1.0274984395217166\n",
      "train loss:0.6738341816108856\n",
      "train loss:1.0341642559764488\n",
      "train loss:0.7871009434894762\n",
      "train loss:0.9743229848080323\n",
      "train loss:0.8415656956205625\n",
      "train loss:0.8846872339928753\n",
      "train loss:0.9742186842837712\n",
      "train loss:0.9313342266940977\n",
      "train loss:0.8961898459700276\n",
      "train loss:0.8382431384651317\n",
      "train loss:0.8477515192532846\n",
      "train loss:0.9420017319404819\n",
      "train loss:0.8558504813602454\n",
      "train loss:0.878247394292402\n",
      "train loss:0.7585520760259513\n",
      "train loss:0.824756436532336\n",
      "train loss:1.0182661917124178\n",
      "train loss:0.9635440831431253\n",
      "train loss:0.8855586119451425\n",
      "train loss:0.8004810552569565\n",
      "train loss:0.9366399613004637\n",
      "train loss:0.9161141585006098\n",
      "train loss:0.9624141238414826\n",
      "train loss:0.8314172842649739\n",
      "train loss:0.7883122633645844\n",
      "train loss:0.9726007760478143\n",
      "train loss:0.8142249228948912\n",
      "train loss:0.8384463439441567\n",
      "train loss:0.7420564197841827\n",
      "train loss:0.8464475002388072\n",
      "train loss:0.7322549414712747\n",
      "train loss:0.8669516965808939\n",
      "train loss:0.8587450697025125\n",
      "train loss:0.9130608207289335\n",
      "train loss:0.8120451200188334\n",
      "train loss:0.9814344986356339\n",
      "train loss:0.968580035427382\n",
      "train loss:1.2505415139463982\n",
      "train loss:0.8164320297294811\n",
      "train loss:0.7670737416491064\n",
      "train loss:0.9478393701723955\n",
      "train loss:0.8874178498522953\n",
      "train loss:1.170006004886838\n",
      "train loss:0.8590181747182727\n",
      "train loss:0.8379733802364097\n",
      "train loss:0.9457420687398289\n",
      "train loss:0.8592993259271349\n",
      "train loss:0.7351522886602306\n",
      "train loss:1.0057920444019752\n",
      "train loss:0.8894827267865162\n",
      "train loss:0.7882785134441942\n",
      "train loss:0.9630422606292965\n",
      "train loss:0.9365022029893059\n",
      "train loss:0.8736748676769741\n",
      "train loss:0.9952291788137938\n",
      "train loss:0.843947658888265\n",
      "train loss:0.7788059918968419\n",
      "train loss:0.7442165933196135\n",
      "train loss:0.8637790152223407\n",
      "train loss:0.782870110545486\n",
      "train loss:0.9107439131960965\n",
      "train loss:0.9329404468263036\n",
      "train loss:0.7873770176047148\n",
      "train loss:0.8669737278533037\n",
      "train loss:0.9435829291778446\n",
      "train loss:0.9835060175634512\n",
      "train loss:0.8864233998280908\n",
      "train loss:0.8540231761688633\n",
      "train loss:1.0321372140502585\n",
      "train loss:0.8712624621755698\n",
      "train loss:0.8489470843844912\n",
      "=== epoch:16, train acc:0.999, test acc:0.989 ===\n",
      "train loss:0.889901448683915\n",
      "train loss:0.8256206020572175\n",
      "train loss:0.8962332822852089\n",
      "train loss:0.7864348890799698\n",
      "train loss:0.6958761803243003\n",
      "train loss:0.7105983832460835\n",
      "train loss:0.7947761499909436\n",
      "train loss:0.8490443483742383\n",
      "train loss:0.7301860684954843\n",
      "train loss:0.9318962572952462\n",
      "train loss:0.7311233435193943\n",
      "train loss:0.9553464930435349\n",
      "train loss:0.8758574807099593\n",
      "train loss:0.7886891341023535\n",
      "train loss:0.9074571725710624\n",
      "train loss:1.0453186717660208\n",
      "train loss:0.8886344106666872\n",
      "train loss:0.9671162280306976\n",
      "train loss:0.8233668947095687\n",
      "train loss:0.852562369293331\n",
      "train loss:0.8522516139950976\n",
      "train loss:0.9294705320803212\n",
      "train loss:0.8761896238622634\n",
      "train loss:0.8286023765390056\n",
      "train loss:1.0227341409074473\n",
      "train loss:0.889423523221132\n",
      "train loss:0.8124478230645577\n",
      "train loss:0.9003356210138115\n",
      "train loss:0.6674676938249426\n",
      "train loss:0.8363244924299097\n",
      "train loss:0.8132980767027196\n",
      "train loss:0.827865155493576\n",
      "train loss:0.966978162537975\n",
      "train loss:0.9685983094160128\n",
      "train loss:0.7540911249823568\n",
      "train loss:0.8300470029579983\n",
      "train loss:0.9148956202481118\n",
      "train loss:0.9383519616926174\n",
      "train loss:0.9178004206850318\n",
      "train loss:0.7906349355019502\n",
      "train loss:0.9346588623429766\n",
      "train loss:0.8977828386141833\n",
      "train loss:0.9391706196417907\n",
      "train loss:0.8558703470428227\n",
      "train loss:0.9780514983824398\n",
      "train loss:0.9162200409705241\n",
      "train loss:0.9428311594293401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7837484106325985\n",
      "train loss:0.9237651164506725\n",
      "train loss:0.8991830202144024\n",
      "train loss:1.0334291990639979\n",
      "train loss:0.6680290252549294\n",
      "train loss:1.083330794454062\n",
      "train loss:0.9920262273665353\n",
      "train loss:0.9358602537608404\n",
      "train loss:0.8805789147784922\n",
      "train loss:0.9864657726990401\n",
      "train loss:0.9481309496318596\n",
      "train loss:1.0055381956894411\n",
      "train loss:0.7717970080152722\n",
      "train loss:1.0459443948343334\n",
      "train loss:1.0418449439766386\n",
      "train loss:0.983178060085683\n",
      "train loss:0.7976068576137573\n",
      "train loss:0.9727886949970608\n",
      "train loss:0.9151344124058283\n",
      "train loss:0.9402394233800578\n",
      "train loss:0.6460024580633851\n",
      "train loss:0.925852308315208\n",
      "train loss:1.0584683038710387\n",
      "train loss:0.9122356407105227\n",
      "train loss:0.9008138833243396\n",
      "train loss:0.7429550355431835\n",
      "train loss:0.8574016231766108\n",
      "train loss:0.9641714001896321\n",
      "train loss:0.8655388160794207\n",
      "train loss:0.9139614397258704\n",
      "train loss:0.8175391414849765\n",
      "train loss:1.093406906395878\n",
      "train loss:0.8342015010913735\n",
      "train loss:0.8816187788988181\n",
      "train loss:0.810312336942442\n",
      "train loss:0.8840873381290605\n",
      "train loss:1.051887317724471\n",
      "train loss:0.7494086810884936\n",
      "train loss:1.091731650172083\n",
      "train loss:0.8943452749846559\n",
      "train loss:0.9669379927201457\n",
      "train loss:0.9924734740222456\n",
      "train loss:0.8708076490403271\n",
      "train loss:1.0658008870110358\n",
      "train loss:1.006890117721585\n",
      "train loss:0.9969402978341967\n",
      "train loss:0.9504917637602683\n",
      "train loss:0.9013649826623493\n",
      "train loss:1.0084921028409268\n",
      "train loss:0.7420650140593004\n",
      "train loss:0.8540222921172378\n",
      "train loss:0.7215863621568688\n",
      "train loss:0.9500105376933914\n",
      "train loss:0.861864521417841\n",
      "train loss:0.964735800031496\n",
      "train loss:0.794833304072025\n",
      "train loss:0.8673589395173784\n",
      "train loss:0.9568089386355222\n",
      "train loss:0.7667744659421044\n",
      "train loss:0.8696063419031872\n",
      "train loss:0.9008985782676195\n",
      "train loss:0.9624321499866003\n",
      "train loss:0.6757350952527168\n",
      "train loss:0.9214362266434267\n",
      "train loss:0.8053873661605989\n",
      "train loss:0.8746439304547005\n",
      "train loss:0.7745110096728045\n",
      "train loss:0.9858703559454082\n",
      "train loss:0.7465635756903296\n",
      "train loss:0.6804229686550148\n",
      "train loss:0.9266501294873014\n",
      "train loss:0.7793492072404926\n",
      "train loss:0.8122174704574789\n",
      "train loss:0.7644989026023193\n",
      "train loss:0.874138399294734\n",
      "train loss:0.8852633611392555\n",
      "train loss:0.7837603020366221\n",
      "train loss:0.8422031202406091\n",
      "train loss:0.954375318039703\n",
      "train loss:0.9355892951178013\n",
      "train loss:0.918969967335076\n",
      "train loss:0.874633582604495\n",
      "train loss:0.9397466247049395\n",
      "train loss:0.9941202504407866\n",
      "train loss:0.7537864594288862\n",
      "train loss:0.7987523993353258\n",
      "train loss:0.7432426939856919\n",
      "train loss:0.8511793924608646\n",
      "train loss:0.8212451902031195\n",
      "train loss:0.8288514120462881\n",
      "train loss:0.8503890764327585\n",
      "train loss:0.7855902943224403\n",
      "train loss:1.0772969864716786\n",
      "train loss:0.963052486874017\n",
      "train loss:0.7403592708769132\n",
      "train loss:0.9606460134244582\n",
      "train loss:0.9665567267477837\n",
      "train loss:1.0005870768093714\n",
      "train loss:0.7989439291054512\n",
      "train loss:0.9350121681612481\n",
      "train loss:0.973382693490483\n",
      "train loss:0.7899620436073823\n",
      "train loss:0.7644800858071776\n",
      "train loss:0.7885153975850149\n",
      "train loss:1.0297472095172988\n",
      "train loss:0.9646517369953043\n",
      "train loss:0.7810921369606469\n",
      "train loss:1.0465754338695648\n",
      "train loss:0.8848800670469932\n",
      "train loss:0.7545907287916264\n",
      "train loss:0.8921146665399122\n",
      "train loss:1.0485356189894386\n",
      "train loss:0.7914962025122583\n",
      "train loss:0.872122317693723\n",
      "train loss:0.8810170579082448\n",
      "train loss:0.9158722126347411\n",
      "train loss:0.8475698570778687\n",
      "train loss:0.7531129500443912\n",
      "train loss:0.7609789378811584\n",
      "train loss:0.8597895874186168\n",
      "train loss:0.8652418611922851\n",
      "train loss:0.7389932614194976\n",
      "train loss:0.9746799975119559\n",
      "train loss:0.8576626279951179\n",
      "train loss:0.9028918552990848\n",
      "train loss:0.7177581197746444\n",
      "train loss:0.9882507787208649\n",
      "train loss:0.7945851039480093\n",
      "train loss:0.9763230365232276\n",
      "train loss:0.860010975063743\n",
      "train loss:0.754254221188644\n",
      "train loss:0.8277973419052838\n",
      "train loss:0.9217272472208083\n",
      "train loss:0.9133840775565066\n",
      "train loss:0.9407781575605177\n",
      "train loss:0.8618652097935666\n",
      "train loss:0.9475902187943681\n",
      "train loss:0.7755930831604049\n",
      "train loss:0.9781754375359145\n",
      "train loss:1.0070633443706822\n",
      "train loss:0.8855429010272176\n",
      "train loss:0.9706883100394407\n",
      "train loss:0.91414015039079\n",
      "train loss:0.859687904569192\n",
      "train loss:0.8236739960072542\n",
      "train loss:0.9310826296887044\n",
      "train loss:0.976990676886231\n",
      "train loss:0.8441599361571988\n",
      "train loss:0.8513244662564294\n",
      "train loss:1.0085659788088601\n",
      "train loss:0.7223880573920495\n",
      "train loss:0.8629374959863548\n",
      "train loss:0.7322729654088608\n",
      "train loss:0.9265833968085885\n",
      "train loss:0.9567810339744317\n",
      "train loss:0.9547600962558408\n",
      "train loss:0.8626616644590166\n",
      "train loss:0.7510323139133334\n",
      "train loss:0.7258917227941504\n",
      "train loss:0.9835736372348951\n",
      "train loss:0.7930832744317933\n",
      "train loss:1.1297298600796943\n",
      "train loss:0.7944876654978016\n",
      "train loss:1.032797634676206\n",
      "train loss:0.9363526042918774\n",
      "train loss:0.7524210901727703\n",
      "train loss:0.8718828682768909\n",
      "train loss:0.9990955344234216\n",
      "train loss:0.8124385598252214\n",
      "train loss:0.7921882005923248\n",
      "train loss:0.9068597212897012\n",
      "train loss:0.9586427417545518\n",
      "train loss:0.902919702387791\n",
      "train loss:0.7828302775103009\n",
      "train loss:0.6946909968950747\n",
      "train loss:0.8243801784899304\n",
      "train loss:0.8530325254151749\n",
      "train loss:0.8538952127019015\n",
      "train loss:0.780068145341303\n",
      "train loss:0.8889932110972003\n",
      "train loss:0.8335725995938463\n",
      "train loss:0.8401997722688829\n",
      "train loss:0.8081561908183413\n",
      "train loss:0.8681797614649446\n",
      "train loss:0.996485787215677\n",
      "train loss:0.7842319804988214\n",
      "train loss:0.8918784606381629\n",
      "train loss:0.8704431050103536\n",
      "train loss:0.9319470892740175\n",
      "train loss:0.7596617792072824\n",
      "train loss:0.8466458947702126\n",
      "train loss:0.8215093538145207\n",
      "train loss:0.6926650296668491\n",
      "train loss:1.0334140987621896\n",
      "train loss:0.8237175462116363\n",
      "train loss:0.777221474436498\n",
      "train loss:0.8894323287864269\n",
      "train loss:0.9605789056166613\n",
      "train loss:0.7960238100394694\n",
      "train loss:0.979623532618527\n",
      "train loss:0.8079398215571384\n",
      "train loss:0.8471706711998359\n",
      "train loss:0.7857227554547702\n",
      "train loss:0.9798011195507037\n",
      "train loss:0.9077262256571614\n",
      "train loss:0.8497435050465947\n",
      "train loss:0.7923812126753789\n",
      "train loss:0.9402513157937709\n",
      "train loss:0.9591823012756668\n",
      "train loss:0.8842663590190603\n",
      "train loss:0.7254769188698869\n",
      "train loss:0.8604579875132242\n",
      "train loss:0.8005406324945038\n",
      "train loss:0.8848413154212379\n",
      "train loss:0.7448822280556842\n",
      "train loss:0.8504784248072\n",
      "train loss:0.8379511634456874\n",
      "train loss:0.9607407041190499\n",
      "train loss:0.7899308863564779\n",
      "train loss:0.7746592331301116\n",
      "train loss:0.8234461655518858\n",
      "train loss:1.0330958030182271\n",
      "train loss:0.9145638982604709\n",
      "train loss:0.8846220719816347\n",
      "train loss:0.9217868002016584\n",
      "train loss:0.907534601497768\n",
      "train loss:0.8021512084078494\n",
      "train loss:0.836251780466965\n",
      "train loss:0.9470388877256234\n",
      "train loss:0.8351060935377141\n",
      "train loss:0.8270725156716\n",
      "train loss:0.9211960350728221\n",
      "train loss:0.8520407496273528\n",
      "train loss:0.9312220965509799\n",
      "train loss:0.9474927667957718\n",
      "train loss:0.9769621268324395\n",
      "train loss:1.0231857938700677\n",
      "train loss:0.7798484270987955\n",
      "train loss:0.7625923967221722\n",
      "train loss:0.8208816079295462\n",
      "train loss:0.8319707340539472\n",
      "train loss:0.9831925017919722\n",
      "train loss:0.7738415277767927\n",
      "train loss:0.9839202134216805\n",
      "train loss:0.9817180867077511\n",
      "train loss:0.7788666082513613\n",
      "train loss:0.9764476837311216\n",
      "train loss:0.957100894912971\n",
      "train loss:0.7169020143442114\n",
      "train loss:0.6419299714723898\n",
      "train loss:0.8292998507307864\n",
      "train loss:0.7963230968049406\n",
      "train loss:0.9011061119456093\n",
      "train loss:0.8248316454469482\n",
      "train loss:0.8041894471026215\n",
      "train loss:0.8046406631415965\n",
      "train loss:0.8786076484684021\n",
      "train loss:0.7371908519836289\n",
      "train loss:0.7835427924658385\n",
      "train loss:0.9164501080253956\n",
      "train loss:0.7586739100109752\n",
      "train loss:0.8928084002601594\n",
      "train loss:0.8563964068156177\n",
      "train loss:0.7984087723852855\n",
      "train loss:0.999799885131474\n",
      "train loss:0.7848757188036601\n",
      "train loss:0.8560653780165731\n",
      "train loss:0.9661610194112559\n",
      "train loss:0.7376379846003981\n",
      "train loss:0.9224367050576129\n",
      "train loss:0.9039341264625278\n",
      "train loss:0.8703221462756785\n",
      "train loss:0.930909202427414\n",
      "train loss:0.8418341933662374\n",
      "train loss:0.8400520364650323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9111660301108633\n",
      "train loss:0.8300446139535714\n",
      "train loss:0.9451041395459153\n",
      "train loss:0.9359137826042793\n",
      "train loss:0.8677584611522912\n",
      "train loss:0.7788169264779167\n",
      "train loss:0.709280260271984\n",
      "train loss:0.8268926217631452\n",
      "train loss:0.8525270783447528\n",
      "train loss:0.7245622595277795\n",
      "train loss:0.9614417813594384\n",
      "train loss:0.9079104739119953\n",
      "train loss:0.7979703579197621\n",
      "train loss:0.8267469885886869\n",
      "train loss:0.8773112979720598\n",
      "train loss:1.0479130706601107\n",
      "train loss:1.037816866543603\n",
      "train loss:0.8860087445482496\n",
      "train loss:0.711878509158915\n",
      "train loss:0.7308628178264598\n",
      "train loss:0.6653653458360185\n",
      "train loss:0.9274437004456404\n",
      "train loss:0.7167763516448576\n",
      "train loss:0.7137972964258826\n",
      "train loss:0.7497720842386738\n",
      "train loss:0.9043870370318284\n",
      "train loss:0.9440507322095748\n",
      "train loss:0.8790232596009407\n",
      "train loss:0.7935481078507288\n",
      "train loss:0.7372569089056646\n",
      "train loss:0.9454025744115817\n",
      "train loss:0.8166641148121073\n",
      "train loss:0.9095459545274626\n",
      "train loss:0.8642267825531755\n",
      "train loss:0.8888868583432344\n",
      "train loss:0.8840428493338254\n",
      "train loss:0.9277806342361443\n",
      "train loss:0.6862365651940201\n",
      "train loss:0.8114585288884945\n",
      "train loss:0.9966329668153339\n",
      "train loss:0.6753432697334302\n",
      "train loss:0.9657873241275347\n",
      "train loss:0.9227373490349733\n",
      "train loss:0.8582498643326492\n",
      "train loss:0.9480203525825454\n",
      "train loss:0.8006403295442485\n",
      "train loss:0.8452313762403818\n",
      "train loss:0.9292655768628427\n",
      "train loss:0.7002262511674079\n",
      "train loss:0.9382506900337367\n",
      "train loss:0.9013508142414666\n",
      "train loss:0.9096183216027114\n",
      "train loss:0.8300201719736444\n",
      "train loss:0.7110491884784632\n",
      "train loss:0.9416342850833\n",
      "train loss:0.5776108672890349\n",
      "train loss:0.8271412157476283\n",
      "train loss:0.8253425725782736\n",
      "train loss:0.7901337771028224\n",
      "train loss:0.8637276832658665\n",
      "train loss:0.9018458525517772\n",
      "train loss:0.8472394305944025\n",
      "train loss:0.7369899599519191\n",
      "train loss:0.7800652154091382\n",
      "train loss:0.6847681391616754\n",
      "train loss:0.9307297639866018\n",
      "train loss:0.8436535723632804\n",
      "train loss:0.8984737058741284\n",
      "train loss:0.9596732633958759\n",
      "train loss:0.9258757726270731\n",
      "train loss:0.8203408644626343\n",
      "train loss:0.8497213194078307\n",
      "train loss:0.6117211986568433\n",
      "train loss:0.7962978847902442\n",
      "train loss:0.8897418839063326\n",
      "train loss:0.9662377038356743\n",
      "train loss:0.7818022895395781\n",
      "train loss:0.8513984734088399\n",
      "train loss:0.8631646183665981\n",
      "train loss:0.7720153481462545\n",
      "train loss:0.7878062789294052\n",
      "train loss:0.8160152878852968\n",
      "train loss:0.8914615318124065\n",
      "train loss:0.906723419174513\n",
      "train loss:0.8512113996695428\n",
      "train loss:0.8284737253336181\n",
      "train loss:0.8551179495898467\n",
      "train loss:0.818138247432274\n",
      "train loss:0.8856722792383402\n",
      "train loss:0.9248931392123018\n",
      "train loss:0.9242966467731272\n",
      "train loss:0.9919254051809838\n",
      "train loss:0.8971051682141323\n",
      "train loss:0.7317103914899493\n",
      "train loss:0.9697519879095867\n",
      "train loss:0.8322152710535663\n",
      "train loss:0.9431098701459142\n",
      "train loss:0.9915251456874502\n",
      "train loss:0.8849964141664773\n",
      "train loss:0.8374603942981059\n",
      "train loss:0.8087609088460626\n",
      "train loss:0.8078182368764008\n",
      "train loss:1.0025120013671476\n",
      "train loss:0.7766375013193086\n",
      "train loss:0.9781275742242517\n",
      "train loss:1.0073013794420969\n",
      "train loss:0.770405157264128\n",
      "train loss:0.9532725538996423\n",
      "train loss:0.9432813904351031\n",
      "train loss:0.7188285861720156\n",
      "train loss:1.0361093507522834\n",
      "train loss:0.8619279971290638\n",
      "train loss:0.8924066565216219\n",
      "train loss:1.0613325516153373\n",
      "train loss:0.8925840130139566\n",
      "train loss:0.8935221477036851\n",
      "train loss:0.8440016492578915\n",
      "train loss:0.8359077963768696\n",
      "train loss:0.871991195504282\n",
      "train loss:0.8740431014574536\n",
      "train loss:0.7995006824874412\n",
      "train loss:0.865910430636125\n",
      "train loss:0.9661877014660278\n",
      "train loss:0.9418535360196139\n",
      "train loss:0.9040901820586982\n",
      "train loss:0.8954593848185449\n",
      "train loss:1.0422208628227907\n",
      "train loss:0.9781449950126162\n",
      "train loss:0.8509305879851823\n",
      "train loss:0.8728756843168476\n",
      "train loss:0.9678064047225478\n",
      "train loss:0.9123600755596694\n",
      "train loss:0.8710489698697347\n",
      "train loss:0.7018715980803542\n",
      "train loss:0.7546641118461881\n",
      "train loss:0.7949570572334104\n",
      "train loss:0.9543073135676646\n",
      "train loss:0.7659100564499184\n",
      "train loss:0.7210408008797207\n",
      "train loss:0.9188227757046369\n",
      "train loss:0.8854781070391924\n",
      "train loss:0.8026029958532012\n",
      "train loss:0.965679803714533\n",
      "train loss:0.9302107017165667\n",
      "train loss:0.8530788165226137\n",
      "train loss:0.8736631265113535\n",
      "train loss:0.7479825014214596\n",
      "train loss:0.7521324836812397\n",
      "train loss:0.847991763055887\n",
      "train loss:0.808513892294934\n",
      "train loss:0.7571029120876582\n",
      "train loss:0.9591518025910071\n",
      "train loss:0.8054735077922877\n",
      "train loss:0.7705493246026173\n",
      "train loss:1.1957185330025575\n",
      "train loss:0.9234596928645681\n",
      "train loss:0.81823357201402\n",
      "train loss:0.9590444140383044\n",
      "train loss:0.7970688603463455\n",
      "train loss:0.9208913946093156\n",
      "train loss:0.7787463612933059\n",
      "train loss:0.9412472500760236\n",
      "train loss:1.0112165748252147\n",
      "train loss:0.9013206247785159\n",
      "train loss:0.808621138005764\n",
      "train loss:0.7505370877932573\n",
      "train loss:0.9101143165855795\n",
      "train loss:0.6611469104139753\n",
      "train loss:0.9393114507551011\n",
      "train loss:0.7581731123083472\n",
      "train loss:0.881366530386644\n",
      "train loss:0.866286649229429\n",
      "train loss:0.6913507067239466\n",
      "train loss:1.0863820674448994\n",
      "train loss:0.8023889906254662\n",
      "train loss:0.8956647924695897\n",
      "train loss:0.7535868490736575\n",
      "train loss:0.6843974640262529\n",
      "train loss:0.9202765741598321\n",
      "train loss:0.8653959315013746\n",
      "train loss:0.7711775370807561\n",
      "train loss:0.7927346066937314\n",
      "train loss:0.8000594886923674\n",
      "train loss:0.871881639004171\n",
      "train loss:0.9492371632678346\n",
      "train loss:1.0161667546834552\n",
      "train loss:0.7273658259631561\n",
      "train loss:0.8597510579842528\n",
      "train loss:0.8681164338840603\n",
      "train loss:0.9609471455191974\n",
      "train loss:0.8300317363727572\n",
      "train loss:0.8906065346684063\n",
      "train loss:0.9130051365353212\n",
      "train loss:0.8412339462220774\n",
      "train loss:0.9589980375087217\n",
      "train loss:0.8578046345604491\n",
      "train loss:0.7584722504647923\n",
      "train loss:0.9830299741949992\n",
      "train loss:0.749677106119683\n",
      "train loss:1.0118856212582283\n",
      "train loss:0.9817150189113825\n",
      "train loss:0.8258771576487476\n",
      "train loss:0.9583251124802338\n",
      "train loss:0.9138748167009422\n",
      "train loss:0.8914752265022193\n",
      "train loss:1.0762901983412891\n",
      "train loss:0.8309988762876129\n",
      "train loss:0.8246477229700954\n",
      "train loss:1.0413397499934904\n",
      "train loss:0.8629791044436843\n",
      "train loss:0.781439933190724\n",
      "train loss:0.919807158978497\n",
      "train loss:0.7871261901449685\n",
      "train loss:0.9831234228879145\n",
      "train loss:1.0035884941073236\n",
      "train loss:0.6899499424978915\n",
      "train loss:0.8885438057927217\n",
      "train loss:0.8323083237260349\n",
      "train loss:0.9176002706511052\n",
      "train loss:0.8585714848086959\n",
      "train loss:0.9250827146953228\n",
      "train loss:0.766903580571949\n",
      "train loss:0.8631083386383916\n",
      "train loss:0.8423017003680121\n",
      "train loss:0.8794124972226903\n",
      "train loss:0.9581944622198602\n",
      "train loss:0.8248538218844175\n",
      "train loss:0.8938034628661553\n",
      "train loss:0.7941486667272543\n",
      "train loss:0.9995574183242492\n",
      "train loss:0.9631844459450976\n",
      "train loss:0.9337769630069378\n",
      "train loss:1.0219952899429796\n",
      "train loss:0.8308182284740905\n",
      "train loss:0.8869011162243737\n",
      "train loss:0.9097880523168941\n",
      "train loss:0.8685698655535681\n",
      "train loss:0.7436328664766133\n",
      "train loss:0.9491250839524826\n",
      "train loss:0.9722841758480534\n",
      "train loss:0.8540808035828994\n",
      "train loss:0.7813442929869742\n",
      "train loss:0.9328171801203932\n",
      "train loss:1.040325870967578\n",
      "train loss:0.9222074235837738\n",
      "train loss:0.7241617328253068\n",
      "train loss:0.8005033886902063\n",
      "train loss:0.9937850344720007\n",
      "train loss:0.9417293649681464\n",
      "train loss:0.8695883813027252\n",
      "train loss:0.9057538605626873\n",
      "train loss:0.9279284663839542\n",
      "train loss:0.8772465096575499\n",
      "train loss:0.7923754589781419\n",
      "train loss:0.9645518888012121\n",
      "train loss:0.927760608133656\n",
      "train loss:0.8783287259441656\n",
      "train loss:0.9236603246157975\n",
      "train loss:0.9066475399393031\n",
      "train loss:0.954464151316753\n",
      "train loss:0.9695985979073443\n",
      "train loss:0.7188054833230302\n",
      "train loss:0.8719543043820026\n",
      "train loss:0.9973384684944697\n",
      "train loss:0.9919279307560588\n",
      "train loss:0.8611601404129817\n",
      "train loss:0.8098527199254293\n",
      "train loss:0.8982457719518006\n",
      "train loss:0.900224988292632\n",
      "train loss:0.7725183846817391\n",
      "train loss:0.8927896257141825\n",
      "train loss:0.9677051599025508\n",
      "train loss:0.9924674136946666\n",
      "train loss:1.0323773450763698\n",
      "train loss:0.9725570526483501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8382810180737631\n",
      "train loss:0.9126446581346968\n",
      "train loss:0.9486325668278635\n",
      "=== epoch:17, train acc:0.996, test acc:0.991 ===\n",
      "train loss:0.9844119843914854\n",
      "train loss:0.7413870956930951\n",
      "train loss:0.9298570842575653\n",
      "train loss:0.59655405302548\n",
      "train loss:0.8994273307915835\n",
      "train loss:0.8713068728053013\n",
      "train loss:0.8823731949659305\n",
      "train loss:1.0150493406236476\n",
      "train loss:0.9033579034293677\n",
      "train loss:0.8291939430244571\n",
      "train loss:0.9191972084522692\n",
      "train loss:0.8923703227937804\n",
      "train loss:0.9117188147949652\n",
      "train loss:1.0004472617986753\n",
      "train loss:0.9239726688177423\n",
      "train loss:0.9661837476627612\n",
      "train loss:0.8019975366995108\n",
      "train loss:0.9089184938603484\n",
      "train loss:0.6947183460806856\n",
      "train loss:0.9847597379116847\n",
      "train loss:0.7769778662240365\n",
      "train loss:0.8635426482854733\n",
      "train loss:0.8965960717135036\n",
      "train loss:1.0256371122498031\n",
      "train loss:0.8944336373084678\n",
      "train loss:0.9232048672618441\n",
      "train loss:0.8226775942631122\n",
      "train loss:0.7827037305450113\n",
      "train loss:0.8876736699124897\n",
      "train loss:0.7646970131688482\n",
      "train loss:0.949599835130698\n",
      "train loss:0.8773796163714348\n",
      "train loss:0.8350393691299801\n",
      "train loss:0.897123320384563\n",
      "train loss:0.9536817538364523\n",
      "train loss:1.0620291510747208\n",
      "train loss:0.8719391495722059\n",
      "train loss:0.8567266949410935\n",
      "train loss:0.8006645655594294\n",
      "train loss:0.7832344648071917\n",
      "train loss:0.7857237320588805\n",
      "train loss:0.9449076895328935\n",
      "train loss:0.8070556355646659\n",
      "train loss:0.8656662765043827\n",
      "train loss:0.8772618712146624\n",
      "train loss:1.1246836911318352\n",
      "train loss:0.9712855453133133\n",
      "train loss:0.8029314960255052\n",
      "train loss:0.7949392638618913\n",
      "train loss:0.7892489678137035\n",
      "train loss:0.8221457592702123\n",
      "train loss:1.0028797092211688\n",
      "train loss:0.8778835228082711\n",
      "train loss:0.847347911978626\n",
      "train loss:0.7834236259834078\n",
      "train loss:0.9236599605257855\n",
      "train loss:1.0097772356260273\n",
      "train loss:0.8714371836904684\n",
      "train loss:0.9541556361562578\n",
      "train loss:0.7996419784719823\n",
      "train loss:1.0025882535799417\n",
      "train loss:0.862716333876052\n",
      "train loss:0.8383554374267027\n",
      "train loss:1.0343164601573243\n",
      "train loss:0.7955215553427037\n",
      "train loss:0.7507416611300002\n",
      "train loss:0.6022684987679894\n",
      "train loss:0.6739741174467702\n",
      "train loss:0.8538792434547068\n",
      "train loss:0.8665122613835524\n",
      "train loss:0.6620660845101881\n",
      "train loss:1.0018967056565786\n",
      "train loss:0.8500235078977676\n",
      "train loss:0.7787505661544408\n",
      "train loss:0.7896100493499383\n",
      "train loss:0.8747239007920753\n",
      "train loss:0.9088941043410249\n",
      "train loss:0.8015851898281946\n",
      "train loss:0.9114910310120957\n",
      "train loss:1.0014119557708208\n",
      "train loss:1.0066920620828193\n",
      "train loss:0.8785140552012034\n",
      "train loss:0.8745550852505627\n",
      "train loss:0.8797320016770672\n",
      "train loss:1.0607070011266517\n",
      "train loss:0.9514127368477802\n",
      "train loss:0.8636532552278774\n",
      "train loss:0.8780421880520062\n",
      "train loss:0.7593457424470421\n",
      "train loss:0.8893473299542717\n",
      "train loss:0.8419372520777102\n",
      "train loss:0.9778925610807727\n",
      "train loss:0.8961162340862622\n",
      "train loss:0.8706443180346791\n",
      "train loss:0.7796261131701943\n",
      "train loss:0.9575208059902371\n",
      "train loss:0.9292216264299836\n",
      "train loss:0.7576476827017724\n",
      "train loss:1.0259505568538803\n",
      "train loss:0.9566901648633435\n",
      "train loss:0.9365233984636565\n",
      "train loss:0.9398725921749213\n",
      "train loss:0.9484157835777305\n",
      "train loss:0.9299010405405835\n",
      "train loss:0.8127490210190254\n",
      "train loss:0.7793182440216743\n",
      "train loss:0.7798157139105882\n",
      "train loss:0.9226374244423389\n",
      "train loss:0.9887066207876316\n",
      "train loss:0.8617014481476261\n",
      "train loss:0.8567678572183166\n",
      "train loss:0.5812876057592229\n",
      "train loss:0.969678634294435\n",
      "train loss:1.0468701331189216\n",
      "train loss:0.9377739943528383\n",
      "train loss:0.8512394355017492\n",
      "train loss:0.9520210242425405\n",
      "train loss:0.9286320768679773\n",
      "train loss:0.9645614073176315\n",
      "train loss:0.7399418855595548\n",
      "train loss:0.734878060261535\n",
      "train loss:0.8594094581134162\n",
      "train loss:0.7975674383656363\n",
      "train loss:0.9356860750229372\n",
      "train loss:0.9397260879895086\n",
      "train loss:0.9988171399171608\n",
      "train loss:0.8232821983572604\n",
      "train loss:0.6669019901095169\n",
      "train loss:0.9539888704694764\n",
      "train loss:0.7214016844657478\n",
      "train loss:0.8091140113683762\n",
      "train loss:1.1066833123267914\n",
      "train loss:0.8887797918440534\n",
      "train loss:1.0677336944335607\n",
      "train loss:0.7955540541889229\n",
      "train loss:0.9045389383207462\n",
      "train loss:0.8316285360572964\n",
      "train loss:1.0840543053006428\n",
      "train loss:0.9335056834511755\n",
      "train loss:1.0069571859020257\n",
      "train loss:1.0848892437979272\n",
      "train loss:0.7172174924252187\n",
      "train loss:0.9212835069397891\n",
      "train loss:0.7963532456793001\n",
      "train loss:0.9169324549886758\n",
      "train loss:1.0207316347643292\n",
      "train loss:0.8372955773026023\n",
      "train loss:0.7744589601270505\n",
      "train loss:0.7885482668609329\n",
      "train loss:0.793629471273628\n",
      "train loss:0.7105163711204451\n",
      "train loss:1.0097442992721335\n",
      "train loss:0.7338005885298127\n",
      "train loss:0.8726227556406556\n",
      "train loss:0.8002572702870371\n",
      "train loss:0.9567383929731461\n",
      "train loss:0.7693371544116724\n",
      "train loss:0.7916854172015146\n",
      "train loss:0.8363571658559846\n",
      "train loss:0.8484353816087717\n",
      "train loss:0.8484551491884905\n",
      "train loss:0.8969165841884452\n",
      "train loss:0.7162806436306223\n",
      "train loss:0.9179870940039494\n",
      "train loss:0.739767233619879\n",
      "train loss:0.8272354164559296\n",
      "train loss:0.9618079669660885\n",
      "train loss:0.8644363672653895\n",
      "train loss:0.9734877178964402\n",
      "train loss:0.7960105530744768\n",
      "train loss:0.8805993038866667\n",
      "train loss:0.9203076911176913\n",
      "train loss:0.942777461967525\n",
      "train loss:0.7965379352785146\n",
      "train loss:0.8768145350169851\n",
      "train loss:0.8972493365733913\n",
      "train loss:0.9526723311544535\n",
      "train loss:0.8443495575968959\n",
      "train loss:0.8157070404139133\n",
      "train loss:0.9357847126166732\n",
      "train loss:0.8844419248122368\n",
      "train loss:0.7800437086712856\n",
      "train loss:0.7965582789937636\n",
      "train loss:0.7980954685813663\n",
      "train loss:0.782738145125243\n",
      "train loss:0.8226526673039242\n",
      "train loss:0.9150338912602866\n",
      "train loss:0.7364846746206132\n",
      "train loss:0.9382658933606538\n",
      "train loss:0.9638973534515746\n",
      "train loss:0.8391459630618301\n",
      "train loss:0.7455361188703846\n",
      "train loss:0.9125387354086975\n",
      "train loss:0.7760505753620563\n",
      "train loss:0.9110193742168989\n",
      "train loss:0.8835604896568638\n",
      "train loss:0.7797627192240671\n",
      "train loss:0.8171297994111048\n",
      "train loss:0.9469717789569649\n",
      "train loss:0.8355842458863839\n",
      "train loss:0.7898324904804999\n",
      "train loss:0.835969913287365\n",
      "train loss:0.8121621993188124\n",
      "train loss:0.7924240588569661\n",
      "train loss:0.8049049372513495\n",
      "train loss:0.8766484703611281\n",
      "train loss:0.7213799190190286\n",
      "train loss:0.8788935329129408\n",
      "train loss:0.8535096053711907\n",
      "train loss:0.8505827031355894\n",
      "train loss:0.816660558312533\n",
      "train loss:0.9887293415768782\n",
      "train loss:1.0450562921059146\n",
      "train loss:0.7586234627565033\n",
      "train loss:1.0687796881596419\n",
      "train loss:0.8568451665436189\n",
      "train loss:0.7665530165445904\n",
      "train loss:0.814958888249179\n",
      "train loss:0.8247873375899433\n",
      "train loss:0.8501725403871526\n",
      "train loss:0.8959682552515447\n",
      "train loss:0.9321234498448996\n",
      "train loss:0.9035282510138753\n",
      "train loss:0.9083953013370016\n",
      "train loss:0.797482558946561\n",
      "train loss:0.9462815224326261\n",
      "train loss:0.9292592160895271\n",
      "train loss:0.9824373500284698\n",
      "train loss:0.8195136206878244\n",
      "train loss:0.8337964454564788\n",
      "train loss:1.0617784315046739\n",
      "train loss:0.9095265740574128\n",
      "train loss:0.9559591898678906\n",
      "train loss:0.9182928089302814\n",
      "train loss:0.9196009441364665\n",
      "train loss:0.7823546024944651\n",
      "train loss:0.8464457628092079\n",
      "train loss:1.013464231708429\n",
      "train loss:0.8189998386585142\n",
      "train loss:1.1029076978830412\n",
      "train loss:0.8992599541360451\n",
      "train loss:0.9202135817888939\n",
      "train loss:0.9395856504274965\n",
      "train loss:0.7946169261829568\n",
      "train loss:0.9966808552884939\n",
      "train loss:0.9211641009997027\n",
      "train loss:0.9666581536036019\n",
      "train loss:0.8987399531206333\n",
      "train loss:0.8794737211830942\n",
      "train loss:0.8671623283860938\n",
      "train loss:0.8563093809717643\n",
      "train loss:0.8093879634510744\n",
      "train loss:0.740907548527777\n",
      "train loss:0.7917650076357197\n",
      "train loss:0.6938513495401127\n",
      "train loss:1.0676923053849234\n",
      "train loss:0.8199510984774413\n",
      "train loss:0.8223265453045348\n",
      "train loss:0.9236059002818559\n",
      "train loss:0.869292968840028\n",
      "train loss:0.8665558834625589\n",
      "train loss:0.7806370749583338\n",
      "train loss:0.7894739334576366\n",
      "train loss:0.9547095159526553\n",
      "train loss:0.8158495889607561\n",
      "train loss:0.7829551521022964\n",
      "train loss:0.8369346417876984\n",
      "train loss:0.9378815151959092\n",
      "train loss:0.8703634955885394\n",
      "train loss:0.9123915149696293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7725201877164057\n",
      "train loss:0.9056023896903893\n",
      "train loss:0.7016713759368575\n",
      "train loss:0.8584882012224203\n",
      "train loss:0.9804151073632213\n",
      "train loss:1.0225484074987379\n",
      "train loss:0.760669795553539\n",
      "train loss:0.793561178815078\n",
      "train loss:0.8041070418788605\n",
      "train loss:0.9427300440387453\n",
      "train loss:0.7769476880390542\n",
      "train loss:0.8532776024501139\n",
      "train loss:0.9016335084440685\n",
      "train loss:0.8857878805035565\n",
      "train loss:0.7444784076289517\n",
      "train loss:0.8189442940781096\n",
      "train loss:0.6763336773594655\n",
      "train loss:0.8814530141473661\n",
      "train loss:0.9434090145410329\n",
      "train loss:0.968725800210644\n",
      "train loss:0.7850567031153816\n",
      "train loss:0.8546831417017766\n",
      "train loss:0.7019131005317755\n",
      "train loss:0.7602825731891025\n",
      "train loss:0.8038455834267354\n",
      "train loss:0.7974973345108287\n",
      "train loss:0.97633071099386\n",
      "train loss:0.8502731303845313\n",
      "train loss:0.8977686376722849\n",
      "train loss:0.9286253671147121\n",
      "train loss:0.8484560390743877\n",
      "train loss:0.9609888191963304\n",
      "train loss:0.9317547082253423\n",
      "train loss:0.7142924959350713\n",
      "train loss:1.0532632552031465\n",
      "train loss:0.9241076914719182\n",
      "train loss:0.8055361281261878\n",
      "train loss:0.9387981879228025\n",
      "train loss:0.8188124406802174\n",
      "train loss:0.7798541551104826\n",
      "train loss:1.000885262235584\n",
      "train loss:0.8343481397130843\n",
      "train loss:0.9647034258702735\n",
      "train loss:0.8816402816827779\n",
      "train loss:0.8209673164517898\n",
      "train loss:0.9469500198511596\n",
      "train loss:0.9644022542686551\n",
      "train loss:0.7578126120219568\n",
      "train loss:0.8983450434087961\n",
      "train loss:0.8775670542916246\n",
      "train loss:0.9066579502640217\n",
      "train loss:0.9784051773762249\n",
      "train loss:0.8750026947750829\n",
      "train loss:0.9578381468949219\n",
      "train loss:0.9653623021647454\n",
      "train loss:0.9213986626263245\n",
      "train loss:1.0203584260821765\n",
      "train loss:1.085677395534217\n",
      "train loss:0.9791993417959332\n",
      "train loss:0.8209016051035745\n",
      "train loss:0.8773518646999751\n",
      "train loss:0.9493977783341139\n",
      "train loss:0.9706682991123479\n",
      "train loss:0.9414704054471901\n",
      "train loss:1.0524796165173016\n",
      "train loss:0.8044199243032711\n",
      "train loss:0.9143888880016339\n",
      "train loss:0.884511110005944\n",
      "train loss:0.7731904262620085\n",
      "train loss:0.9761679234857212\n",
      "train loss:0.8806472061279887\n",
      "train loss:0.748987969215642\n",
      "train loss:0.8612753160327878\n",
      "train loss:0.8531349604996025\n",
      "train loss:0.8624443912953801\n",
      "train loss:0.8392827822856206\n",
      "train loss:1.0036334728184668\n",
      "train loss:0.9199854217667788\n",
      "train loss:0.991033836280228\n",
      "train loss:0.7363035921759682\n",
      "train loss:0.8846251181651481\n",
      "train loss:0.9323157330275952\n",
      "train loss:0.8629562152688783\n",
      "train loss:0.9653122046794551\n",
      "train loss:0.878260087058934\n",
      "train loss:0.9108717776745417\n",
      "train loss:0.8478173334419137\n",
      "train loss:0.8551462443835324\n",
      "train loss:0.8853166335263842\n",
      "train loss:0.9248330631636591\n",
      "train loss:0.8794576346265608\n",
      "train loss:0.9815962387588607\n",
      "train loss:0.8629736321285877\n",
      "train loss:0.8193845542285646\n",
      "train loss:0.9081770852918958\n",
      "train loss:0.8604901532322872\n",
      "train loss:0.9056476973823453\n",
      "train loss:0.8657623270179755\n",
      "train loss:0.9669963795419235\n",
      "train loss:0.9328052206635631\n",
      "train loss:0.9888114844300211\n",
      "train loss:0.7636524064490411\n",
      "train loss:0.8080578288558554\n",
      "train loss:0.8640187473792692\n",
      "train loss:0.7522700973280244\n",
      "train loss:0.78887870391722\n",
      "train loss:0.8422437946875889\n",
      "train loss:0.9415393139765245\n",
      "train loss:0.8703103257579048\n",
      "train loss:1.00345638717022\n",
      "train loss:0.9546112776478202\n",
      "train loss:0.8933175268406331\n",
      "train loss:0.8556520117941888\n",
      "train loss:0.7355326848109381\n",
      "train loss:0.7744596737250962\n",
      "train loss:0.9553803976307315\n",
      "train loss:0.8454414277321262\n",
      "train loss:0.919929589894632\n",
      "train loss:0.8856405014069995\n",
      "train loss:0.7977057047248409\n",
      "train loss:1.0074509647457908\n",
      "train loss:0.9187987564236572\n",
      "train loss:0.9958018531226923\n",
      "train loss:0.9483982694238997\n",
      "train loss:0.9133246273855995\n",
      "train loss:1.1090809089834595\n",
      "train loss:0.9444013896545055\n",
      "train loss:0.956514601900874\n",
      "train loss:0.8933273759115281\n",
      "train loss:0.8997664492136783\n",
      "train loss:0.7797265279685186\n",
      "train loss:0.8767551174683345\n",
      "train loss:0.8668911943650088\n",
      "train loss:0.8970821250510231\n",
      "train loss:0.6773917469789946\n",
      "train loss:0.895270694234943\n",
      "train loss:0.8868159163617096\n",
      "train loss:0.9285866947306125\n",
      "train loss:0.896140968202795\n",
      "train loss:0.7972379790304899\n",
      "train loss:0.9634480067778715\n",
      "train loss:0.8824271774792014\n",
      "train loss:0.8751983084000835\n",
      "train loss:0.837668229074313\n",
      "train loss:0.8906651323272549\n",
      "train loss:0.9195876239484656\n",
      "train loss:0.8032606355843942\n",
      "train loss:0.9013041367720276\n",
      "train loss:0.8730898171230365\n",
      "train loss:0.8147305540623457\n",
      "train loss:0.9295944876695811\n",
      "train loss:0.8651838642092093\n",
      "train loss:0.6833591560266467\n",
      "train loss:0.7987162229296167\n",
      "train loss:0.8560003870697795\n",
      "train loss:0.8969380835184075\n",
      "train loss:0.8636951747941972\n",
      "train loss:0.7961747648635918\n",
      "train loss:0.7210678038954308\n",
      "train loss:0.7704512020263081\n",
      "train loss:0.7861108321828644\n",
      "train loss:0.8572687071520515\n",
      "train loss:0.8491249563436315\n",
      "train loss:0.7159095823217908\n",
      "train loss:0.822386280723279\n",
      "train loss:0.8776950706516469\n",
      "train loss:0.9577854986122677\n",
      "train loss:1.1022132474028807\n",
      "train loss:0.8013974328658268\n",
      "train loss:0.8211554809775663\n",
      "train loss:0.8250844952629391\n",
      "train loss:0.9218462050860536\n",
      "train loss:0.7764934364674966\n",
      "train loss:0.9858222160477493\n",
      "train loss:0.9543701569730283\n",
      "train loss:0.866274470419335\n",
      "train loss:0.8428241156133963\n",
      "train loss:0.8165240717796383\n",
      "train loss:0.8619735496977735\n",
      "train loss:0.8694421179239857\n",
      "train loss:0.8724966371637491\n",
      "train loss:0.9851050612509268\n",
      "train loss:0.8983613516472089\n",
      "train loss:0.9697535605201734\n",
      "train loss:0.8592175045523516\n",
      "train loss:0.824022708764481\n",
      "train loss:0.9275897247816232\n",
      "train loss:0.8482476708992687\n",
      "train loss:0.7925385569330914\n",
      "train loss:0.9030275886931607\n",
      "train loss:0.9627731268558908\n",
      "train loss:0.9283091833615971\n",
      "train loss:0.8800495138668842\n",
      "train loss:0.9457124611455581\n",
      "train loss:0.9628282983524953\n",
      "train loss:0.6464270852952073\n",
      "train loss:0.8982173804682086\n",
      "train loss:0.6908494463195177\n",
      "train loss:0.9599965127924222\n",
      "train loss:0.7759205462299519\n",
      "train loss:0.8828270981242153\n",
      "train loss:0.8842739850272345\n",
      "train loss:0.9590855041515699\n",
      "train loss:0.8912880968673916\n",
      "train loss:0.9191027049410292\n",
      "train loss:0.78189558005955\n",
      "train loss:0.8427944454998857\n",
      "train loss:0.8143644913334827\n",
      "train loss:0.9355299208598722\n",
      "train loss:0.8678355932867202\n",
      "train loss:0.6068312723582578\n",
      "train loss:0.6914064395501065\n",
      "train loss:0.9939462289609209\n",
      "train loss:0.8095768441117569\n",
      "train loss:0.7789617777267805\n",
      "train loss:0.919215566529302\n",
      "train loss:0.6965134124250292\n",
      "train loss:0.8996877229687401\n",
      "train loss:0.6683629110289995\n",
      "train loss:0.9709573977019109\n",
      "train loss:0.8215712699938913\n",
      "train loss:0.7579539134282779\n",
      "train loss:0.8366479558403932\n",
      "train loss:0.8825171055794566\n",
      "train loss:0.7540205831599461\n",
      "train loss:0.7467294094834094\n",
      "train loss:0.8245811066858699\n",
      "train loss:0.9622651927813699\n",
      "train loss:0.9255521910485683\n",
      "train loss:0.8442556094473592\n",
      "train loss:0.9614866003104207\n",
      "train loss:0.7527444289595138\n",
      "train loss:0.9871141086468985\n",
      "train loss:0.9899026147967542\n",
      "train loss:0.7577314279773438\n",
      "train loss:0.7830375165214336\n",
      "train loss:0.8345629941619697\n",
      "train loss:0.9026013287081812\n",
      "train loss:0.751545161129215\n",
      "train loss:0.6833731677715378\n",
      "train loss:0.8799759689574508\n",
      "train loss:0.8107266252084041\n",
      "train loss:0.8163146480504443\n",
      "train loss:0.8244434965556029\n",
      "train loss:1.0324467082822042\n",
      "train loss:0.9538216334973474\n",
      "train loss:0.9064977265321085\n",
      "train loss:0.9041609578848167\n",
      "train loss:0.7724574844736698\n",
      "train loss:0.9198214187074351\n",
      "train loss:0.8488362947520562\n",
      "train loss:0.8355561067601611\n",
      "train loss:0.8677696753090521\n",
      "train loss:1.026437394846588\n",
      "train loss:0.875578296326267\n",
      "train loss:0.8008539141403241\n",
      "train loss:0.9411692102663533\n",
      "train loss:1.0542804729660837\n",
      "train loss:0.9524757380981935\n",
      "train loss:0.8742897991573441\n",
      "train loss:0.9967736046738271\n",
      "train loss:0.8760264604663471\n",
      "train loss:0.841651042794022\n",
      "train loss:0.8702883062314766\n",
      "train loss:0.7463691278178156\n",
      "train loss:0.7590949070888514\n",
      "train loss:0.9069562586749442\n",
      "train loss:0.8191447824089678\n",
      "train loss:0.6922393137747477\n",
      "train loss:0.89611357105495\n",
      "train loss:0.7960523531193943\n",
      "train loss:0.8074416177711596\n",
      "train loss:0.9582857705040062\n",
      "train loss:0.9551943139796387\n",
      "train loss:0.770053486419255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8944676646257791\n",
      "train loss:1.071413497209204\n",
      "train loss:0.8916539147856253\n",
      "train loss:0.8423137979076825\n",
      "train loss:0.8020338722986244\n",
      "train loss:0.9860649864766944\n",
      "train loss:0.8630427927899887\n",
      "train loss:0.8107789384427341\n",
      "train loss:0.8426716922090549\n",
      "train loss:0.6424584682492593\n",
      "train loss:0.935266528617618\n",
      "train loss:0.8131785388568946\n",
      "train loss:0.9660554382206118\n",
      "train loss:0.7750031021391959\n",
      "train loss:0.7956253846999377\n",
      "train loss:0.8575064144294922\n",
      "train loss:0.8510519878395683\n",
      "train loss:0.721730024655767\n",
      "train loss:0.9278319093024399\n",
      "train loss:0.8233888166755436\n",
      "train loss:0.7843663155471952\n",
      "train loss:0.8543310039398638\n",
      "train loss:0.933292035793556\n",
      "train loss:0.8447688338775056\n",
      "train loss:0.7172406520851541\n",
      "train loss:0.8599748456117072\n",
      "train loss:0.816082540438585\n",
      "train loss:0.8115250977113918\n",
      "train loss:0.7469687823378134\n",
      "train loss:0.6275484568199365\n",
      "train loss:0.8592417232876648\n",
      "train loss:0.8270311090854919\n",
      "train loss:0.7781011593255688\n",
      "train loss:0.9129235112199059\n",
      "train loss:0.9015164647297196\n",
      "train loss:0.771423838622297\n",
      "train loss:0.7859274031600282\n",
      "train loss:0.7875833302018218\n",
      "train loss:0.8437767054235269\n",
      "train loss:0.923200871205031\n",
      "train loss:0.8650826792838331\n",
      "train loss:0.8402880058388312\n",
      "train loss:0.953353127504241\n",
      "train loss:0.8836183725601273\n",
      "train loss:0.8652504203668407\n",
      "train loss:0.7286055335296382\n",
      "train loss:0.8536266804550273\n",
      "train loss:0.8060912956744217\n",
      "train loss:0.8371733544423055\n",
      "train loss:0.8387897713841747\n",
      "train loss:0.8666437866837162\n",
      "train loss:0.8478694947809555\n",
      "train loss:0.8929972800773157\n",
      "train loss:0.9894531863437277\n",
      "train loss:0.9538012310988294\n",
      "=== epoch:18, train acc:1.0, test acc:0.993 ===\n",
      "train loss:0.8215759041810812\n",
      "train loss:0.785364733096082\n",
      "train loss:0.7170663224129851\n",
      "train loss:0.8076435120526362\n",
      "train loss:0.7078659286455558\n",
      "train loss:0.7429749139108877\n",
      "train loss:0.9351411365408776\n",
      "train loss:0.8742298588833503\n",
      "train loss:0.7646966440229918\n",
      "train loss:0.8759701150759525\n",
      "train loss:0.8953061549786786\n",
      "train loss:0.8927079851495486\n",
      "train loss:0.8034379340532323\n",
      "train loss:0.704936355281082\n",
      "train loss:0.9763635487895092\n",
      "train loss:0.8809714638408108\n",
      "train loss:0.9799223220116872\n",
      "train loss:0.8192796975010599\n",
      "train loss:0.803593024116504\n",
      "train loss:0.9609164796359551\n",
      "train loss:0.8866042138951858\n",
      "train loss:0.9155382455288651\n",
      "train loss:0.9472017519691405\n",
      "train loss:1.139543036048495\n",
      "train loss:0.8286521537368745\n",
      "train loss:0.8662125599018574\n",
      "train loss:0.7613197022508834\n",
      "train loss:0.8562220711376858\n",
      "train loss:0.9688481363112463\n",
      "train loss:0.8947317840812171\n",
      "train loss:0.8049226371999966\n",
      "train loss:0.834308879415677\n",
      "train loss:0.7529362158726245\n",
      "train loss:0.8789022731324623\n",
      "train loss:0.7617738715862196\n",
      "train loss:0.872762563732408\n",
      "train loss:0.7297983123194041\n",
      "train loss:0.7278778279900407\n",
      "train loss:0.8718698185408985\n",
      "train loss:0.7999558711054269\n",
      "train loss:0.7284927637573094\n",
      "train loss:0.8732801710336244\n",
      "train loss:0.8934279249990545\n",
      "train loss:0.8639390002283192\n",
      "train loss:0.7686644801528929\n",
      "train loss:0.8111000316035433\n",
      "train loss:0.9521485864634261\n",
      "train loss:0.7550391966845215\n",
      "train loss:0.868872932693069\n",
      "train loss:0.769042870706931\n",
      "train loss:0.9100727965684627\n",
      "train loss:0.8246249097065504\n",
      "train loss:0.7958025089596216\n",
      "train loss:1.051269551816126\n",
      "train loss:0.7705130838315728\n",
      "train loss:0.9660901706166544\n",
      "train loss:0.8385993823185482\n",
      "train loss:0.926968761631783\n",
      "train loss:0.9023245428489958\n",
      "train loss:0.9564336046294766\n",
      "train loss:0.8513386620850301\n",
      "train loss:0.8163324242578126\n",
      "train loss:0.8923767839032637\n",
      "train loss:0.8923372812737372\n",
      "train loss:0.7046548198111613\n",
      "train loss:0.9460163227409376\n",
      "train loss:0.8671260352087897\n",
      "train loss:0.8518441265275869\n",
      "train loss:0.9635989448728914\n",
      "train loss:0.9243071094882697\n",
      "train loss:0.8779233175967854\n",
      "train loss:0.8844898664647391\n",
      "train loss:0.9038914659861085\n",
      "train loss:0.8781143101513013\n",
      "train loss:0.9001541833650125\n",
      "train loss:0.9956401595906413\n",
      "train loss:0.8730968917154361\n",
      "train loss:0.7769974245675142\n",
      "train loss:0.8631185765332541\n",
      "train loss:0.8120747959868901\n",
      "train loss:0.9129903636044403\n",
      "train loss:1.0424619324525908\n",
      "train loss:0.8593273115921888\n",
      "train loss:0.9218471706350729\n",
      "train loss:0.8597397187738802\n",
      "train loss:0.9529166742500407\n",
      "train loss:0.8725101716833568\n",
      "train loss:0.803182356709383\n",
      "train loss:1.0320075610854536\n",
      "train loss:0.8069367217614668\n",
      "train loss:0.7897795899777106\n",
      "train loss:0.698043023014605\n",
      "train loss:0.9282440469240218\n",
      "train loss:0.9168105992497303\n",
      "train loss:1.0559669346765497\n",
      "train loss:0.8636516654096765\n",
      "train loss:0.9110615048829317\n",
      "train loss:0.8505159114548577\n",
      "train loss:1.0584235583963055\n",
      "train loss:0.9095918342264184\n",
      "train loss:1.022536991834966\n",
      "train loss:0.8409676500495074\n",
      "train loss:0.8428105518031144\n",
      "train loss:0.9464476111258668\n",
      "train loss:0.8314273382382104\n",
      "train loss:0.9884329980116126\n",
      "train loss:0.7675745196949733\n",
      "train loss:0.7615516442068798\n",
      "train loss:0.9337531236648735\n",
      "train loss:0.8340549294241755\n",
      "train loss:0.8799765364782356\n",
      "train loss:0.8683428786732342\n",
      "train loss:0.9469835984435471\n",
      "train loss:0.7803569788905836\n",
      "train loss:0.8076001547887834\n",
      "train loss:0.8880850380444077\n",
      "train loss:0.8454763893859666\n",
      "train loss:0.8516163551941809\n",
      "train loss:0.984160830340053\n",
      "train loss:0.7893857096518175\n",
      "train loss:0.8696496045096136\n",
      "train loss:0.7925680315947022\n",
      "train loss:0.8489832423239159\n",
      "train loss:0.847328544070436\n",
      "train loss:0.8429290410599457\n",
      "train loss:0.8767574400947179\n",
      "train loss:0.6990154521011587\n",
      "train loss:0.9902963920117344\n",
      "train loss:0.8410989421491115\n",
      "train loss:0.9413054711813981\n",
      "train loss:0.8545823361117454\n",
      "train loss:0.7811239782558657\n",
      "train loss:0.8819172099856216\n",
      "train loss:0.9654472085870313\n",
      "train loss:0.878479127985674\n",
      "train loss:0.8596114274526727\n",
      "train loss:1.0155170182722262\n",
      "train loss:0.864702637147095\n",
      "train loss:0.8203452116364539\n",
      "train loss:0.704873662709693\n",
      "train loss:0.9448824331236423\n",
      "train loss:0.9123500330511323\n",
      "train loss:0.8777502286169622\n",
      "train loss:0.908140994011059\n",
      "train loss:0.9729692967542993\n",
      "train loss:0.7365715703471072\n",
      "train loss:1.1001854755012723\n",
      "train loss:0.7978781564325196\n",
      "train loss:0.8877471589455442\n",
      "train loss:0.8988067046611609\n",
      "train loss:0.8684461425613993\n",
      "train loss:1.0014763902159014\n",
      "train loss:0.84144582903996\n",
      "train loss:0.8819101942081521\n",
      "train loss:0.7763372447235194\n",
      "train loss:1.0760699359266066\n",
      "train loss:0.7144077739514233\n",
      "train loss:0.9029343857519982\n",
      "train loss:0.9820503220821167\n",
      "train loss:0.9368475025767519\n",
      "train loss:0.7816087977034606\n",
      "train loss:0.8060470934232099\n",
      "train loss:0.9510671716859993\n",
      "train loss:0.8466574307090653\n",
      "train loss:0.8888975582236534\n",
      "train loss:0.8029591073095594\n",
      "train loss:1.0018522793004774\n",
      "train loss:0.7907975509997969\n",
      "train loss:0.8599383496259417\n",
      "train loss:1.107226690713184\n",
      "train loss:0.8931052921630496\n",
      "train loss:0.9109996050131502\n",
      "train loss:0.6387357819954727\n",
      "train loss:0.7936294023218784\n",
      "train loss:0.6938473726006045\n",
      "train loss:0.8822049061275465\n",
      "train loss:0.8326730313748903\n",
      "train loss:1.048789289567841\n",
      "train loss:0.8489004195439743\n",
      "train loss:0.9925018263970966\n",
      "train loss:0.7476196332716111\n",
      "train loss:0.7854607919948207\n",
      "train loss:0.955683185687838\n",
      "train loss:0.7977719550514348\n",
      "train loss:0.7895004026457387\n",
      "train loss:0.8975616762066747\n",
      "train loss:0.7610939493844033\n",
      "train loss:0.7820920609048402\n",
      "train loss:0.847784987855874\n",
      "train loss:0.8746347813525479\n",
      "train loss:0.8496011229126107\n",
      "train loss:0.7321096188412253\n",
      "train loss:0.6450291226257672\n",
      "train loss:0.7746877369183782\n",
      "train loss:0.763282262145728\n",
      "train loss:0.8894354429784517\n",
      "train loss:0.8869893618187983\n",
      "train loss:0.8730354601711858\n",
      "train loss:0.7067761750235756\n",
      "train loss:1.1333049722618564\n",
      "train loss:0.8540744463149417\n",
      "train loss:0.9224954652278831\n",
      "train loss:0.9671068186040059\n",
      "train loss:0.8858115014782625\n",
      "train loss:0.7105839562956087\n",
      "train loss:0.8464786513346079\n",
      "train loss:0.8803841654732263\n",
      "train loss:0.8151269532411146\n",
      "train loss:0.8465835697644022\n",
      "train loss:0.8045556225467577\n",
      "train loss:0.908451188764354\n",
      "train loss:0.7716701748413876\n",
      "train loss:0.9610797168570518\n",
      "train loss:0.7855605242529146\n",
      "train loss:0.8024908997821473\n",
      "train loss:0.7949428156192688\n",
      "train loss:0.8929204840438839\n",
      "train loss:0.8316715579469366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7520828786280126\n",
      "train loss:0.8416484961656039\n",
      "train loss:0.8211976365396526\n",
      "train loss:0.7621641316922186\n",
      "train loss:0.8002709497488506\n",
      "train loss:0.8275221899941247\n",
      "train loss:0.7341069835710062\n",
      "train loss:0.7586717309068743\n",
      "train loss:0.7726014085775411\n",
      "train loss:0.851075676764161\n",
      "train loss:0.9196570751039974\n",
      "train loss:0.7403613139070478\n",
      "train loss:0.8956770616224756\n",
      "train loss:0.8910462630145097\n",
      "train loss:0.8087748226855475\n",
      "train loss:0.8728682315207759\n",
      "train loss:0.7710864587566355\n",
      "train loss:0.8331444856119924\n",
      "train loss:0.8411526992993855\n",
      "train loss:0.9013950683974444\n",
      "train loss:0.8281491314569358\n",
      "train loss:0.841326360764146\n",
      "train loss:0.986830485790757\n",
      "train loss:0.8679518749090757\n",
      "train loss:0.8108974923334143\n",
      "train loss:0.833936530951782\n",
      "train loss:0.9072861353156795\n",
      "train loss:0.8660730260417767\n",
      "train loss:0.8524562485375333\n",
      "train loss:0.8699293748427432\n",
      "train loss:0.8507008573896797\n",
      "train loss:0.8825792077723393\n",
      "train loss:0.774064727874106\n",
      "train loss:0.7044569830749775\n",
      "train loss:0.7297449747124852\n",
      "train loss:0.7646091167186009\n",
      "train loss:1.0593930003317744\n",
      "train loss:0.8586406952957124\n",
      "train loss:0.7795202855643508\n",
      "train loss:0.9156277273606049\n",
      "train loss:0.8547554098188551\n",
      "train loss:0.85788047601606\n",
      "train loss:0.8388520635859151\n",
      "train loss:0.8515271907741766\n",
      "train loss:0.815000168695134\n",
      "train loss:0.8091661084366806\n",
      "train loss:0.9357006225008284\n",
      "train loss:0.9330302933784707\n",
      "train loss:0.9482511490589504\n",
      "train loss:0.9526706266392062\n",
      "train loss:0.7624516053942766\n",
      "train loss:0.8743008819041026\n",
      "train loss:0.7547510882575061\n",
      "train loss:0.7167474747614182\n",
      "train loss:0.8141642997951501\n",
      "train loss:0.935121904211503\n",
      "train loss:0.8918788951898609\n",
      "train loss:0.8397685052224857\n",
      "train loss:0.8868253685236615\n",
      "train loss:0.817048369484447\n",
      "train loss:0.7306456072961702\n",
      "train loss:0.9281590286841539\n",
      "train loss:0.9008451698795816\n",
      "train loss:0.9251964494946019\n",
      "train loss:0.8329701854966713\n",
      "train loss:0.6738723685887229\n",
      "train loss:0.7285396036604126\n",
      "train loss:0.8612583472820166\n",
      "train loss:0.8967662760851346\n",
      "train loss:0.9519574850666772\n",
      "train loss:0.7682432432199113\n",
      "train loss:0.888709064972338\n",
      "train loss:0.7704239613819859\n",
      "train loss:0.8161078650027861\n",
      "train loss:0.9255830823025714\n",
      "train loss:0.8219426228190443\n",
      "train loss:0.8076889217815052\n",
      "train loss:0.879432848147428\n",
      "train loss:0.9617521361319311\n",
      "train loss:0.8217301165123849\n",
      "train loss:0.7033662299392265\n",
      "train loss:0.7849389632401242\n",
      "train loss:0.8249269241149279\n",
      "train loss:0.9208733702561542\n",
      "train loss:0.8189290019429326\n",
      "train loss:0.9023104179629761\n",
      "train loss:0.7238404026159178\n",
      "train loss:0.933175438269475\n",
      "train loss:0.8158268316453898\n",
      "train loss:0.8852844620768218\n",
      "train loss:0.6929965893059021\n",
      "train loss:0.8640216278477272\n",
      "train loss:0.9327117762526744\n",
      "train loss:0.9680026117927112\n",
      "train loss:0.9606892925393501\n",
      "train loss:0.9613659635220898\n",
      "train loss:0.8767730077162464\n",
      "train loss:0.6552144193583057\n",
      "train loss:0.9693174133022857\n",
      "train loss:0.8516322774324019\n",
      "train loss:0.8926647618395143\n",
      "train loss:0.9158221416657836\n",
      "train loss:0.76798938663546\n",
      "train loss:0.8565179988207556\n",
      "train loss:0.717294186957447\n",
      "train loss:0.8145449358554586\n",
      "train loss:0.8259291313239132\n",
      "train loss:0.8095231240958579\n",
      "train loss:0.8515998831701118\n",
      "train loss:0.8841370296595517\n",
      "train loss:0.8135958589512637\n",
      "train loss:0.6359308847438065\n",
      "train loss:0.7702286829448108\n",
      "train loss:0.7712452401425892\n",
      "train loss:1.021727421736159\n",
      "train loss:0.8675042287190381\n",
      "train loss:0.7530322711571634\n",
      "train loss:0.9633507551338713\n",
      "train loss:0.7270620098700097\n",
      "train loss:0.9024422228446128\n",
      "train loss:0.9365931223004165\n",
      "train loss:0.7245625808895152\n",
      "train loss:0.8673715257395513\n",
      "train loss:0.818552748881108\n",
      "train loss:1.0083459789242857\n",
      "train loss:1.0343971115063721\n",
      "train loss:0.7957071177451941\n",
      "train loss:0.7979133889906258\n",
      "train loss:0.7687120412819551\n",
      "train loss:0.8133413352851617\n",
      "train loss:0.7752581357427607\n",
      "train loss:0.8711394585549534\n",
      "train loss:0.8986355319083106\n",
      "train loss:0.8038884102637549\n",
      "train loss:0.6841827160497445\n",
      "train loss:0.8491455575985911\n",
      "train loss:0.893695649119745\n",
      "train loss:0.7818134433565563\n",
      "train loss:0.9294844692176087\n",
      "train loss:1.0268067999031045\n",
      "train loss:0.9881789807824937\n",
      "train loss:0.7156436592637246\n",
      "train loss:0.8251702868747947\n",
      "train loss:0.76811103190827\n",
      "train loss:0.8767141728642015\n",
      "train loss:0.9949522981007517\n",
      "train loss:0.8837911948727003\n",
      "train loss:0.7922377202313321\n",
      "train loss:0.8203265197623317\n",
      "train loss:0.9069923309717549\n",
      "train loss:0.7890442285951232\n",
      "train loss:0.9654886609200405\n",
      "train loss:0.8201584239026575\n",
      "train loss:0.7649103307985076\n",
      "train loss:0.8116847073182167\n",
      "train loss:0.9341466727432131\n",
      "train loss:0.9260393667780589\n",
      "train loss:0.7282196857770381\n",
      "train loss:0.8633231160943329\n",
      "train loss:0.9875951963091937\n",
      "train loss:0.8952561637183273\n",
      "train loss:0.7647983188662291\n",
      "train loss:0.8294035889208472\n",
      "train loss:0.8806431955941352\n",
      "train loss:0.7655241569594543\n",
      "train loss:0.8735453769954682\n",
      "train loss:0.9960497948284948\n",
      "train loss:0.9123523801586022\n",
      "train loss:0.8310577945618677\n",
      "train loss:0.8850706388440269\n",
      "train loss:0.8762550525425954\n",
      "train loss:0.8489541991832646\n",
      "train loss:0.9300283672283023\n",
      "train loss:0.932650817924246\n",
      "train loss:0.8566360606898005\n",
      "train loss:0.8050146981351537\n",
      "train loss:0.9502210866849984\n",
      "train loss:0.9116784026735519\n",
      "train loss:0.7629863526386278\n",
      "train loss:0.8997644258982821\n",
      "train loss:0.7593795249345701\n",
      "train loss:1.0652151136030887\n",
      "train loss:0.7849004674880687\n",
      "train loss:1.0263005574920263\n",
      "train loss:1.0929943890077656\n",
      "train loss:0.8011492985313491\n",
      "train loss:0.9788748804881634\n",
      "train loss:1.050743421284835\n",
      "train loss:0.8143787674707772\n",
      "train loss:0.9331729665489635\n",
      "train loss:0.8407920783796452\n",
      "train loss:0.905701319734186\n",
      "train loss:0.759427532800119\n",
      "train loss:0.844245402092861\n",
      "train loss:0.8080057791769018\n",
      "train loss:0.840212057152\n",
      "train loss:0.7932153982859945\n",
      "train loss:1.053318505365066\n",
      "train loss:0.8141208131884976\n",
      "train loss:0.9408081821586258\n",
      "train loss:0.9500900192333295\n",
      "train loss:0.7899194617964159\n",
      "train loss:0.6717017348178267\n",
      "train loss:0.7156674730342633\n",
      "train loss:0.8336004355073586\n",
      "train loss:0.7910904048673407\n",
      "train loss:0.9168633834723454\n",
      "train loss:0.7253132841829961\n",
      "train loss:0.8742752471436678\n",
      "train loss:0.9696562313148206\n",
      "train loss:0.8290642309922543\n",
      "train loss:0.912464260609047\n",
      "train loss:0.8133189819393045\n",
      "train loss:1.0177899662386287\n",
      "train loss:0.9061193211680828\n",
      "train loss:0.8476513598194834\n",
      "train loss:0.8519755795744929\n",
      "train loss:0.7794176338906706\n",
      "train loss:0.7776528101581905\n",
      "train loss:0.8074257419847504\n",
      "train loss:0.7540667062193562\n",
      "train loss:0.7908276752543162\n",
      "train loss:0.8864171402488991\n",
      "train loss:0.8635087895791657\n",
      "train loss:0.8294521561996029\n",
      "train loss:0.750794444896584\n",
      "train loss:0.8131307049901253\n",
      "train loss:0.9306950566108462\n",
      "train loss:0.8303124843449665\n",
      "train loss:0.7822246783085711\n",
      "train loss:0.8747483610402174\n",
      "train loss:0.8608445558002374\n",
      "train loss:0.8761304705738792\n",
      "train loss:0.7999138337005159\n",
      "train loss:0.8922720177968503\n",
      "train loss:0.7736529777940291\n",
      "train loss:0.8282540241267945\n",
      "train loss:0.9774911597053767\n",
      "train loss:0.957803294112589\n",
      "train loss:0.8401278028673026\n",
      "train loss:0.7519249573764815\n",
      "train loss:0.95260375324247\n",
      "train loss:0.9448320787468175\n",
      "train loss:0.9411051761706664\n",
      "train loss:0.7199934409314136\n",
      "train loss:0.83950862233791\n",
      "train loss:0.7996594705971377\n",
      "train loss:1.1037870845792104\n",
      "train loss:1.014707514624869\n",
      "train loss:0.9374793636444977\n",
      "train loss:0.9162122229160796\n",
      "train loss:0.8372864484321353\n",
      "train loss:0.9727049691786043\n",
      "train loss:0.801116750026039\n",
      "train loss:0.8589938098266788\n",
      "train loss:0.996451245735322\n",
      "train loss:0.8913802050368086\n",
      "train loss:1.0000136481734774\n",
      "train loss:1.087311815731549\n",
      "train loss:0.8729617596751852\n",
      "train loss:1.0377986031281494\n",
      "train loss:0.9259922909418232\n",
      "train loss:1.0057096732977842\n",
      "train loss:0.7355923364055194\n",
      "train loss:0.925531911536281\n",
      "train loss:0.8798262312046663\n",
      "train loss:0.7980837135754261\n",
      "train loss:0.8702166220125523\n",
      "train loss:0.9028746568570312\n",
      "train loss:0.8029696377988236\n",
      "train loss:0.9672689367076053\n",
      "train loss:0.777395058184951\n",
      "train loss:0.9036785413493175\n",
      "train loss:0.9122484855396018\n",
      "train loss:0.8347355532864456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9628447269321901\n",
      "train loss:0.8096874222782741\n",
      "train loss:0.9265833149156054\n",
      "train loss:0.9038539071140446\n",
      "train loss:0.8735428093018482\n",
      "train loss:0.8282054888922954\n",
      "train loss:0.9657140824652349\n",
      "train loss:0.8043087514815866\n",
      "train loss:0.8310254879040643\n",
      "train loss:0.827512600325178\n",
      "train loss:0.8541038247430186\n",
      "train loss:0.9433641992318488\n",
      "train loss:0.9857062047443013\n",
      "train loss:0.8215076380802199\n",
      "train loss:0.9295849526895508\n",
      "train loss:0.892639291596844\n",
      "train loss:0.862269293852732\n",
      "train loss:0.8133891617473122\n",
      "train loss:0.8859134855647048\n",
      "train loss:0.9376069833958391\n",
      "train loss:0.8545552134919441\n",
      "train loss:0.8783342635231357\n",
      "train loss:0.7284811354207218\n",
      "train loss:0.8255957607558773\n",
      "train loss:0.7522082107634159\n",
      "train loss:0.8504376612493774\n",
      "train loss:0.8492370454523055\n",
      "train loss:0.7272811113488592\n",
      "train loss:0.9415067845763165\n",
      "train loss:0.7372156062611563\n",
      "train loss:0.7828558037787038\n",
      "train loss:0.8457704477275118\n",
      "train loss:0.6802616091454354\n",
      "train loss:0.7032096730352667\n",
      "train loss:0.7870203796922327\n",
      "train loss:0.846124551867938\n",
      "train loss:0.9704161053879433\n",
      "train loss:0.832825725318482\n",
      "train loss:1.0530250647771673\n",
      "train loss:0.8469096701054145\n",
      "train loss:0.8224011091886284\n",
      "train loss:1.0374207827788824\n",
      "train loss:0.8339453747953701\n",
      "train loss:1.075699822638223\n",
      "train loss:0.9944819268400498\n",
      "train loss:0.8232373595923977\n",
      "train loss:0.8315056997214608\n",
      "train loss:0.9095915335993807\n",
      "train loss:0.8856620404444645\n",
      "train loss:0.9406354279222736\n",
      "train loss:0.9577614733198666\n",
      "train loss:0.9063629694704535\n",
      "train loss:0.9803229379443388\n",
      "train loss:0.9132202443972064\n",
      "train loss:0.7825493385807745\n",
      "train loss:0.8457484993767292\n",
      "train loss:0.8039933559110368\n",
      "train loss:0.8658989055522126\n",
      "train loss:0.9753676907238179\n",
      "train loss:1.0759228367459102\n",
      "train loss:1.0482798677747396\n",
      "train loss:0.9321830268577928\n",
      "train loss:0.9168962367523669\n",
      "train loss:0.8350841013519821\n",
      "train loss:0.8044991340541607\n",
      "train loss:0.8364030675881365\n",
      "train loss:0.766505080851521\n",
      "train loss:0.8844631933066631\n",
      "train loss:0.9262212276329087\n",
      "train loss:0.9602235166544442\n",
      "train loss:0.8670620627984706\n",
      "train loss:1.0106269472324698\n",
      "train loss:0.8009139101547795\n",
      "train loss:0.841516379580186\n",
      "train loss:0.7598761756983761\n",
      "train loss:0.7808503360125885\n",
      "train loss:0.8536959303433789\n",
      "train loss:0.8822400169618764\n",
      "train loss:0.8443172218439067\n",
      "train loss:0.9929391411884825\n",
      "train loss:0.855794701227149\n",
      "train loss:0.8493639736173009\n",
      "train loss:0.7082442978797837\n",
      "train loss:0.7398566767588178\n",
      "train loss:0.8979204615962211\n",
      "train loss:0.8080375988592676\n",
      "train loss:0.7816235425565254\n",
      "train loss:0.9351711307090328\n",
      "train loss:0.9351042244660529\n",
      "train loss:1.0189527874825346\n",
      "train loss:0.9355687924554984\n",
      "train loss:0.8773068811930561\n",
      "train loss:0.8185366118200811\n",
      "train loss:1.0368033913077799\n",
      "train loss:0.8933577579509765\n",
      "train loss:0.8023659051351764\n",
      "train loss:0.9316213905753284\n",
      "train loss:0.7939242957872369\n",
      "train loss:0.9588441564993394\n",
      "train loss:0.783591364545757\n",
      "train loss:0.9183094896255413\n",
      "train loss:0.9075042005663911\n",
      "train loss:0.9593857148886058\n",
      "train loss:0.882289895183712\n",
      "train loss:0.9648486880215816\n",
      "train loss:0.9435349174377561\n",
      "train loss:0.8443335432593141\n",
      "=== epoch:19, train acc:0.999, test acc:0.99 ===\n",
      "train loss:0.729121585194643\n",
      "train loss:0.8350342055615028\n",
      "train loss:0.804292958724086\n",
      "train loss:0.8183653156592989\n",
      "train loss:0.8565112175863754\n",
      "train loss:0.8955918232415904\n",
      "train loss:0.8931623533063395\n",
      "train loss:0.8829052017258974\n",
      "train loss:0.8261213808833416\n",
      "train loss:0.992734089332666\n",
      "train loss:0.9406542351027741\n",
      "train loss:0.9504709171027966\n",
      "train loss:0.7861437341096569\n",
      "train loss:0.8831283128490071\n",
      "train loss:0.8145843044334145\n",
      "train loss:0.8853467513046729\n",
      "train loss:0.8121752196910732\n",
      "train loss:0.8547725044945078\n",
      "train loss:0.9980173161568642\n",
      "train loss:0.8044676371479901\n",
      "train loss:0.7869678613232935\n",
      "train loss:0.9601197001239364\n",
      "train loss:0.8627838770638933\n",
      "train loss:0.9347148719997\n",
      "train loss:0.9489715865430537\n",
      "train loss:0.787404726424089\n",
      "train loss:1.0033383040230688\n",
      "train loss:0.8349406252807356\n",
      "train loss:0.9677745598331461\n",
      "train loss:0.998718232438808\n",
      "train loss:0.7104235905637032\n",
      "train loss:0.917585339594594\n",
      "train loss:0.7771395801524043\n",
      "train loss:0.8700867623974502\n",
      "train loss:0.9851682729675381\n",
      "train loss:0.7516305490606635\n",
      "train loss:0.9792271466461162\n",
      "train loss:0.8427055082317227\n",
      "train loss:0.9214277069120825\n",
      "train loss:0.883535437452869\n",
      "train loss:0.8157780886372589\n",
      "train loss:0.911038970748518\n",
      "train loss:0.8588192121296783\n",
      "train loss:0.7548414275352618\n",
      "train loss:0.8835435710638463\n",
      "train loss:0.8560997343797205\n",
      "train loss:0.8692982264515622\n",
      "train loss:0.9284510811462857\n",
      "train loss:0.9731954387889656\n",
      "train loss:0.876655212743287\n",
      "train loss:0.9123131666745428\n",
      "train loss:0.8387264440818012\n",
      "train loss:0.8663985228129344\n",
      "train loss:0.929907101005481\n",
      "train loss:0.9139132757937457\n",
      "train loss:1.0153586448785727\n",
      "train loss:0.8029755477414457\n",
      "train loss:0.879678883363422\n",
      "train loss:0.8068380318275536\n",
      "train loss:0.7106029387898929\n",
      "train loss:0.8100247772214191\n",
      "train loss:0.8647555761897169\n",
      "train loss:0.7764702292902789\n",
      "train loss:1.0118655029137202\n",
      "train loss:0.9303980262356848\n",
      "train loss:0.7823218357897538\n",
      "train loss:0.784964892523812\n",
      "train loss:0.7672294785956456\n",
      "train loss:0.694097585200425\n",
      "train loss:0.9569493563770476\n",
      "train loss:0.9050676653398563\n",
      "train loss:0.9300252667791759\n",
      "train loss:0.7904950498613939\n",
      "train loss:0.9044323381652193\n",
      "train loss:0.9502517757061705\n",
      "train loss:0.9828150256522176\n",
      "train loss:0.8696418028556162\n",
      "train loss:0.8514859783109866\n",
      "train loss:0.8753356401713813\n",
      "train loss:0.8118609684398959\n",
      "train loss:0.8290649172032176\n",
      "train loss:0.77361105993592\n",
      "train loss:0.8164858856842414\n",
      "train loss:0.9610241447059914\n",
      "train loss:0.8986962645885849\n",
      "train loss:0.8755009737198717\n",
      "train loss:0.8894700063596589\n",
      "train loss:0.868201185167149\n",
      "train loss:0.8901684564604317\n",
      "train loss:0.9645200647816132\n",
      "train loss:0.859849732583541\n",
      "train loss:0.8268163026985161\n",
      "train loss:1.0716853491391256\n",
      "train loss:0.8453900004157314\n",
      "train loss:0.9132707234631389\n",
      "train loss:0.8534746438197856\n",
      "train loss:0.7885607438120746\n",
      "train loss:0.8378930292752049\n",
      "train loss:0.9443527162896018\n",
      "train loss:0.9368775704961082\n",
      "train loss:0.8766868367140183\n",
      "train loss:0.8855796314094707\n",
      "train loss:0.8670926981585798\n",
      "train loss:0.7456306307420316\n",
      "train loss:0.8685393987853745\n",
      "train loss:0.7955837673471493\n",
      "train loss:0.8724377553562076\n",
      "train loss:0.9682206645823627\n",
      "train loss:0.8056187268660541\n",
      "train loss:0.994951124154037\n",
      "train loss:1.0065964021135911\n",
      "train loss:0.8506654943462132\n",
      "train loss:0.8623152102787404\n",
      "train loss:0.7392132667541935\n",
      "train loss:0.9558339238524555\n",
      "train loss:0.8252035903208323\n",
      "train loss:0.9106661947701906\n",
      "train loss:0.8978042786572366\n",
      "train loss:0.8038229517778529\n",
      "train loss:0.9718023849356588\n",
      "train loss:0.7578693820709422\n",
      "train loss:0.8187144451310638\n",
      "train loss:0.8025659406942257\n",
      "train loss:0.8923103468996687\n",
      "train loss:0.8296382880254548\n",
      "train loss:0.9008642297883039\n",
      "train loss:0.8904304121989999\n",
      "train loss:0.9258488973957171\n",
      "train loss:1.0276969992097356\n",
      "train loss:1.0860922453014448\n",
      "train loss:0.8113486004007087\n",
      "train loss:0.8915948065420687\n",
      "train loss:0.8414261369899749\n",
      "train loss:0.8272698793213263\n",
      "train loss:0.7817572763055507\n",
      "train loss:0.8897121351889515\n",
      "train loss:0.890577685308629\n",
      "train loss:0.8909268590105276\n",
      "train loss:0.7885643556076005\n",
      "train loss:0.8698765012475006\n",
      "train loss:0.7647160416176259\n",
      "train loss:0.8441436784695672\n",
      "train loss:0.7530167484345897\n",
      "train loss:0.9049055189888087\n",
      "train loss:1.0363951350086058\n",
      "train loss:0.7459078224347855\n",
      "train loss:0.7424374780715871\n",
      "train loss:0.916627971138607\n",
      "train loss:0.930719378923548\n",
      "train loss:0.7816341727556904\n",
      "train loss:0.8768963412350692\n",
      "train loss:0.9273223169486219\n",
      "train loss:0.8769727295754959\n",
      "train loss:0.8342554127360866\n",
      "train loss:1.073249311311808\n",
      "train loss:0.8789039403905771\n",
      "train loss:0.8767993662700531\n",
      "train loss:0.926575055874646\n",
      "train loss:0.888428713848978\n",
      "train loss:0.7114865757848876\n",
      "train loss:0.9145079012895704\n",
      "train loss:0.79709889501679\n",
      "train loss:0.8826169194517588\n",
      "train loss:0.7323029760483186\n",
      "train loss:0.9669344836593585\n",
      "train loss:1.0711038998698001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7724049999366145\n",
      "train loss:0.8590652821798289\n",
      "train loss:0.8654128156208805\n",
      "train loss:0.9037082059709909\n",
      "train loss:0.8807382133150476\n",
      "train loss:0.8936225859616214\n",
      "train loss:0.8175496052968083\n",
      "train loss:0.8727416340950472\n",
      "train loss:0.807158789858201\n",
      "train loss:0.7809873659415356\n",
      "train loss:1.013528860305721\n",
      "train loss:0.908696560001641\n",
      "train loss:0.782501189251392\n",
      "train loss:0.8647734401020821\n",
      "train loss:0.9069562075428079\n",
      "train loss:0.9504363295317582\n",
      "train loss:0.8249912095385585\n",
      "train loss:0.7892027199673816\n",
      "train loss:0.8159895659541323\n",
      "train loss:0.8437164155022729\n",
      "train loss:0.7429086928599825\n",
      "train loss:0.7816676134685179\n",
      "train loss:0.812856994455001\n",
      "train loss:0.8721814469244751\n",
      "train loss:0.67458947336223\n",
      "train loss:0.9223549792196145\n",
      "train loss:0.8408058489894001\n",
      "train loss:0.7954970186410102\n",
      "train loss:0.9815668822432603\n",
      "train loss:0.7507716753704843\n",
      "train loss:0.7914256420319645\n",
      "train loss:0.8480498939779108\n",
      "train loss:0.983329582896675\n",
      "train loss:0.9455223273931549\n",
      "train loss:0.6904820170331308\n",
      "train loss:0.7978159852902336\n",
      "train loss:0.9448074399593075\n",
      "train loss:0.9323997145876028\n",
      "train loss:0.9105686467034847\n",
      "train loss:0.8055529847665825\n",
      "train loss:0.7437995538570428\n",
      "train loss:0.7925874908512455\n",
      "train loss:1.1494706526407525\n",
      "train loss:0.7010029572949464\n",
      "train loss:0.8971594156783702\n",
      "train loss:0.7323468426348806\n",
      "train loss:1.019753062836409\n",
      "train loss:0.8800581930492565\n",
      "train loss:0.9084882015140602\n",
      "train loss:0.9667212432898308\n",
      "train loss:0.7878376678612927\n",
      "train loss:1.058657643219261\n",
      "train loss:0.8672088127531368\n",
      "train loss:0.9554880971355901\n",
      "train loss:0.8034868573452101\n",
      "train loss:0.8182141408353303\n",
      "train loss:0.9070952141901657\n",
      "train loss:0.9582270562691194\n",
      "train loss:0.7268988202000942\n",
      "train loss:0.8871079171471142\n",
      "train loss:0.8210824804856217\n",
      "train loss:0.901325963222266\n",
      "train loss:0.8056221584522778\n",
      "train loss:0.8562165882328441\n",
      "train loss:0.9609781699741695\n",
      "train loss:0.87304487402595\n",
      "train loss:0.8657408631057857\n",
      "train loss:0.9373758229731921\n",
      "train loss:0.7544072303035847\n",
      "train loss:0.8679681441254797\n",
      "train loss:0.8237591765165644\n",
      "train loss:0.8525794415318891\n",
      "train loss:0.7792876013857466\n",
      "train loss:0.8663855021505877\n",
      "train loss:0.7463914071682093\n",
      "train loss:0.7908919194993922\n",
      "train loss:0.670839062324918\n",
      "train loss:0.9414375089711323\n",
      "train loss:0.6466861955121647\n",
      "train loss:0.8659761178774451\n",
      "train loss:0.9054099403877308\n",
      "train loss:0.8156561153937715\n",
      "train loss:0.9163875101848608\n",
      "train loss:0.8625283017508188\n",
      "train loss:0.640443073924684\n",
      "train loss:0.7418703407835201\n",
      "train loss:0.9145395852255479\n",
      "train loss:0.8650773319684687\n",
      "train loss:0.8998860686604938\n",
      "train loss:0.9365184505456018\n",
      "train loss:0.9196744545963825\n",
      "train loss:0.8452332077095598\n",
      "train loss:0.9320601562130196\n",
      "train loss:0.9323672924586333\n",
      "train loss:0.9024768151327085\n",
      "train loss:0.8115279155919651\n",
      "train loss:0.8567308115834014\n",
      "train loss:0.890692077934995\n",
      "train loss:0.8450596331600541\n",
      "train loss:0.8909213787257295\n",
      "train loss:0.8660364989827688\n",
      "train loss:0.8741322035731638\n",
      "train loss:0.8116159247978955\n",
      "train loss:0.8995099361283332\n",
      "train loss:0.738501010265316\n",
      "train loss:0.9847465411275581\n",
      "train loss:0.8481058716107773\n",
      "train loss:0.8978724084927543\n",
      "train loss:0.8193195378166652\n",
      "train loss:0.8501801234816883\n",
      "train loss:0.8686010093339479\n",
      "train loss:1.0746332547156363\n",
      "train loss:0.771285759564346\n",
      "train loss:0.6906687674855124\n",
      "train loss:0.7814476746442378\n",
      "train loss:0.9018612669155256\n",
      "train loss:0.7665642927792365\n",
      "train loss:0.8837698654314344\n",
      "train loss:0.7985682722482348\n",
      "train loss:0.79939626699999\n",
      "train loss:0.7884330572597804\n",
      "train loss:0.870058527117183\n",
      "train loss:0.8042834388921726\n",
      "train loss:0.9403848000213222\n",
      "train loss:0.8198329817922598\n",
      "train loss:0.7826267642087298\n",
      "train loss:0.8217410665444056\n",
      "train loss:0.9086677802676371\n",
      "train loss:0.9356399387835365\n",
      "train loss:0.8755665979820094\n",
      "train loss:0.658098871588872\n",
      "train loss:0.7544825420541573\n",
      "train loss:0.9179479975792497\n",
      "train loss:1.0261828034742018\n",
      "train loss:0.8392634318579111\n",
      "train loss:0.8718955214959294\n",
      "train loss:0.7643511775817328\n",
      "train loss:0.8675588707719848\n",
      "train loss:0.810754658923705\n",
      "train loss:0.9588632647645216\n",
      "train loss:0.8233658378402146\n",
      "train loss:0.9159154707261813\n",
      "train loss:0.7473359252612163\n",
      "train loss:1.0371112873477615\n",
      "train loss:0.7582166694679603\n",
      "train loss:0.783985352286436\n",
      "train loss:0.8632107336732127\n",
      "train loss:0.893352807748071\n",
      "train loss:0.9849185548597506\n",
      "train loss:0.9146758526963188\n",
      "train loss:0.9319129114056988\n",
      "train loss:1.0198437782574508\n",
      "train loss:0.8227854114777878\n",
      "train loss:0.815143894297487\n",
      "train loss:0.8461216430076475\n",
      "train loss:0.931201580327994\n",
      "train loss:0.953386819264661\n",
      "train loss:0.9331538100929638\n",
      "train loss:1.0194984541117627\n",
      "train loss:0.7775524042566179\n",
      "train loss:0.8217405423661528\n",
      "train loss:0.8314176912029229\n",
      "train loss:0.7870743066850696\n",
      "train loss:1.0597908288162485\n",
      "train loss:0.8993678925500447\n",
      "train loss:0.7393011951676534\n",
      "train loss:0.9618364637629452\n",
      "train loss:0.7722022319669025\n",
      "train loss:0.9355171881816107\n",
      "train loss:0.8923474695622295\n",
      "train loss:0.8370476912847369\n",
      "train loss:0.8328523701674792\n",
      "train loss:0.8127901122120684\n",
      "train loss:0.9673423085130465\n",
      "train loss:0.8989877432875797\n",
      "train loss:0.8589619059215494\n",
      "train loss:0.9468602215130271\n",
      "train loss:0.8122020997093591\n",
      "train loss:0.7745226221216904\n",
      "train loss:1.006817123261289\n",
      "train loss:0.837510323516835\n",
      "train loss:0.8885557283216595\n",
      "train loss:0.9474535878274957\n",
      "train loss:0.6493463281302868\n",
      "train loss:0.6786269906507303\n",
      "train loss:0.9574797173328368\n",
      "train loss:0.6870971037396026\n",
      "train loss:0.885810044452476\n",
      "train loss:0.9763899768673135\n",
      "train loss:0.6772881675913516\n",
      "train loss:0.7450786716973248\n",
      "train loss:0.8657268462850212\n",
      "train loss:1.013999148017295\n",
      "train loss:1.0289300364942344\n",
      "train loss:1.016017766130938\n",
      "train loss:0.8874563584917807\n",
      "train loss:0.843641847549047\n",
      "train loss:0.7939146196059531\n",
      "train loss:0.8627412491927717\n",
      "train loss:0.9157414040783779\n",
      "train loss:0.8204565298948239\n",
      "train loss:0.8899445010156358\n",
      "train loss:0.7613892346967223\n",
      "train loss:1.013175581226358\n",
      "train loss:0.9032316200394817\n",
      "train loss:0.8761519959922023\n",
      "train loss:0.8719334578763498\n",
      "train loss:0.8432331086161762\n",
      "train loss:0.907500884931146\n",
      "train loss:0.7858234633053465\n",
      "train loss:0.7906396356703443\n",
      "train loss:0.7985245944669201\n",
      "train loss:0.8978843126427501\n",
      "train loss:0.9756179923637639\n",
      "train loss:0.909234000555768\n",
      "train loss:0.8385390510933821\n",
      "train loss:0.8094345413857154\n",
      "train loss:0.7598841583798154\n",
      "train loss:0.8227461401290072\n",
      "train loss:0.8445743077221496\n",
      "train loss:0.7345617785860159\n",
      "train loss:0.9387799346693442\n",
      "train loss:0.8158667394213505\n",
      "train loss:0.8157581461353015\n",
      "train loss:0.7807264277534475\n",
      "train loss:0.85126312791118\n",
      "train loss:0.9737908994173963\n",
      "train loss:0.8485879441162879\n",
      "train loss:0.8267443282072472\n",
      "train loss:0.8464124877810688\n",
      "train loss:0.9123847372976738\n",
      "train loss:0.8127637121916587\n",
      "train loss:0.813728603847428\n",
      "train loss:1.0177833918080044\n",
      "train loss:0.8062589120854972\n",
      "train loss:0.9160995074622469\n",
      "train loss:0.8495224489714466\n",
      "train loss:1.059481119279371\n",
      "train loss:0.8991663905968963\n",
      "train loss:0.6733938711210904\n",
      "train loss:1.0169993121857095\n",
      "train loss:1.006703559990129\n",
      "train loss:0.9109813525556961\n",
      "train loss:0.8655971799788219\n",
      "train loss:0.8913547373240985\n",
      "train loss:0.9298305773730321\n",
      "train loss:0.8817166488625674\n",
      "train loss:0.8907559911809335\n",
      "train loss:0.9469077312538573\n",
      "train loss:0.7671937208972918\n",
      "train loss:0.8359808040116037\n",
      "train loss:0.8972966718650836\n",
      "train loss:0.8919799839220108\n",
      "train loss:0.9565486128127658\n",
      "train loss:0.8542342309674419\n",
      "train loss:0.9813003149684906\n",
      "train loss:0.9557037600032949\n",
      "train loss:0.7258847923304727\n",
      "train loss:0.8719862149791239\n",
      "train loss:0.858974891657253\n",
      "train loss:0.8246230260908045\n",
      "train loss:0.752996913283155\n",
      "train loss:0.8022295703484369\n",
      "train loss:0.8573177351188952\n",
      "train loss:0.9258008202065408\n",
      "train loss:0.8210277302941413\n",
      "train loss:0.8878729484526034\n",
      "train loss:0.8318774366263775\n",
      "train loss:0.7687135682863842\n",
      "train loss:0.783291890489701\n",
      "train loss:0.9199738152139989\n",
      "train loss:0.8451572805202977\n",
      "train loss:0.8968563142328538\n",
      "train loss:0.8842977647260959\n",
      "train loss:0.8386021265442516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8016451707519096\n",
      "train loss:0.9951509719345785\n",
      "train loss:0.9354105019455904\n",
      "train loss:0.9196240381468145\n",
      "train loss:0.8768608566587023\n",
      "train loss:0.8828811210215709\n",
      "train loss:0.9217880675146923\n",
      "train loss:0.8280662186975161\n",
      "train loss:0.8643949860004975\n",
      "train loss:0.8639913806493036\n",
      "train loss:0.8056179369792065\n",
      "train loss:0.9315441457111036\n",
      "train loss:0.7925501477328776\n",
      "train loss:0.8838892800329716\n",
      "train loss:0.8018530882575257\n",
      "train loss:0.8300032992605376\n",
      "train loss:0.852077208627872\n",
      "train loss:0.9262874798862467\n",
      "train loss:0.8532828780583902\n",
      "train loss:0.9617648408695461\n",
      "train loss:0.770835371693143\n",
      "train loss:0.9255749600272355\n",
      "train loss:0.7190767238734722\n",
      "train loss:0.988060803139674\n",
      "train loss:0.983988054810417\n",
      "train loss:0.987525214716538\n",
      "train loss:0.7140658850152016\n",
      "train loss:0.677142094108751\n",
      "train loss:0.986543850984901\n",
      "train loss:0.7562748679504436\n",
      "train loss:0.7958045446785633\n",
      "train loss:0.8668942945470418\n",
      "train loss:0.7984243253082706\n",
      "train loss:0.8233011742797121\n",
      "train loss:0.8384282961978515\n",
      "train loss:0.7396507659401861\n",
      "train loss:0.98435566702062\n",
      "train loss:0.9967831756230591\n",
      "train loss:0.939571840407182\n",
      "train loss:0.844326121573962\n",
      "train loss:0.7259243232290556\n",
      "train loss:0.8756758825280765\n",
      "train loss:0.8935264961216369\n",
      "train loss:0.6867003938952047\n",
      "train loss:0.853348366525359\n",
      "train loss:0.7021671929144078\n",
      "train loss:0.9032387631154074\n",
      "train loss:0.9635186635720251\n",
      "train loss:0.8972628131310282\n",
      "train loss:0.7891162496914608\n",
      "train loss:0.851492493090247\n",
      "train loss:0.9865616614981516\n",
      "train loss:0.777478902026855\n",
      "train loss:0.9268402006743647\n",
      "train loss:0.8926322157904294\n",
      "train loss:0.835942841628858\n",
      "train loss:0.6929993544121759\n",
      "train loss:0.9564646975653035\n",
      "train loss:0.8851339474780653\n",
      "train loss:0.8476038124848639\n",
      "train loss:0.8635381882778571\n",
      "train loss:0.7458078803663319\n",
      "train loss:0.7873539429713914\n",
      "train loss:0.8797229463783409\n",
      "train loss:0.8551990544198337\n",
      "train loss:0.9063122891334401\n",
      "train loss:0.7964041293396212\n",
      "train loss:0.8150578908108908\n",
      "train loss:0.8426565844675612\n",
      "train loss:0.8229048560775156\n",
      "train loss:0.7402211731169226\n",
      "train loss:0.6341904919106258\n",
      "train loss:0.8800349715199245\n",
      "train loss:1.1697936452376516\n",
      "train loss:0.9281706356328985\n",
      "train loss:0.8291050811854158\n",
      "train loss:0.8801900657887682\n",
      "train loss:0.9134570586178887\n",
      "train loss:0.9257908272488707\n",
      "train loss:0.8031226792740038\n",
      "train loss:0.9230180304671066\n",
      "train loss:0.9839094685082891\n",
      "train loss:0.9809581413462404\n",
      "train loss:0.7880918220881358\n",
      "train loss:1.0242976557863466\n",
      "train loss:0.9312063711357979\n",
      "train loss:0.8009462256243057\n",
      "train loss:0.8963483779082663\n",
      "train loss:0.9156460038471325\n",
      "train loss:0.6938365997323508\n",
      "train loss:0.9124359517259039\n",
      "train loss:0.830290288700531\n",
      "train loss:0.9462680626539288\n",
      "train loss:1.0428773599935561\n",
      "train loss:0.7009796513620459\n",
      "train loss:0.7788291610041221\n",
      "train loss:0.8291884905318017\n",
      "train loss:0.843713439395534\n",
      "train loss:0.8429972879522277\n",
      "train loss:0.6884592048311905\n",
      "train loss:0.9128049553765922\n",
      "train loss:0.9478966100262832\n",
      "train loss:0.7770765662252326\n",
      "train loss:0.8720714155260145\n",
      "train loss:0.9585576618712005\n",
      "train loss:0.8998070056413142\n",
      "train loss:0.8255498915330545\n",
      "train loss:0.8915498573914067\n",
      "train loss:0.8409345794507612\n",
      "train loss:0.6642994049261906\n",
      "train loss:1.0103765921294068\n",
      "train loss:0.9588231289267334\n",
      "train loss:1.0116372164739404\n",
      "train loss:0.8094409442490309\n",
      "train loss:0.7817925590600061\n",
      "train loss:0.9223222326467425\n",
      "train loss:0.9445496787625903\n",
      "train loss:0.9214849108055728\n",
      "train loss:0.9419076112761003\n",
      "train loss:0.8167135066368245\n",
      "train loss:0.8122124223047402\n",
      "train loss:0.9448444557063069\n",
      "train loss:0.747769783100367\n",
      "train loss:0.8017549777560612\n",
      "train loss:0.8670457480869436\n",
      "train loss:0.9368796920728255\n",
      "train loss:0.8242357585889419\n",
      "train loss:0.7811189296543484\n",
      "train loss:0.8322318578492076\n",
      "train loss:0.9787373691050364\n",
      "train loss:0.8237076963039506\n",
      "train loss:0.8685452222895554\n",
      "train loss:0.7262809124830382\n",
      "train loss:0.8133909832927341\n",
      "train loss:1.0189010860884304\n",
      "train loss:0.6926955954469933\n",
      "train loss:0.8242007660230223\n",
      "train loss:0.812476978903041\n",
      "train loss:1.1211316905145317\n",
      "train loss:0.8835513066840371\n",
      "train loss:0.9732920527431648\n",
      "train loss:0.7054015136546831\n",
      "train loss:0.8488008556597744\n",
      "train loss:0.8649797981694922\n",
      "train loss:0.689946895622899\n",
      "train loss:0.7436032251508208\n",
      "train loss:0.7379240508681706\n",
      "train loss:0.9493595004386739\n",
      "train loss:0.8643218377163806\n",
      "train loss:0.9378931564802965\n",
      "train loss:0.8164892262303982\n",
      "train loss:0.8401426791005322\n",
      "train loss:0.8757186371917745\n",
      "train loss:0.8725041372364578\n",
      "train loss:0.7910156772298097\n",
      "train loss:0.9303198426548625\n",
      "train loss:0.7309688605117337\n",
      "train loss:0.8436233957077169\n",
      "train loss:0.7977580529818326\n",
      "=== epoch:20, train acc:1.0, test acc:0.99 ===\n",
      "train loss:0.790415610111923\n",
      "train loss:0.8276113673398227\n",
      "train loss:0.8203987006713751\n",
      "train loss:0.8229909432254368\n",
      "train loss:0.7087443608983014\n",
      "train loss:0.6923782998340212\n",
      "train loss:0.566136633796173\n",
      "train loss:0.8231963541306772\n",
      "train loss:0.7508347875965038\n",
      "train loss:0.8604783366584351\n",
      "train loss:0.7687874658878472\n",
      "train loss:0.9761939831491238\n",
      "train loss:0.777399461530631\n",
      "train loss:0.9837406601274873\n",
      "train loss:0.8911449648482762\n",
      "train loss:0.8597029702868582\n",
      "train loss:0.874631983564925\n",
      "train loss:0.8145890553637785\n",
      "train loss:0.9856331949120368\n",
      "train loss:0.9012746148294951\n",
      "train loss:1.0151832312863578\n",
      "train loss:0.7064911594460491\n",
      "train loss:0.8881254341079283\n",
      "train loss:0.9135836980149605\n",
      "train loss:0.711240747080132\n",
      "train loss:0.9156445206361168\n",
      "train loss:0.8906413595800861\n",
      "train loss:0.7993960220380981\n",
      "train loss:0.7720265009212111\n",
      "train loss:0.8319829360770735\n",
      "train loss:0.7324365012339404\n",
      "train loss:0.7990297040971696\n",
      "train loss:0.8290276395586907\n",
      "train loss:0.7018722519501979\n",
      "train loss:0.7819000370296721\n",
      "train loss:0.8287797632026909\n",
      "train loss:0.8806876725508382\n",
      "train loss:0.8292645378536975\n",
      "train loss:1.0301395501339288\n",
      "train loss:0.9073292979916053\n",
      "train loss:0.933697288485748\n",
      "train loss:0.9107808445339409\n",
      "train loss:0.9760473800790638\n",
      "train loss:0.6949847904969931\n",
      "train loss:0.9223193001552406\n",
      "train loss:0.8681911251714176\n",
      "train loss:0.8025329933278063\n",
      "train loss:0.8562597517373818\n",
      "train loss:0.8322926255565503\n",
      "train loss:0.7678224076014836\n",
      "train loss:0.8648163173734852\n",
      "train loss:0.8040882508881146\n",
      "train loss:0.7346396960206566\n",
      "train loss:0.7892377290363578\n",
      "train loss:0.8227478792200401\n",
      "train loss:0.9176886577466788\n",
      "train loss:0.9114446803109508\n",
      "train loss:0.8284473542583111\n",
      "train loss:0.8224107753244312\n",
      "train loss:0.8550472240061566\n",
      "train loss:0.8546148053798681\n",
      "train loss:0.992835895697841\n",
      "train loss:0.7364931637731595\n",
      "train loss:0.9905696784098869\n",
      "train loss:0.7083796603610081\n",
      "train loss:0.8695048415357414\n",
      "train loss:0.9986928893769147\n",
      "train loss:0.8562012010080564\n",
      "train loss:0.7734493936763794\n",
      "train loss:0.963262350577251\n",
      "train loss:0.685079506666644\n",
      "train loss:0.8472178479342938\n",
      "train loss:0.699853946167274\n",
      "train loss:0.8605055092623861\n",
      "train loss:0.8374149837770978\n",
      "train loss:0.8926383802994354\n",
      "train loss:0.849032849636835\n",
      "train loss:0.8522076546007095\n",
      "train loss:0.7780342268240767\n",
      "train loss:0.8633688480725555\n",
      "train loss:0.9694447925774403\n",
      "train loss:0.877981412255333\n",
      "train loss:0.7968325529855177\n",
      "train loss:0.8127363157301268\n",
      "train loss:0.7282495888515942\n",
      "train loss:0.871897424827319\n",
      "train loss:0.9848913774938695\n",
      "train loss:0.8567542546882042\n",
      "train loss:0.7535164597633203\n",
      "train loss:0.7389159463041564\n",
      "train loss:0.7480653377087321\n",
      "train loss:0.8202733925105234\n",
      "train loss:0.9243676045919754\n",
      "train loss:0.9498996798523701\n",
      "train loss:0.8677248847289853\n",
      "train loss:0.9178058230342127\n",
      "train loss:0.8693077846660237\n",
      "train loss:0.9572576079968788\n",
      "train loss:0.8966359711879509\n",
      "train loss:0.9151078321075414\n",
      "train loss:0.8317279409213107\n",
      "train loss:0.9275437180705417\n",
      "train loss:0.898568753135421\n",
      "train loss:0.7287384370848876\n",
      "train loss:0.78918746567418\n",
      "train loss:0.9721422842701654\n",
      "train loss:0.8513866663881612\n",
      "train loss:0.8578128911862083\n",
      "train loss:1.0491384634036123\n",
      "train loss:0.9045415443264934\n",
      "train loss:0.8832769220751615\n",
      "train loss:0.9814142461811268\n",
      "train loss:0.9622562141975344\n",
      "train loss:0.8613352142402487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9052657468636653\n",
      "train loss:0.804172331042119\n",
      "train loss:0.869862705159358\n",
      "train loss:1.0176242822174675\n",
      "train loss:0.8281374011389612\n",
      "train loss:0.8035319898779077\n",
      "train loss:0.7570994523816119\n",
      "train loss:0.8679365736037074\n",
      "train loss:0.9653729460611019\n",
      "train loss:0.8708074803912069\n",
      "train loss:0.9298660202882679\n",
      "train loss:0.8826975142345264\n",
      "train loss:0.9361037623920322\n",
      "train loss:1.0246819994602172\n",
      "train loss:0.835166009469379\n",
      "train loss:0.8173478413138916\n",
      "train loss:0.7888392288907832\n",
      "train loss:0.8986061909329508\n",
      "train loss:0.7610089222361133\n",
      "train loss:0.7468073352255102\n",
      "train loss:0.8555033402198989\n",
      "train loss:0.8933313308779287\n",
      "train loss:0.7657176808574085\n",
      "train loss:0.9515876480775916\n",
      "train loss:0.8366284916695943\n",
      "train loss:0.8224778362464694\n",
      "train loss:0.8169818660753633\n",
      "train loss:0.9583924220239417\n",
      "train loss:0.8289160500071893\n",
      "train loss:1.021043982551216\n",
      "train loss:1.01609052336005\n",
      "train loss:0.7650628122369718\n",
      "train loss:0.8257498641715069\n",
      "train loss:0.7518185751816123\n",
      "train loss:0.9594350637976545\n",
      "train loss:0.7960297179438344\n",
      "train loss:0.8675119161430684\n",
      "train loss:0.8684507316296888\n",
      "train loss:0.800246094770813\n",
      "train loss:0.9793212071914975\n",
      "train loss:0.7181613319610222\n",
      "train loss:0.9060606466425152\n",
      "train loss:0.9354856844080222\n",
      "train loss:0.9211254978579191\n",
      "train loss:0.9235430207523896\n",
      "train loss:0.9496241962898337\n",
      "train loss:0.8815834335286872\n",
      "train loss:0.7084049248766524\n",
      "train loss:0.7027663211983967\n",
      "train loss:0.7532418867169197\n",
      "train loss:0.7386614574762663\n",
      "train loss:0.8569794164338822\n",
      "train loss:0.9514131468733489\n",
      "train loss:0.8968149854491514\n",
      "train loss:0.7867209575038708\n",
      "train loss:0.854830019091232\n",
      "train loss:0.8677962659654878\n",
      "train loss:0.8418086242700825\n",
      "train loss:0.9971957249213723\n",
      "train loss:0.8387992811613669\n",
      "train loss:0.8899588955835656\n",
      "train loss:0.9386529058553257\n",
      "train loss:0.8527847202521815\n",
      "train loss:0.7774646366415794\n",
      "train loss:0.9583158271598683\n",
      "train loss:0.9838882344733199\n",
      "train loss:0.8579434797224748\n",
      "train loss:0.8205618008329044\n",
      "train loss:0.8131779106820838\n",
      "train loss:0.8053603127777258\n",
      "train loss:1.0892931816603433\n",
      "train loss:0.844831747820978\n",
      "train loss:0.9756937805102837\n",
      "train loss:0.8740815274792538\n",
      "train loss:0.826284916801629\n",
      "train loss:0.9155240117724778\n",
      "train loss:1.0343259180862925\n",
      "train loss:0.8833814223641024\n",
      "train loss:0.9445588141653792\n",
      "train loss:1.0035491883458925\n",
      "train loss:0.8104288145607991\n",
      "train loss:0.8300499361907444\n",
      "train loss:0.7745592846385512\n",
      "train loss:0.8975002175522384\n",
      "train loss:0.9235376209448063\n",
      "train loss:0.8595641650565697\n",
      "train loss:0.7962571530213249\n",
      "train loss:0.8400719005041936\n",
      "train loss:0.8456140100326627\n",
      "train loss:0.931576913735195\n",
      "train loss:0.9220484789344059\n",
      "train loss:0.844419504679378\n",
      "train loss:0.6787268410821519\n",
      "train loss:0.9539714721939242\n",
      "train loss:0.81432728658356\n",
      "train loss:0.9087724490634804\n",
      "train loss:0.9392088026452798\n",
      "train loss:1.0419016431010142\n",
      "train loss:0.7039588468388079\n",
      "train loss:0.6565344365805857\n",
      "train loss:0.7556978834366309\n",
      "train loss:0.8538271754021093\n",
      "train loss:0.8954146135523107\n",
      "train loss:0.8104003421144169\n",
      "train loss:0.8455864075009546\n",
      "train loss:0.8612853021784601\n",
      "train loss:0.7829495383391847\n",
      "train loss:0.7066923490960635\n",
      "train loss:0.9396997660900213\n",
      "train loss:0.9260380958625848\n",
      "train loss:0.747364765499587\n",
      "train loss:0.9111006904227446\n",
      "train loss:0.8490615273151463\n",
      "train loss:0.8554638120871193\n",
      "train loss:0.9269148998695207\n",
      "train loss:0.8700104299101754\n",
      "train loss:0.7219293767500591\n",
      "train loss:0.8127964970848004\n",
      "train loss:0.7969348992011304\n",
      "train loss:0.9236028139553959\n",
      "train loss:0.7795716501653278\n",
      "train loss:0.7851706254499301\n",
      "train loss:0.7867241904442355\n",
      "train loss:0.9019972358859352\n",
      "train loss:1.0164959086371355\n",
      "train loss:0.9033757485513118\n",
      "train loss:1.0137408237235659\n",
      "train loss:0.8028480728100856\n",
      "train loss:0.6681321645074482\n",
      "train loss:0.8241026738426939\n",
      "train loss:0.9605988987585543\n",
      "train loss:0.7912823602916933\n",
      "train loss:0.7444892296989002\n",
      "train loss:0.8629642106485469\n",
      "train loss:0.8708886960508394\n",
      "train loss:0.802044562853046\n",
      "train loss:0.8913550999329937\n",
      "train loss:0.7763068977926286\n",
      "train loss:0.9340128597520478\n",
      "train loss:0.7854107932070461\n",
      "train loss:0.864232949763571\n",
      "train loss:1.009056468889917\n",
      "train loss:0.8351459077508899\n",
      "train loss:0.9785670003341093\n",
      "train loss:0.7368872055511548\n",
      "train loss:0.9068473493771962\n",
      "train loss:0.6793449772565383\n",
      "train loss:0.8281903113752819\n",
      "train loss:0.7947983637989224\n",
      "train loss:0.7934647251320647\n",
      "train loss:0.8662934333709981\n",
      "train loss:0.743034324846406\n",
      "train loss:0.9548192587976326\n",
      "train loss:0.8670311625738139\n",
      "train loss:0.933924596554166\n",
      "train loss:0.8873285852217677\n",
      "train loss:0.8352882301005577\n",
      "train loss:0.7791765140421822\n",
      "train loss:0.8631170628475461\n",
      "train loss:0.9666034491926342\n",
      "train loss:0.8310052599168505\n",
      "train loss:0.9013138032963026\n",
      "train loss:0.8340593413347327\n",
      "train loss:0.8318467798443607\n",
      "train loss:0.9908463050151108\n",
      "train loss:1.0936303725461765\n",
      "train loss:0.9185151165183434\n",
      "train loss:0.8850243562397274\n",
      "train loss:0.9563709241373428\n",
      "train loss:0.9737403177482679\n",
      "train loss:0.6229472282134381\n",
      "train loss:0.9289051679131874\n",
      "train loss:0.8209209945145457\n",
      "train loss:0.885470217481741\n",
      "train loss:0.8408326678142289\n",
      "train loss:0.7755711355824303\n",
      "train loss:0.8856036446429957\n",
      "train loss:0.757196958785429\n",
      "train loss:0.9373852643941929\n",
      "train loss:0.9461238957485567\n",
      "train loss:0.8879304644680951\n",
      "train loss:0.8121112895946248\n",
      "train loss:0.9516316920557039\n",
      "train loss:0.6676562891232198\n",
      "train loss:0.8405287900146373\n",
      "train loss:0.9239909672397308\n",
      "train loss:0.8199432383846735\n",
      "train loss:1.0716527858497333\n",
      "train loss:0.8049672228550611\n",
      "train loss:0.8987122204022638\n",
      "train loss:0.9059344945557471\n",
      "train loss:0.8381515404362554\n",
      "train loss:0.9222748869191163\n",
      "train loss:0.794743469005075\n",
      "train loss:0.9124687226169484\n",
      "train loss:0.6752715354313962\n",
      "train loss:0.8477460038469321\n",
      "train loss:1.0394150433846376\n",
      "train loss:0.8305144250017652\n",
      "train loss:0.6520564851692953\n",
      "train loss:0.769552214013888\n",
      "train loss:0.8366712492856136\n",
      "train loss:0.8734625577784206\n",
      "train loss:0.9515392302107283\n",
      "train loss:1.0311206791135072\n",
      "train loss:0.8891674192305082\n",
      "train loss:0.9071849285039261\n",
      "train loss:0.7552085227442998\n",
      "train loss:0.8957516247936179\n",
      "train loss:0.8060310711098424\n",
      "train loss:0.9570267633840693\n",
      "train loss:0.7659735550128492\n",
      "train loss:0.7055586318848188\n",
      "train loss:0.7341595917599595\n",
      "train loss:0.9377189610966579\n",
      "train loss:0.8431829820213301\n",
      "train loss:0.9182674633384746\n",
      "train loss:0.9013997847154697\n",
      "train loss:0.9158125014207512\n",
      "train loss:0.9745830722543013\n",
      "train loss:0.8223519608724148\n",
      "train loss:0.9465610475994855\n",
      "train loss:0.8048765398833804\n",
      "train loss:0.9408988211365298\n",
      "train loss:0.7687721350712021\n",
      "train loss:0.8284644453686895\n",
      "train loss:0.8685571946285233\n",
      "train loss:0.9545863612774032\n",
      "train loss:0.9131841013948345\n",
      "train loss:0.8984794882692726\n",
      "train loss:0.8121192633546533\n",
      "train loss:0.867696561180219\n",
      "train loss:0.8280067010851907\n",
      "train loss:0.9913496627193186\n",
      "train loss:0.7681368587761044\n",
      "train loss:0.9131166175798804\n",
      "train loss:0.9037514298211523\n",
      "train loss:0.8150913104016527\n",
      "train loss:0.8617407212299455\n",
      "train loss:0.8622684688979863\n",
      "train loss:0.8347316789216843\n",
      "train loss:0.7718122041980192\n",
      "train loss:0.9170619172515714\n",
      "train loss:0.9346687266605563\n",
      "train loss:0.7906092500973223\n",
      "train loss:0.853020483137608\n",
      "train loss:0.9108615511581394\n",
      "train loss:0.8007855303653014\n",
      "train loss:0.757845865219644\n",
      "train loss:0.885892183470809\n",
      "train loss:0.8003930236901293\n",
      "train loss:0.605841875889774\n",
      "train loss:0.8216914395555829\n",
      "train loss:0.881052487700613\n",
      "train loss:0.8340464460644808\n",
      "train loss:0.937853100766994\n",
      "train loss:1.0247910988812718\n",
      "train loss:0.7983376363718269\n",
      "train loss:0.8165289013234421\n",
      "train loss:0.9206304544958\n",
      "train loss:0.9103362658547799\n",
      "train loss:0.8607257616787116\n",
      "train loss:0.8124739981373686\n",
      "train loss:0.8280199350398857\n",
      "train loss:0.797412603899909\n",
      "train loss:0.9393232131100785\n",
      "train loss:0.9133507393398694\n",
      "train loss:0.975348746608764\n",
      "train loss:0.7800493008360703\n",
      "train loss:0.7159548152043027\n",
      "train loss:0.9386400752063473\n",
      "train loss:0.8349681622928822\n",
      "train loss:0.8316114049081501\n",
      "train loss:0.6588664477566681\n",
      "train loss:0.838652037373927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7123226254623151\n",
      "train loss:0.8439002841969977\n",
      "train loss:0.9468283487164959\n",
      "train loss:0.7715309041475693\n",
      "train loss:0.8296177385877046\n",
      "train loss:0.8538485752386343\n",
      "train loss:0.7671115670729002\n",
      "train loss:0.8376590733179623\n",
      "train loss:0.90374259587767\n",
      "train loss:0.9065686116162631\n",
      "train loss:0.8253178569301007\n",
      "train loss:0.8449245373915301\n",
      "train loss:0.9507264810966564\n",
      "train loss:0.8165434639957898\n",
      "train loss:0.6838935332635232\n",
      "train loss:0.9580859087754358\n",
      "train loss:1.003987958236137\n",
      "train loss:0.7243980666160944\n",
      "train loss:0.9204842577642891\n",
      "train loss:0.6814468401007636\n",
      "train loss:0.8035924250454025\n",
      "train loss:0.9446383649949045\n",
      "train loss:0.8627155865040413\n",
      "train loss:0.9009177656082337\n",
      "train loss:0.8775428864543976\n",
      "train loss:0.748703468155106\n",
      "train loss:0.9123205492991279\n",
      "train loss:0.9232449430918548\n",
      "train loss:0.7945882447645812\n",
      "train loss:0.8032258747082088\n",
      "train loss:0.7284109958135717\n",
      "train loss:0.8161677356086987\n",
      "train loss:0.8604724060853053\n",
      "train loss:1.0597817238511562\n",
      "train loss:0.7388080833389779\n",
      "train loss:0.9011591166775426\n",
      "train loss:0.9935635845095057\n",
      "train loss:0.7632870537957467\n",
      "train loss:0.8503455969719512\n",
      "train loss:0.7471805452660084\n",
      "train loss:0.7541808130734308\n",
      "train loss:0.7642983967974415\n",
      "train loss:0.8734768369885089\n",
      "train loss:0.7704078622670668\n",
      "train loss:0.6878101141701244\n",
      "train loss:0.8480271120604254\n",
      "train loss:0.7330074650267838\n",
      "train loss:0.8501535164456403\n",
      "train loss:0.8825920106727512\n",
      "train loss:1.028981360497433\n",
      "train loss:0.9026566059451178\n",
      "train loss:0.9105839724710879\n",
      "train loss:0.7373174252608184\n",
      "train loss:0.970696461419895\n",
      "train loss:0.8500970965270267\n",
      "train loss:0.8021092072965567\n",
      "train loss:0.8920250792555791\n",
      "train loss:0.9233112272688869\n",
      "train loss:1.1249583379244108\n",
      "train loss:0.7848393597289899\n",
      "train loss:0.8803356112338427\n",
      "train loss:0.828117752129049\n",
      "train loss:0.6597353639530148\n",
      "train loss:0.7994784389216855\n",
      "train loss:0.7519405815254058\n",
      "train loss:0.7649251139736165\n",
      "train loss:0.9044516873128202\n",
      "train loss:0.9492468995650516\n",
      "train loss:0.8116283675279854\n",
      "train loss:0.9461633090126952\n",
      "train loss:0.8226962478402406\n",
      "train loss:0.7791552974260199\n",
      "train loss:0.869317213122324\n",
      "train loss:0.7869706022906034\n",
      "train loss:0.8551235544014353\n",
      "train loss:0.8332820515420717\n",
      "train loss:0.897540278423821\n",
      "train loss:0.847065661685922\n",
      "train loss:0.95382412217414\n",
      "train loss:0.7787984808521601\n",
      "train loss:1.0201731494686568\n",
      "train loss:0.9863603712894373\n",
      "train loss:0.7346831936353495\n",
      "train loss:0.88960167804671\n",
      "train loss:0.9151372365901821\n",
      "train loss:0.7961560189431256\n",
      "train loss:0.8012703192803861\n",
      "train loss:0.7951643889107171\n",
      "train loss:0.942467876939551\n",
      "train loss:0.9925211583038288\n",
      "train loss:0.9668996879900598\n",
      "train loss:0.986372587005547\n",
      "train loss:0.6467465029231753\n",
      "train loss:1.0163608274993154\n",
      "train loss:0.8738396307591683\n",
      "train loss:0.9474433890352119\n",
      "train loss:0.9193044647935493\n",
      "train loss:0.8862271048885831\n",
      "train loss:0.7266910899239025\n",
      "train loss:0.8388096479958534\n",
      "train loss:0.7892719444850331\n",
      "train loss:0.90065620534721\n",
      "train loss:1.0767056533592814\n",
      "train loss:0.8749556132013467\n",
      "train loss:0.9496246964543237\n",
      "train loss:0.8345563519362037\n",
      "train loss:0.8899055841092056\n",
      "train loss:0.722165669578935\n",
      "train loss:0.7518285330022235\n",
      "train loss:0.8655143792143359\n",
      "train loss:0.8740270502398262\n",
      "train loss:1.006546850126928\n",
      "train loss:0.730058040640109\n",
      "train loss:0.8826723649760473\n",
      "train loss:0.8572853023095844\n",
      "train loss:0.8608630412175308\n",
      "train loss:0.7983196693520545\n",
      "train loss:0.9215826131971486\n",
      "train loss:0.6422464369811247\n",
      "train loss:1.0300578473671071\n",
      "train loss:0.8476398231574335\n",
      "train loss:1.0938715520018045\n",
      "train loss:0.831710040796941\n",
      "train loss:0.9241646178364721\n",
      "train loss:0.9357745433511471\n",
      "train loss:0.8796081173413727\n",
      "train loss:0.7405814943254865\n",
      "train loss:0.6967694024677256\n",
      "train loss:0.7595497499530258\n",
      "train loss:0.9207393931133724\n",
      "train loss:0.8798270943771413\n",
      "train loss:0.9332462611609958\n",
      "train loss:0.8437640980439408\n",
      "train loss:0.853990854491164\n",
      "train loss:0.8647409022357635\n",
      "train loss:0.9396170720590541\n",
      "train loss:0.8468854276793871\n",
      "train loss:0.8244375711946862\n",
      "train loss:0.79397911765015\n",
      "train loss:0.8645913978436576\n",
      "train loss:0.771872914549021\n",
      "train loss:0.8068085524239464\n",
      "train loss:0.8360847525100301\n",
      "train loss:0.7483129097534718\n",
      "train loss:0.8211327599537697\n",
      "train loss:0.9630952258975369\n",
      "train loss:0.8989231992147104\n",
      "train loss:0.8233851197725588\n",
      "train loss:0.8454637191232771\n",
      "train loss:0.8675236578971911\n",
      "train loss:0.7891701955705033\n",
      "train loss:0.836489240218745\n",
      "train loss:0.877384762233868\n",
      "train loss:0.8938121760607752\n",
      "train loss:0.9695386791200903\n",
      "train loss:0.7134917939889347\n",
      "train loss:0.9486765288286138\n",
      "train loss:0.9004056164421113\n",
      "train loss:0.7064926281863247\n",
      "train loss:0.8805746737883139\n",
      "train loss:0.9907521264821949\n",
      "train loss:0.9544635546033062\n",
      "train loss:0.8428643905842018\n",
      "train loss:0.8765688075414185\n",
      "train loss:0.822872078278369\n",
      "train loss:0.8677170544303475\n",
      "train loss:0.820479495423823\n",
      "train loss:0.7882424087541581\n",
      "train loss:0.9090510324087042\n",
      "train loss:0.7346506101064303\n",
      "train loss:0.8549399854362085\n",
      "train loss:0.9952192735255124\n",
      "train loss:0.9801070949807158\n",
      "train loss:0.8589185676338663\n",
      "train loss:0.840959821523933\n",
      "train loss:0.7685462114010566\n",
      "train loss:0.8986091510459053\n",
      "train loss:0.872880118422226\n",
      "train loss:0.9088275283859548\n",
      "train loss:0.9760605262052588\n",
      "train loss:0.840074097008636\n",
      "train loss:0.8939069345611257\n",
      "train loss:0.8836566621488398\n",
      "train loss:0.9195113864615653\n",
      "train loss:1.0493337161820957\n",
      "train loss:1.0072605336382683\n",
      "train loss:0.8427076665395998\n",
      "train loss:0.8959897287873421\n",
      "train loss:0.8071587936331659\n",
      "train loss:0.8730947700410332\n",
      "train loss:0.7968267699031236\n",
      "train loss:0.9787751614215396\n",
      "train loss:0.7663360017583275\n",
      "train loss:0.8030807525247867\n",
      "train loss:0.871282159470979\n",
      "train loss:0.9584029707916364\n",
      "train loss:0.9320426720837176\n",
      "train loss:0.9518159570469503\n",
      "train loss:0.9521397374892612\n",
      "train loss:0.8896046959733946\n",
      "train loss:0.9387276947885641\n",
      "train loss:0.8591192294975489\n",
      "train loss:0.8497769009801845\n",
      "train loss:0.7901239040065439\n",
      "train loss:0.9491650910732757\n",
      "train loss:0.8462566457770647\n",
      "train loss:0.7875613207852098\n",
      "train loss:0.7817733217904967\n",
      "train loss:0.9693180870916076\n",
      "train loss:1.0130625683689973\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9915\n",
      "Saved Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from deep_convnet import DeepConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=20, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보관\n",
    "network.save_params(\"deep_convnet_params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating test accuracy ... \n",
      "test accuracy:0.9915\n",
      "======= misclassified result =======\n",
      "{view index: (label, inference), ...}\n",
      "{1: (4, 6), 2: (8, 4), 3: (2, 1), 4: (5, 3), 5: (4, 9), 6: (4, 9), 7: (8, 2), 8: (2, 7), 9: (2, 1), 10: (5, 3), 11: (1, 7), 12: (8, 9), 13: (6, 5), 14: (4, 6), 15: (7, 2), 16: (9, 4), 17: (7, 1), 18: (8, 3), 19: (5, 3), 20: (1, 3)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_convnet import DeepConvNet\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "print(\"calculating test accuracy ... \")\n",
    "#sampled = 1000\n",
    "#x_test = x_test[:sampled]\n",
    "#t_test = t_test[:sampled]\n",
    "\n",
    "classified_ids = []\n",
    "\n",
    "acc = 0.0\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(int(x_test.shape[0] / batch_size)):\n",
    "    tx = x_test[i*batch_size:(i+1)*batch_size]\n",
    "    tt = t_test[i*batch_size:(i+1)*batch_size]\n",
    "    y = network.predict(tx, train_flg=False)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    classified_ids.append(y)\n",
    "    acc += np.sum(y == tt)\n",
    "    \n",
    "acc = acc / x_test.shape[0]\n",
    "print(\"test accuracy:\" + str(acc))\n",
    "\n",
    "classified_ids = np.array(classified_ids)\n",
    "classified_ids = classified_ids.flatten()\n",
    " \n",
    "max_view = 20\n",
    "current_view = 1\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.2, wspace=0.2)\n",
    "\n",
    "mis_pairs = {}\n",
    "for i, val in enumerate(classified_ids == t_test):\n",
    "    if not val:\n",
    "        ax = fig.add_subplot(4, 5, current_view, xticks=[], yticks=[])\n",
    "        ax.imshow(x_test[i].reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        mis_pairs[current_view] = (t_test[i], classified_ids[i])\n",
    "            \n",
    "        current_view += 1\n",
    "        if current_view > max_view:\n",
    "            break\n",
    "\n",
    "print(\"======= misclassified result =======\")\n",
    "print(\"{view index: (label, inference), ...}\")\n",
    "print(mis_pairs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caluculate accuracy (float64) ... \n",
      "0.9915\n",
      "caluculate accuracy (float16) ... \n",
      "0.9915\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_convnet import DeepConvNet\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "sampled = 10000 # 고속화를 위한 표본추출\n",
    "x_test = x_test[:sampled]\n",
    "t_test = t_test[:sampled]\n",
    "\n",
    "print(\"caluculate accuracy (float64) ... \")\n",
    "print(network.accuracy(x_test, t_test))\n",
    "\n",
    "# float16(반정밀도)로 형변환\n",
    "x_test = x_test.astype(np.float16)\n",
    "for param in network.params.values():\n",
    "    param[...] = param.astype(np.float16)\n",
    "\n",
    "print(\"caluculate accuracy (float16) ... \")\n",
    "print(network.accuracy(x_test, t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
