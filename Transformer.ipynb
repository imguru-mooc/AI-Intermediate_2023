{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 1. 2. 3.], shape=(4,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]], shape=(4, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "position=4\n",
    "position=tf.range(position, dtype=tf.float32)\n",
    "print(position)\n",
    "position = position[:, tf.newaxis]\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 1. 2. 3. 4. 5. 6. 7.], shape=(8,), dtype=float32)\n",
      "[[0. 1. 2. 3. 4. 5. 6. 7.]]\n"
     ]
    }
   ],
   "source": [
    "d_model=8\n",
    "i=tf.range(d_model, dtype=tf.float32)\n",
    "print(i)\n",
    "i = i[tf.newaxis, :]\n",
    "print(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position * i   # (4,1)(1,8) => (4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 0. 2. 2. 4. 4. 6. 6.]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(2 * (i // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.   0.   0.25 0.25 0.5  0.5  0.75 0.75]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print((2 * (i // 2))/tf.cast(d_model, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  1.        1.       10.       10.       99.99999  99.99999 999.99994\n",
      "  999.99994]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.    1.    0.1   0.1   0.01  0.01  0.001 0.001]], shape=(1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "print(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8), dtype=float32, numpy=\n",
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 1.0000000e+00, 1.0000000e-01, 1.0000000e-01,\n",
       "        1.0000001e-02, 1.0000001e-02, 1.0000000e-03, 1.0000000e-03],\n",
       "       [2.0000000e+00, 2.0000000e+00, 2.0000000e-01, 2.0000000e-01,\n",
       "        2.0000001e-02, 2.0000001e-02, 2.0000001e-03, 2.0000001e-03],\n",
       "       [3.0000000e+00, 3.0000000e+00, 3.0000001e-01, 3.0000001e-01,\n",
       "        3.0000001e-02, 3.0000001e-02, 3.0000000e-03, 3.0000000e-03]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position * angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'abs',\n",
       " 'accumulate_n',\n",
       " 'acos',\n",
       " 'acosh',\n",
       " 'add',\n",
       " 'add_n',\n",
       " 'angle',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'asin',\n",
       " 'asinh',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atanh',\n",
       " 'bessel_i0',\n",
       " 'bessel_i0e',\n",
       " 'bessel_i1',\n",
       " 'bessel_i1e',\n",
       " 'betainc',\n",
       " 'bincount',\n",
       " 'ceil',\n",
       " 'confusion_matrix',\n",
       " 'conj',\n",
       " 'cos',\n",
       " 'cosh',\n",
       " 'count_nonzero',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'cumulative_logsumexp',\n",
       " 'digamma',\n",
       " 'divide',\n",
       " 'divide_no_nan',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erfc',\n",
       " 'erfcinv',\n",
       " 'erfinv',\n",
       " 'exp',\n",
       " 'expm1',\n",
       " 'floor',\n",
       " 'floordiv',\n",
       " 'floormod',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'igamma',\n",
       " 'igammac',\n",
       " 'imag',\n",
       " 'in_top_k',\n",
       " 'invert_permutation',\n",
       " 'is_finite',\n",
       " 'is_inf',\n",
       " 'is_nan',\n",
       " 'is_non_decreasing',\n",
       " 'is_strictly_increasing',\n",
       " 'l2_normalize',\n",
       " 'lbeta',\n",
       " 'less',\n",
       " 'less_equal',\n",
       " 'lgamma',\n",
       " 'log',\n",
       " 'log1p',\n",
       " 'log_sigmoid',\n",
       " 'log_softmax',\n",
       " 'logical_and',\n",
       " 'logical_not',\n",
       " 'logical_or',\n",
       " 'logical_xor',\n",
       " 'maximum',\n",
       " 'minimum',\n",
       " 'mod',\n",
       " 'multiply',\n",
       " 'multiply_no_nan',\n",
       " 'ndtri',\n",
       " 'negative',\n",
       " 'nextafter',\n",
       " 'not_equal',\n",
       " 'polygamma',\n",
       " 'polyval',\n",
       " 'pow',\n",
       " 'real',\n",
       " 'reciprocal',\n",
       " 'reciprocal_no_nan',\n",
       " 'reduce_all',\n",
       " 'reduce_any',\n",
       " 'reduce_euclidean_norm',\n",
       " 'reduce_logsumexp',\n",
       " 'reduce_max',\n",
       " 'reduce_mean',\n",
       " 'reduce_min',\n",
       " 'reduce_prod',\n",
       " 'reduce_std',\n",
       " 'reduce_sum',\n",
       " 'reduce_variance',\n",
       " 'rint',\n",
       " 'round',\n",
       " 'rsqrt',\n",
       " 'scalar_mul',\n",
       " 'segment_max',\n",
       " 'segment_mean',\n",
       " 'segment_min',\n",
       " 'segment_prod',\n",
       " 'segment_sum',\n",
       " 'sigmoid',\n",
       " 'sign',\n",
       " 'sin',\n",
       " 'sinh',\n",
       " 'sobol_sample',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'special',\n",
       " 'sqrt',\n",
       " 'square',\n",
       " 'squared_difference',\n",
       " 'subtract',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'top_k',\n",
       " 'truediv',\n",
       " 'unsorted_segment_max',\n",
       " 'unsorted_segment_mean',\n",
       " 'unsorted_segment_min',\n",
       " 'unsorted_segment_prod',\n",
       " 'unsorted_segment_sqrt_n',\n",
       " 'unsorted_segment_sum',\n",
       " 'xdivy',\n",
       " 'xlog1py',\n",
       " 'xlogy',\n",
       " 'zero_fraction',\n",
       " 'zeta']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.sin((90.*3.1415926535)/180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim((0, 8))\n",
    "plt.ylim((-1, 0))\n",
    "y = angles.numpy()[0]\n",
    "y = -y\n",
    "plt.plot(i.numpy()[0], y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "#         print(\"PositionalEncoding.__init__()\")\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "#         print(\"PositionalEncoding.get_angles()\")\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles     #  (4,1)*(1,8) => (4,1)*(4,8) => (4,8)*(4,8) => (4,8)\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "#         print(\"PositionalEncoding.positional_encoding()\")\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        \n",
    "#         print(angle_rads)\n",
    "\n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "#         print(sines)\n",
    "\n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "#         print(cosines)\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "#         print(pos_encoding)   # (4,8)\n",
    "        \n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "#         print(pos_encoding.shape)  # (1,4,8) => (N,T,D)\n",
    "#         print(pos_encoding) \n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :] # (64,20,128)+(64,:20,128)=>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.  2.  3.  4.  5.  6.  7.  8.]\n",
      "  [ 9. 10. 11. 12. 13. 14. 15. 16.]\n",
      "  [17. 18. 19. 20. 21. 22. 23. 24.]\n",
      "  [25. 26. 27. 28. 29. 30. 31. 32.]]], shape=(1, 4, 8), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 1.         2.         3.         4.         6.         7.\n",
      "    8.         9.       ]\n",
      "  [ 9.841471  10.0998335 11.01      12.001     13.540302  14.995005\n",
      "   15.99995   17.       ]\n",
      "  [17.909298  18.19867   19.019999  20.002     20.583853  22.980066\n",
      "   23.9998    24.999998 ]\n",
      "  [25.14112   26.29552   27.029995  28.003     28.010008  30.955336\n",
      "   31.99955   32.999996 ]]], shape=(1, 4, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(4, 8)\n",
    "inputs = tf.constant(np.arange(1,33).reshape(1,4,8), dtype=tf.float32)\n",
    "print(inputs)\n",
    "result = sample_pos_encoding(inputs)\n",
    "print(result)\n",
    "# plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "# plt.xlabel('Depth')\n",
    "# plt.xlim((0, 512))\n",
    "# plt.ylabel('Position')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABioklEQVR4nO2deZgU1dm376eq19n3GZgBBhgQEEERcMEd97glcY9Ro8Ykb0xiYhaXJL7JZxLN4vImGkMSozHGfUPF4AbiEhFU9l3WYfZ96b37fH9UddMzzDANzAAD576uc3XVqaquqqE5Xf07z/N7RCmFRqPRaA4NjP19ARqNRqPZd+hBX6PRaA4h9KCv0Wg0hxB60NdoNJpDCD3oazQazSGEHvQ1Go3mEGJAB30R2Swiy0VkiYgstvvyRORNEVlvv+YO5DVoNBrN/kJEHhGROhFZ0ct2EZH/E5ENIrJMRKYkbbvGHifXi8g1/XVN++JJ/1Sl1JFKqan2+q3A20qpMcDb9rpGo9EcjDwKnL2L7ecAY+x2I/BnsB6OgTuBY4DpwJ399YC8P+SdC4HH7OXHgIv2wzVoNBrNgKOUWgA07WKXC4F/KouPgBwRGQKcBbyplGpSSjUDb7LrL4+UcfTHm+wCBbwhIgr4i1JqFlCslKq2t9cAxT0dKCI3Yn3zkZ7mPXrsuPFINExDEBwb1hMbM4aoUgTXrKNzaDnpXgeycQNlE0by6aYmhg8vwdywnrZIjGEVxazt9OBvbWH48BKy22qoqWolzTTIGzOUBtKprm0lEgogIniyshiWl0YGQQI1NXQ2B/BFYyjAbQhpHgfubC8OjwsjI4eI6aYzHKUjGKUjECYSihGNhIlFwqhoBKViEM98FgEEMQxEDMQ07VcHYgiGIQAYhiTWTUMwpNurAQaCCIgIAhhJyyIg8e1YzTq/1Z+0mvQ37/Zv0OvKTqt99u/xnrvYrfLTFTR4M8n3t9OcmcdhDh/ukRUsW1/NkcMyadtYySZPPuWlubStXEPZhBEs3dZORm4OZb5q6hv85KQ5MUaPYf3mGsR0MmZYPo66bdTVtWMi5BdnYA4ZztZmPz5/hGBHG6gYzrQsMjPdFGe68aoQkZZGAs2d+P1hglFFDOvDbwq4RHCbBg6vA4fXidPrRjxexOlBOVxElRBVEInFCEUV4ViMUCRGOKqIRGNEowoVU8RiCqUUKFBKoWIxUDG7L/6qAHu/OEqhkpbthV3/3Qdxpr7yNzYopQr39Hgjq0wRCaR6rpVA8s6z7HEuVUqBbUnrlXZfb/17zUAP+icopbaLSBHwpoisSd6olFL2F8JO2H+4WQBHTzpcvf/BBzja63hkoyL/gnPpfPw12kMRPj/xND769kNMH1+E57IL+fVzfyXjmqf46R9/TM755/JWXSf33fcjTlxUwcr/zOanf/wx575xN3ff+R+mZHu48pG7+IcxlV/cO4eWrasxnS4mnH4Wv79qCjNi61n/29/y3+dX82lLgKhSjE5zMeWwfCq+MJHccSPwHH8+jTkVfFLdwYLPG/nvunrqt7XRWluHr3E7wY5mIv4OVCwKgBgmhsOFw+3F4UnHmZ6N05OBMz0bT7oHt9eJYQpurxO314HH6yQnzUmGx0mG20Gmx0GG3Tymgdth4jQFpyG4HSYeh4HTELvPwGlaXxKmiP2lYH1ZmAb2F4XYfdYXRnwf2NEH1hcK7BiDjaTBWJK+LYwUvxyM7t8wvbCr3X6YNo6/HnYaX17yDk9Nv4p/533C2H++yNALfsPCe0/inUt+zFcnXM19d13OGxOP5d5//4mCWxZw4qVf4Hcf38ND/1jKl8aXkP7CHM647g94sgt5/P5ryP/T9/jzfe+Rbhpce+2JZP/0Ib71/AqWLatl4wdvEIuEKJl8KqecNoYfnVrBuMgWWl7+J2ufXciKZXWs6wjhj8aIKsh2GAz1OKnIdlN4eAGFE0spmDQa95gjMMvGEskZRmvMSWc4Rm1nmO1tAao7gmxt8FHd6qeuLUhne4iAL0TQHyEcjBCNxAgHQ0SDfqIhP7FIiGgkRCwcIhYJoWJR64HD/szFYlFU1FqO98Vfuy/vqm+wEF7yjy179QbRIM7xX0xp19CnfwskSdeDggGVd5RS2+3XOuBFLG2q1v75gv1aN5DXoNFoNLuLGGZKrR/YDgxLWi+z+3rr32sGbNAXkXQRyYwvA2cCK4DZQHwm+hrg5YG6Bo1Go9l9ZF8O+rOBq+0onmOBVlv+ngucKSK59gTumXbfXjOQ8k4x8KL9098B/Fsp9R8RWQQ8IyLXA1uASwfwGjQajWb3EOmvAR0ReRI4BSgQkUqsiBwngFLqYWAOcC6wAfABX7O3NYnI/wMW2W/1S6XUriaEU2bABn2l1EZgcg/9jcDM3XmvVXUh5o87hv+97vfMG/8ZP6rv5Plfv0DlTw/j09NHMmvOq8y7+S5+HFUs9ExAxaJcNbGA2xp9lHgcGKdcReU/HiW7bCxnVuSz+UcrCcUUoypyYcwxvDunGl/jdiKBDtIKxlJWlsXwbDehT1bSsqmZ+mCUUEzhNYU8l0lagZf0knzM/CHE0nLpCMdo9odp7LR011AwktBaY+HQTvpo8pOCYWv8psOayBUDTIeB6TAwTMPS43tqYk/yxvV36brcpdnKelwfT0VOT/UnoKSozQ8EV50yghVfuJpLoyt4Cpj13GpWHreQQGsD8y67lZP/9hOabvoP57pn8LbAuuJj8TU+xY9PH8vSn65jYpab8ZdO5defVOJrrGLE1OM5PN/JJx9spDUcY2KWm4Kph/N5W4hNlW20NTQTCXTgzswjIyedMcUZ5HlN1KbtdG5vwNfgpyMSIxRTRJU9iWsIGQ7BleHEneXGlZmGmZ6B4UlHOTwoh5uQ3/p8BSMxgpEY/lCUYMSazI1EYkSjMVRM7WhKoWLRRIslLQPWBG+KDGbtfqAQEUynq1/eSyl1RR/bFfDtXrY9AjzSLxeSxEBP5Go0Gs2go7+e9A9E9KCv0Wg0yfSjvHMgogd9jUajSUIAMQ5eW7JBcWfB9hbeqGzjsxef5L5r/srXv3gYLVtX8+YXf8KUR/6MikZpuOdmzhmWxU+eXUbR4TOIvnwf/qhiRnk2b24L0LJ1NaUTDqO0cxPrVtTjNYWy48upMXJY93kTgdYGANILhzNlRC4lHkVg8+e0VbbRFrF0zwyHQZ7LJKMoHXdRAY78EkvTD8VoCoRp7AgS8oeJhKNEQv4usdJxxDCthCzDxHC6ktYF0zQwTcPS9m3N3uWwdH2XaeB27ND4LQ3f2ic5cat7nHwcIxF7nxxTv3OM/q7oL/W+P2L0AVyPvcw7XzA5duEC7vp/1zMt18vCp55h+qWX8OLqehYUnUrB2GmsvOPnnDUih9tfXUV64TCOTWthUXOAKceVUvilr/Duom2IYXLUpBIc6z9g4xrrszCsPAfPEcexpLqdpup2Ouu2WufNyCW7II3RBenkuiBSu5XOmkZ8TZamH7UTm0wRPIaB1zQsPT/diSsrDSM9CyM9k5jTS1hBKKaIRCEQiRGIWpq+P2zp+nE9v/trVw1/5zj8OLEe4vH70vG1zr9Po3f2OfpJX6PRaJLR8o5Go9EcQohg9FP0zoGIHvQ1Go0mCUvTP3if9AeFpj9s+BB+/sfLmPLlKwkrxbBHX+SYyy/n5S2t/O/SGJO+cAGvPPAeJ/3mEla+/R5nnD2RT+6fw/hMN5OvP4E/zttALBJi5vRh+Be8yLqOEOVpLoaceiyfVLXTsL2FWCSE6fKSW5LDEUOyMJu30rxuG02Nlk4LkG4apOV5SRuSh5k/BCO3GL8yafaHaeoI0dIRIhSMEvF3EAtbfig9afpWbL4z4cNjOFw7tPy4tu+wlw3B5TATWn5c4zdlRzx+fBksHdk0drxKFy+dHT46vRqm9bChu9bf17xB4r16/RftH2Z+7ffcO/V6pt3xJtfXvsSVs39BWv5QXv3WMYzNcHPzXxZyyeUnMPvl9cy480I+fvMzRh1zHC1P/omOSIzxXz2VqryJVK1eQ1r+UC6cNISWd+fyeWeYPJfJkClDCA85nMVbmmmvqybU0YwYJt7cEgoL0ijP8WK21RCqrqS9uoOmUJSAHaMPVoy+1xQyHAZOW893ZaVjpGehXOng9BCIKEJRRSASw2fr+P5QlJD9Gk3o+iT0/FhMoaJdY/Ohdy0+rvdrUkS0pq/RaDSHEIIxSAf0VNCDvkaj0SQjB7e8owd9jUajSUIQDIeeyNVoNJpDg4M8ZHNQTORmNW/nobHX8d7XR3PLX67itF/NZ+63pnFWcTqzZr3Oo1+fztLWAJ3nfp+O2s389PQK5i+rY8YJZeRdfiNrFm8hvXAYV04p5fOX/0tTKMq4knRcR53K/PUNtFdtQAwTT3YB+SWZjM1PI7ZtDS0baqkJRPFHFS7DMltLL04jvSQPR0EJ0bRc2kIxGnwh6tqCO4pchKziFt0n0OIfpJ4mhAyHNXmbPKHrchg4ejFci5utxSdxTQEzXnUryWwtce49MFvry0xtf5qtAWQUjwRg/bwXeeArD/FAZAo/uOUSqm7+Clf8/GzWz3uZe84axTZ/GC7+CY0bPuVb549n6d/eZ5jXiev0q3lpbT1tlesoGHMkJwzPZts7y6kPRhjmdVJyzAS2B02Wbm7C31xDqLMVhzeDjIICxg/JYkiGC7OthvattXTWdtIajuGP7jA7syZyDdyZLjxZblyZ6Tgz0jHSMlEuLzGnl1DUmsj1haMEo7FEUlYoEiUSiRGLKmKRGNHIjkncWFKAQE9ma8lGbLtCJ2H1hp7I1Wg0mkMHATEH54CeCnrQ12g0miSEg1ve0YO+RqPRJKM1/f1PTW0Hd93+AK9OPo+XJt7A6rnPsfKyi/jCsz+jZfMKhi94mGm5Hm55ZTXZw8dTuvo1qgIRDv/mhayQUhrWLaLk8KOZ4PWxccFWXIYwfEYZLTmjWby2Hn9zLQ5vBumFwzl6ZB5lmU5CG1fSsqWV5nA3s7XidNJK8iGzIGG21uAL09QZJBgIEw5GupitJeum3fVA0+HCcLqsgilimawlG68lJ2N10faTzNYgWcvf2czMoGcjtb7M1rrr9X2p932ZtSWft79YOetKfvDxLE79+vV0RmP8+lePc+uQKh55dAmB636FN7eYhntu5tg8L7+etwmHN4OrJhbw/sZmjj8sjyX+TJ58dxOxSIhRhxeR17iGbQuriCoYVZRG+pHHsaKuk4bt7QTbm1GxKK60LDLzvIwpziDfaxKu/JyO7fVdCqiAped74gVU0q0CKu6cDCQ9C0nPQjncRDAIRWMJPT+emOUPR/GFokSjlpYfs4unxGJdi6d01+R3pdFrs7Xdw3Q4UmqDkcF51RqNRjNAxB++DlYGxZO+RqPR7Esk/su7j5bie50tImtFZIOI3NrD9vtEZInd1olIS9K2aNK22f1xb/pJX6PRaLph9NOTvoiYwIPAGUAlsEhEZiulVsX3UUp9P2n/7wBHJb2FXyl1ZL9cjM2geNIvzvdSevRM5tX7uPmnjzF25pd45LX1PJ1+AqNPuYg5Nz3GuT+ayZsvfsDkM45j2W/+yjCvE868kT/M20C4s5VjppURff85lrYGGepxMOz0qXxW00nt1harIHr+UHKGFDNleA6e1kqaV2+hpbqji9ladp6H9JIcHIWlRNPzCTm8NPrCNHQEaewIEfJHCAd8RIP+HjVXwC6YYuwooGKYmKZhx+lbTQwScfqmYWBKktGaITsXPpcdRVW6m611ObcMnNnaTu+V2m69H5/CG7xbMY2Zc4XXT4cfPngFkUAn/znru7gM4bKHF3L8xefyygPvceb3T+Gpl1cxfNqpRF++j5pAhCO+dgJ//WgLmz5bize3hCuPGY7vvdksbw2S4TAonTaE2Mij+HhLM621DUQCHQCW2VpxBqNz03B31hOu3kxHdTutgQid0ViiILop4DUNMhx2AZUsr2W2lpED7nSUK41gVCUKovvCUXzhqKXp24ZrcbO1WFQRU0kF0ZMKpsTXtdlaPyIkcmX6aikwHdiglNqolAoBTwEX7mL/K4An++EuemVQDPoajUazr7Cslftt0C8FtiWtV9p9O59XZAQwEngnqdsjIotF5CMRuWjP7qgrWt7RaDSaZMSKoEuRAhFZnLQ+Syk1aw/PfDnwnFIq+efZCKXUdhEZBbwjIsuVUp/v4fsDetDXaDSandiN6J0GpdTUXWzfDgxLWi+z+3ricuDbyR1Kqe3260YRmY+l9+/VoK/lHY1Go0lCxJrITaWlwCJgjIiMFBEX1sC+UxSOiIwDcoH/JvXliojbXi4AZgCruh+7uwyKQd9fPILl957LT35+JmFfG2/97FQmZ3u47Q9zmfWdGbxV10n2zX+gaeNSHvjyJN56dyunTCnhyRV1fPj+Fry5JVx/7Ag2v/iWNYmX5yXtuHN5e109LdvWAZA1ZBQFpZkcUZSJqlxN07oqtvsj+KOxHWZrRelklBZiFpYSS8ulNRBNmK35OkME/WGralYkRDQc6jExy7QrZSVXzZK4gZppYJiC6TASZmsue7l71SzT/rwl1nsxW+teNasvBsUHwuajJj8f/vMx/nbM9bw+9VtccdNVvFLZxnU3Hc+Sl1/g8a8cydLWAPnf+w3Vn73FdRdN4JP751DicZDz5Rt4779bad68gryKKZw+Ko/Nr39MrW22NuS4CdSQxX/XN9BZvxUAhyeD9IISxg3JYli2G7O1ivattYmqWXGzNVMkMYnrTXfZiVmZODPTMNItszXVzWzNF96RlBWKWBO5sahKMlmLm65Fuxiq7anZWk/oxKwdWMEUfbe+UEpFgJuAucBq4Bml1EoR+aWIXJC06+XAU0opldQ3HlgsIkuBecDdyVE/e4qWdzQajaYb/ekgq5SaA8zp1vfzbuv/28NxHwJH9NuF2OhBX6PRaJIQsX5tH6zoQV+j0Wi6oW0Y9jObt9Qwf9wxfHLJL/jhHddR/81LuPrJH1C36gOmrnqKydkebn5lDVllYxm79R02+8Ic9f0LmfWfddSseJ+Sw6dzTF6U9f/ZiCkw8tQRtBVN4L0VtfgaqnCmZ5M3JJMpo/IZnu0ktGEZTeubaAhFiSrwmkKh2yRzaAbppYVITjHtEaEtFKPRF6K+PUDAt8NsLRoKdNFaeyq+kGy2Ftfyk7X9XZmtxSeR4gVUoHezNUjS9ROve2+2lrzP/jBbA/jf+b/luKuuZrMvzE0/fZyHp0a4cEQ23p89jCs9m9CffsSUHA/3fFSL4XDx7ellzF9Wx0lj8lglQ6lZ+QnRkJ/Rk0ooaV3Plne3EYopDitMI+uYE1lW20ldZRuB1gYMhwt3Zi45RelMLM2iKM1hma0lFVCJm615zR1ma+4sF95cD66sNIzMXIz0LJTTS1gcBCIxAmHbcK2b2VokHLWSsyIxYgnTta6JWcn0pMd33zd5H63f7wKh1wTI7m0wop/0NRqNJol4ctbBih70NRqNpgsHt8umHvQ1Go0mGek/w7UDkUGh6TvTMnmjso1rfzCLn8iHPPz0Kp4uPIcxp36R165/iC/dfgazn36Xo885kaW/+KNltnbuTWxYuJhwZysnzBhBdMFTfNoSYJjXyYhzjmFxdSfVm5oSZmtjRuYyvTwXb2sljcs+p7Fqh9lalsPcyWytNRil0Remtj1IXVuw38zWDLswetxszWUaO5mtOQ0jyWSNXZqtxT+7icLovfyNB5vZGsAZH+bzzjlw68NfIdjawJwTvsaZcx7goj/+l5MuP5/n736L8388k0eeXsLI484g9sJvqQpEmHzjyTywYCOd9dvw5pbw1eNG0DnvBZa2BMhwGJQdOxRVMZ0PNjbSvL2GSKADV3p2wmxtTF66Zba2/XPaKltp8oe7mK3FC6JnO82E2Zo7J9MyW/NmdTFbi+v5KZutdW+7MFvT7BkCGKak1AYj+klfo9FoktFP+nuHiJgi8pmIvGqvjxSRhXZBgaft1GSNRqM5YOhHl80Djn0h73wPK/04zj3AfUqpCqAZuH4fXINGo9GkSGpVs/oza3dfMqCDvoiUAV8A/mavC3Aa8Jy9y2PARQN5DRqNRrM79LPh2gHHQD/p3w/8GIjZ6/lAi21CBLsuKHCjXTxgcbE7wJ0PXYGKRXn4S3dzUkEaP/n1Czz1o5N4q64Tx7fuoWnjUh68ZBJz5m3h9BllPLKkmrbKdaQXDuN/Zoxkw5P/oSYQ4ciSDDzHn8+cVbW0bF2DGCbZpaM5fkwBR5ZkEtu8bCeztUK3ZbaWObwYR8lwYun5tAai1HUGqW4JEOgM75XZmuno3WwtPoHb3WwtbrJmiOzSbM1KwrLX+/jHSv4w7OrzfKA84fz3X//k3uk38s9xX+N7t13Pq9Xt3F09lCUvP8czVx/FirYg2Tf/gerP3uKmS4/g43teZZjXSdYl/8P7H2zBdHkpHDeVcyry2PjqQqoCYcrTnJSdPJnt0XQ+SjJb8+QWk1k0hIml2ZRluTCbt9G2qdo2W4slzNZchpBum6250px4cz24czJxZWd2MVsLRBTBSM9ma8FQ1JrATUrO6k+ztR4TufRkcBe0vLMHiMh5QJ1S6pM9OV4pNUspNVUpNbUgP7+fr06j0Wh6RoSEu21fbTAykNE7M4ALRORcwANkAQ8AOSLisJ/2d1VQQKPRaPY5wo5fzwcjA/ZVpZS6TSlVppQqx/KKfkcp9RUsX+iL7d2uAV4eqGvQaDSa3caWTlNpg5H98fvkJ8APRGQDlsb/974OaFixlgdHX8tffv8NqgJhLp7/EC1bV1P20m84tTCNrz6xhPyKKZQt+hdVgQhH3vY1/vbKahyeDMqOnM4kVzOr3t6MyxBGnzma+pwKPlxeg6+xCld6NoVl2Uwdms2IbBeBNUtpWNNEQyhCVEGGw6DQbZJVlkn60CLILqIlFKOuM0iDL2ybrdkFVGyztVgktFtmayKC4TAsE7VuhVO6m605TWu/RHKWIb2arSV/JvvTbK3LefrZbG13pguuv+N7ANz2kwf5mfdTvnJsKff+4VkySsrZ/sOrOb0onZtfWYM7M4/rx6Xx1tpGTplSwocdmVQv/y+55ROZPLWUgtolbHi/kqiCcWVZZB4/k0VV7dRsaSHQ2oDp8pJeOJzc4gyOKM2mJMNJeOs62jZX01HVQWs4mjBbcxlChsMg22ngyfXgyfXgzsnAyMzByMxFudIJiYNQNJbQ8zvjiVm2rh+N2lp+bEcRleRErO7Jf7trtqbZNcLBPejvk+QspdR8YL69vBGYvi/Oq9FoNLuLCDgG6YCeCjojV6PRaJIQkUE7SZsKetDXaDSaJCx55+Ad9A/eO9NoNJo9pD81fRE5W0TW2tYzt/aw/VoRqReRJXa7IWnbNSKy3m7X9Me9DYpBP6rgrtsf4MTXfsUtvz6fm1blMu3Sy/jHj1/ggllf58Pn5nDplSfz4a3/YHK2h/ojv8Tmjz+k6PAZfGnmaHyv/p1PWwKMzXAx7PyZLNjSSvXGOqIhPxnF5RxRkc/oXA+u2rU0LNtAXV1nwmEz12mSXZRO1vAizOLhRDOLaQ1GqesMUdXip6EtSNAfIeLvIOLvIBoJ7TRpJoaJ6XRhOJwYTlciMSvZYdMwBCPJUdPlMBMOm/E+Z7cJXMthkx4dNhMum0ifk6OpTJ7uK4fN3eHu1mf5wcezSC8cxsMX/JJjXn8RX2MV377pIv71908590/XMPvpdxl/2uk0/vkXNIWiHPX9C7nnzXUEWusZNWUcNxxfTsPsZ1jaGiDPZTLipBFERk5n3rp6Wqu2Ew35caVnk1OYTunQTMYVpONs3kZgy+e0VbbREIx0cdj02olZWU7TTszKwJ2biZGZC55MYu4MKzErGk/MsipmdQQiCZfNZIdN6zW2k7smsJPDZirVtDR9I/0YvSMiJvAgcA4wAbhCRCb0sOvTSqkj7RZ3MMgD7gSOwZoHvVNEcvf2/gbFoK/RaDT7inicfj896U8HNiilNiqlQsBTwIUpXspZwJtKqSalVDPwJnD2Ht1UEnrQ12g0mm6Y8RoVfTSgIG4XY7cbu71VKbAtab0365kvi8gyEXlORIbt5rG7hZ7I1Wg0miTiNgwp0qCUmrqXp3wFeFIpFRSRb2AZUZ62l+/ZK4PiSb/k8FGUHj2T3/5sDp+cdzv/vP9R3vz2dDb7wiw96hr8zbXcc9Yo5qxu4IyrJvGrdz7H11jFMSeM5PppZaz85wJawzEmjcvHmH4+Ly3ZTuvWVRgOFzllwzmxooAcfy2R9Z9Sv6LaNltTeE3LbC1jaAaZw4txDi0n6Mqk0Remui1AdWsAX0eIQGeISMAyW4v1ZLZmmjuZrpkOh63n72y25k4yWksYrtlJWXGztR2Vs6SL0ZohssNgLenXp7DrBKk9MVvb36HMt3/9X8ycK7xy39VUBcKc9egajrn8Uu4cYyVMbT7xmzRtXMrvr5rCgvvmMSXHA+fexLL3VuPJLuSrp4zi1OEZrH/pU+qDUcZnuig9/VjWtcVYsq6BjtrNAKTlD6WoNIspI3Ipy3JBzee0bthO27Z2mkJR/NEdiVnpppWY5c522YlZmThzcjAyclDudJTTSzASIxCJ0RGykrM6AhF8oSj+UIRIJEYknGyylpSc1YfZGmBti/au5Wuztb6Jx+mn0lJgOzAsaX0n6xmlVKNSKmiv/g04OtVj94RBMehrNBrNvqKfNf1FwBi7eJQLy5JmdpfziQxJWr2AHfVH5gJnikiuPYF7pt23V2h5R6PRaLrRXxYLSqmIiNyENVibwCNKqZUi8ktgsVJqNvBdEbkAiABNwLX2sU0i8v+wvjgAfqmUatrba9KDvkaj0SQRD9nsL5RSc4A53fp+nrR8G3BbL8c+AjzSbxfDIJF3VtWHWX7vuRyb5+Wa257Am1vMyssu4iunlXP9Ax8w5tQLabjnZqJKMfInP2POnJWkFw7jxzPHMnTbhyz6rJY8l8mYi45iQySL5Svq8DfX4s0tZujIXKaVZqE2fkrrkiU0rbfM1gCynSaFaU6yh+fgGTaMaFYJzYEo1e1BKpv8VLf4CXSGCPn9hAMdREOBXRRPSYrRd7owTMtsLTlWf0fxFCtG350Uo5/Q7xPLOz6YyTH6ceKfWZGu2nt3s7Uuun8vZmt7+/kfCLM1gCuPH8aH/3yMnN98nR/c9QX++8S/+c83pzP/ov/hitNH8rVZC8mvmMLxviUsaPBx8iUTeGRJNQ3rFlE04Ri+OK4A+fAZlq2ox2UIFZOKcE8/i3c3N1G3tYVgexMOTwZZJWVMGZHLEUOyyDOChLespnVzLS0NPtoisYTZWjxGPy3LjSfHgyfHiyc/CyMzFyMrj5g7nUBUEYgq2oO22VrI1vNts7VIOGrp+dEdTcWiibmihJ4fTd1ITWv2u4c2XNNoNJpDCO29o9FoNIcYg/UpPhX0oK/RaDRJ9Lemf6ChB32NRqNJIq7pH6wMCuEq0NbC/HHH8OUlL9JRs5k//O9XeOS19Uz592NseHc293/jGF554D3OHZPH6x1F1C5fwKhjjuNItrHlkUdY1xFkWq6HogsvYfbqWmrXr0XFomSVHcZphxdTnmniW/4JdZ9tYFtrkI5IDJchFLisillZI4fgHFJOLLOIlkCU6o4g1a1+2tqDBHxhy2gt6CfaQ2KW4XQlJnTjRmtWcpZttObYMaGbbK7WfblLQlbCeG3nSdLuZmtx4hWzeqKnD8GefOT39X+TnGdf47irrub+vyxm+Rd/Tt6oyay/7ss8s7yOKY/8meWvv8KlV57MZz/+NRkOgzE//jF/e2U1KhblhBPKydv8AZufeYV1HUGGeZ2MOnsSjVmjmLu8hpata1CxKN7cYgpKs5hcls1hBWk4GjfTvmEzLZtbqQ9GE8Z8yYlZ3lyP1fKzcedmYmbnE3Ono1zWRG4wohJVszoCETqCEToCYdtsTdmVsxSxeHKWbeK3k+Fa0mt8kjdOqpO3epK3Bw7ycon6SV+j0WiSEATnQeynrwd9jUajSUKwrE4OVvSgr9FoNMkIGINUukmFQfEbpmxYCW9UtnHyP7dz3Q9v4JKNTzI528N1c+vIKhvLSXXzWNoa4IR7ruEXzyxFDJNvnT+e2sceYtnTyzFFGHfOaFqGTeeVhdvoqNmMMz2bkvJCTijPw1W1nNrFa6hf1UBVIEJUQYbDoMTjIKc8m6zyIUhBGa0Rg+r2INub/DTaZmshf7hLYlZcI03o+IZpJWY5XFaSltPW8+Mma6ZluuZwxJOxzESS1g4930rKcpqS0PatIipWQlZ3s7XkpCtDumrtyYlZycQTs/bUbK23w1JNzNoTTvza/bxzDlxQkcdVt/6bB392EY88u5pj87z879IYYprcc9YoXp23hbMPL+QT12Fs/vhDcssn8p0TR1H11JOsfWUd/qhi0tAM8meezUfb29m0rhF/cy2Gw0VGyUjGDM/h8KIMSjOcRDatoHndNtoq42ZrlqbvNYUMh0G2x4En10NaQRqe/CzM7HyM7HyUK52w4cIfjllafiiS0PT9doJWJGy1aMQyXIvFFNFIJFEspXvBFKvFuvxNuput7arIiqZnrCf9lK2VBx36SV+j0Wi6MZAPK/sbPehrNBpNElrT12g0mkMIEcFhDgrle48YFHeW01rNnQ9dwaKn/8X95dv4v2v/ytVP/oDZj7zA1244l3dvuIcpOR7qZlzHunfnUzL5VK6aWMCyf3zEB41+xme6GXnZeby5sZlta7YTCXSQNWQ0UyYUMbEojcDS96ldWkO1rdOaYhVEzytOJ7u8GGdZBdHsITQHo2xvD1DZ7MPfHsLfHiLU2Z4oiB6LhLpcd5fY/F4KopsOI1EQPdF6KIjuNAwMEZxmPGa/ayGVvgqix43WulxfPxZE31v25Ne0J7uQe6ffyCmfzqOt6nPOWPpXhnqcXPaPb/GXh19l0rnn0XDPzdQEIhz7i69w2+yV+BqrGHPsJCY76ln1zBIWNfspdJuMPrOCyPhTeHVFDY1bNhMJdODJLqCgNI9jRuUxLNOJp2Ur/g1raNnUTL0vTFsk2qUgejxGPy3fiyc/E09+NmZ2vlUQ3ZOF3y6I3hqM0BHaUTzFl2JB9GSztVQKomsNf8+JFyvqqw1G9JO+RqPRJNFXlbnBjh70NRqNJhntvaPRaDSHDvpJX6PRaA4xBqtenwqDYiK3uqadB0dfy6QLLuOR02+hLRLj2aJziYT8/Gqah5fWNnL+j2dy0/PL8TfXcME5hxF9+T4WVLbREYkxZdoQZMal/PO/W2jZvALT5aVo9CjOHFdEdusm6j5eTvWmFjZ1hgnFFF7ToMRjkjsqh+yKUhxDR+FzZFDTHqKy2U91i5WYFfCFCPtaiYYCicpGccQwMZ0uxDDshKy40ZoDw2HgcBo4nCYO546qWaZh7FQxy2UaGIYkJo66T96a3RKzYOfErOSnlu7VsZI/AIlqWz38G+xJYtZAs/xv1wAw/a4PuOr71/GnGx/n6/dezPyxl9G6dTX/vGE6rzzwHqcXpdNy0vWsmPcJ6YXDuPnsw2h/6e98XNVOfTDKlBwPZeedzpL6IJ+urKWjdjNimGQUj2TYiByOGpJFemctattqmtdto2WLZbbmj+6omJXlMMhzmXgLvHgLrElcZ24uZm4hMU8mMVca/kiMzlCM9mCki9maPxQlFIoSCceIxCd07eSsWDjU1XAtmmy4Fkssx5KqafVET5O6eqK3Z8QOmEilpfh+Z4vIWhHZICK39rD9ByKySkSWicjbIjIiaVtURJbYbXb3Y/cE/aSv0Wg0SVgPSv30XiIm8CBwBlAJLBKR2UqpVUm7fQZMVUr5RORbwG+By+xtfqXUkf1zNRaD4klfo9Fo9iX9aMMwHdiglNqolAoBTwEXJu+glJqnlPLZqx8BZf16M93Qg75Go9EkEZdEU2lAgYgsTmo3dnu7UmBb0nql3dcb1wOvJ6177Pf9SEQu6ofbGxyDflGuh7tuf4APv3cEq9uDfOd/z+ZHv3qeE668mKXX3chQj5Psm//Af195l4Kx07jttFF8cv8cmkJRytOcTLxuJu/VhFm3rIZAaz0ZJeWMG1fAtKGZRFZ8QPWizWzqDNMctjTOXKdJSWEa2SML8IwYTSR7KA3+KNvbAmxp9NHZFiTQGSLk6yTs70hornHiSVnxVzMpQcvS8c0uiVlel5nQ8d3diqcYYiVmOUzD1vJJKqISL6rSVceHnZOdumv3XRO3en5i2dufuKlGQOxpoMRHE47lBx/PYvXc53josDqaw1HWn/0jvvX7+Yw+5SKGvv0AS1sDnHLH2fz0P+to2riUUcccx3kjPCx/dAFVgYhVXGVmOcb083h5RQ01GyoJtjfhzswjt7SEGWMKGJXjRipXEdywjKa1NTQ2B2gORwnFlJ2YJWQ7DdLyvKQVpOEtzCWtKBcjpwjSc1GeTHzhGP5IjI5QBH84SkcwQrtttuYPRBJma/HELKW6Fk+JxboWUelNj9c6fT8gWPNlKTSgQSk1NanN2uPTilwFTAV+l9Q9Qik1FbgSuF9ERu/NrcEADvoi4hGRj0VkqYisFJFf2P0jRWShPanxtIi4BuoaNBqNZneJF1FJpaXAdmBY0nqZ3df1nCKnA3cAFyilgvF+pdR2+3UjMB84as/vzGIgn/SDwGlKqcnAkcDZInIscA9wn1KqAmjG+jmj0Wg0BwS7Ke/0xSJgjP2w6wIuB7pE4YjIUcBfsAb8uqT+XBFx28sFwAwgeQJ4jxiwQV9ZdNirTrsp4DTgObv/MeCigboGjUaj2W12T97ZJUqpCHATMBdYDTyjlFopIr8UkQvs3X4HZADPdgvNHA8sFpGlwDzg7m5RP3vEgIZs2uFKnwAVWGFLnwMt9h8CdjGpYU+I3AhQOKSM0qNn8ubks/n+j05h0xW/pOWFO5h9zXXc+t2NfPub07jltbW0Va7j4u9/i5z/PsH8ZXUM8zo5fmIhzjOu5ZE5m2lY9ymGw0XR6HFcOHkoxaFaav+7iJpVDTSErCLXXlMo9TrIHZlD7tjhOIePpTMtn7o6H1tb/FQ2+fC1BQl2dhDubCUa8hMJ+ruYrYlhIqZVPMV0ey1d3+XF4XLbRmuyo4hKwmjNxGUaiYLLceO1eOEUU8BpxjX+HTH6iSIqtsGaZaxmx+vTtSD67sToG71o/gdKjD7AgtoOfjdXmHHNtfzrtG/w7VtO5rS751H1yVzefv53vHrsrUzJ8ZD29V8x94Yn8GQXcuN544m89hAfrqgnw2EwOdvNqC+dytpgOvOXrqZt+zoAMorLGVqew9Gl2eSEmwmu+4ymFZto3thCTSDSpSB6lsMkz2WSVuAlvSgTb342rvw8zOx8lCeTmDsTvz+KPxyjNRihPRSl1RdO6PqWnm8VTokXUIlGYjtp+D3F6Cf0/t0snqK1/97p74xcpdQcYE63vp8nLZ/ey3EfAkf024XYDOhErlIqaseYlmGFLo3bjWNnxSdHsvPyBuoSNRqNZifiD1B9tcHIPknOUkq1iMg84DggR0Qc9tN+j5MaGo1Gsz8x9utv2IFlIKN3CkUkx172YmWkrcbSpi62d7sGeHmgrkGj0Wh2F6H/NP0DkYF80h8CPGbr+gbWBMarIrIKeEpE7sJKP/77AF6DRqPR7B6DWLpJhYGM3lmmlDpKKTVJKTVRKfVLu3+jUmq6UqpCKXVJckxqb2zcXMPye89lzvY2ar91L5fe8RLTLr2MdTdcRrbTZNhvZvHik/PJKZ/Ib74wnk9/8y+qAhFOPKKQyTeexsI2L58s2o6vsYqMknLGTChkxvAcYisWULXwczZ0hBMTcwUuB0PyveSOKcQ7egzR3GE0+CJsbQ2wsb6TtpYAvvYg4c5WwoEOoqFAj4lZOwzWrElcw+nCMI1EcpbDZb0mJ2R1b3FjNcOQXhOzkidqkxOzekusSjUxa28Z6MQsgF++8f/48J+P8dZFWSxtDeC7+QG2/vdVhh93HlNXPcW8eh/n3XIqP31jA3WrPmDksSdzzREFLHlwLpt9YSZnuzni5OE4T7yYF1fUsH1dFYHWetyZeeQNG8ZJhxUyviANY/sqGpd9TuPq7dTVdXZJzMpwWBWzMnI9pBV48Rbm4i4qwMwtwsguIObNxhdRdEZitNoGa22BMO2BCB2BMMHQjkncSNiqnBWNxohFQgmztVi3hCw9CTuwCFZgRCptMJLSoC8iXxKR9SLSKiJtItIuIm0DfXEajUazP9ATuZbr2/lKqdUDeTEajUZzIHAQF85KedCv1QO+RqM5FBBI1UFzUJLqoL9YRJ4GXsKyVwBAKfXCQFxUdxzeDOaPO4Yf/ehkTrjtBerXfMSGv17OT7PX8I0bpnDz3C00bVzKF7/3TYo/eZrHPq5imNfJkd88He95N/Dn1zdSu3oxhsNFYcUEvjyljKGRemrf+5CapXXUBq1csURi1qgc8saV4yofR2d6IdV1PjY3+djS0JlIzArtRmKW4XThcLlxuMydErO8LjORmNVF27cTs5yG3XpJzIonY+0qMcvA0u6Tn14Ge2IWwNlLhnHcVVfz+NFX8L1bTuKMX77N8OPO4++3nMTs405iSo6HnFvu49kbn8Kdmcf/fPFwYq/8H+99VoPXFCadVs6Yy2ayJprL64sW07J5BWAlZpWU53DciFzyI80EV31M4+rtNK5vpiYQoTXcNTGr0G2SXpROxpBs0opyMXOLMHOLiHmzibkz8e0iMSsUjNh6fjSlxCyr9ZyY1ZPmrxOz9oyDeMxPedDPAnzAmUl9Ctgng75Go9HsSwZpNGZKpDToK6W+NtAXotFoNAcC1q/mg/dRP9XonTIReVFE6uz2vIgMaHUXjUaj2V8YklobjKT6K+YfWHagQ+32it23T5hYlskblW1suOH3NKxbxAnXXM3Kyy4iy2Ew7N7Hee7xN8ivmMK9Fx7OojsfoSoQ4ZQpJXgu+h/ea/Xy8Ufb8DVWkTl0NJMml3BqeQ7Rz95k23vrWNseoiMSI8NhJGL0C8aXkDbmMCJ5I6j3Rdjc7N8pRj8a8qcco+9wuXfE5/dzjH5cw08lRj++fcfy4I3RB/jgsUd55xxY0Rak5bsPsOXDV3jy1lOZtvivzKv38cWfn8Mtr62ldsUCKk6cybUTsll87yts9oWZlutl7JVn4jj1Sp5eUkXl6m0EWuvxZBdSMHIkpx9ezITCNIxtK6hfsp6GtY3U1XXSEOoao5/nsmL004vTd8To55cgOZam35lCjH7ccC21GP1Yyn8frd3vOQdzyGaqg36hUuofSqmI3R4FCgfwujQajWa/EI/e6acauQccqQ76jSJylYiYdrsKaBzIC9NoNJr9QorSzsEu71wHXArUANVYhml6clej0RyUSIptMJJq9M4W4II+d9RoNJpBjpXjsr+vYuDY5aAvIj9WSv1WRP6IFZffBaXUdwfsypJoWr6WOx/6PhU/+DsXfvs6/nVOITffvJ7b7zyLy59YSuvW1dz405vJfetB3vishtHpLo763vm8USM89O566lYtxHR5KTlsApceXUaJfxuV8z5g+8oGqgJhAApcJqVeBwWH5ZM/cRTOkYfT5sljW62PDQ2dbKzroKMlQKCtlVBnK+FAZ2KyLfH3MkxMpyuRmGW6vJhuLw6nieEwcDjjhmtGl8Qsr9MkzWXuUWKW9e+0IzHLkN4TsxLGbEl/28GamAVw5Y9u4t7pl3PbfV/myFtfYvxZFzPmP7/jXz95gVML04hedxcvXvc30vKHcttlk/H9627mL6sj22lw1HkVmKd+laWtJnM/XkHLlhWIYZI5ZDTlFXmcNDKP/EAd/uUf0bC8kpp6HzWBaMKYz2sa5DpNCt0OMoZkkDEkm4yyQsz8IUiWZbQW9WTR6YvQEbQSs1qDEVp9YVr94URiVmISNxIjErITtOzPVU+JWUDKiVk9oSd3U+NQDtmMWy8sxip72L1pNBrNQUX8Sb+/NH0ROVtE1orIBhG5tYftbhF52t6+UETKk7bdZvevFZGz+uP+dvmkr5R6xV70KaWe7Xahl/THBWg0Gs2BRf9F5tj1RB7EKiJVCSwSkdndCpxfDzQrpSpE5HLgHuAyEZkAXA4cjhUq/5aIjFVK7dXPtVQncm9LsU+j0WgGNynG6Kf4vTAd2GDXEQkBTwEXdtvnQuAxe/k5YKZY+tKFwFNKqaBSahOwwX6/vWKXg76InGPr+aUi8n9J7VEgsrcnT5VQTPHg6GsJd7bx5Ikw/5SLmZztIXLTH5j379mUTjuX3587hgW3Pkl9MMrpp5cj53+XP8xdy4qPPifQWk/O8PGcML2MU8pzCH30Glvnr2dVWxB/VJHtNBiZ7qR0aCaFE8vwjp1IJL+cWl+Ez5t9rK9tp73Jj78jSNjXSqQXPd+IJ2W5vDhcltmaw+VMJGWZDkvLN0xLz09zmXhdZiJBy+uyjNcsLd/AYRo4TQNTwGn2nJgVT8aKL+/4t9uh5/dEX5rlnmqa+yoxC+BP6lUAXj72O9Sv+Yi5t53MX3/wHJ+2BLjgb9/kqsc/o2njUo44ayZfKuxk4e/nWsV1CtIZdc1lvF+v+OtHW6hcsY5gexPe3GJKKoZz7qQhTCjwojYsou6TNTSsbWK7P0JDKNItMcskozCNzCEZpJXk4yoswlFQQiwtl1haLh2hGL5wjOZAmGa/peW3+MK0B8L4AxErMSsUtVo4SsxOzOqi2cd6NlpLJlWjNU1qiFIpN6BARBYntRu7vV0psC1pvdLu63Efu3Z4K5Cf4rG7TV/RO1VYev4FdNXw24Hv7+3JNRqN5oBEpZz53KCUmjqQl9Lf9KXpLwWWisgT9jeQRqPRHPRI6oN+X2wHhiWtl9l9Pe1TKSIOIBsr+TWVY3ebvuSdZ+zFz0RkWVJbLiLL9vbkGo1Gc+ChIBZNrfXNImCMiIwUERfWxOzsbvvMBq6xly8G3lFKKbv/cju6ZyQwBvh4b++uL3nne/breXt7or1hyOEjuev2B3j4oVt59rizmFfv4/7Xb2fG/e8T6mzlf79xDI2/vZk5m1uYke9l4m3/w9+W1LD2vytp3rwCd2YeIyaP48opZeRWf8a6199n/fomGkJRTIGhHifFw7MpOCyPgiPHYpYfTqOks7Gpg/W1HWyr77Ri9FubCXW2Egn5E9orJBmtJcXoGw5XIkbf4TIxTEnE6Ltc8bh8S8NPNlqLx+U7TctkzRCxdf2dY/Tjen5yYfR4jH4y8X3i3/BxvX5XMfrdj0+mNzl+X+r5ALdf/Q/uW/4P8m56mLO/cS3NN19BVSDMldOH8tmkr7Do/j+QXzGFP155FNv+8B3e2trKMK+TyddNJzDtS/zl2eWsWFZLy9bVGA4XOeVHcOThxZw0Io/M5s9p/mQhtUuq2NrkpyEUxR+1nv4yHHaMfpqTjKEZpA/JI6O0ELOwFLKLiKXlEjbddPgitAQitAbCtIciNHWEaPWH6AhECAejhIORHUZrkRjRSKTXGH2gi56fHKOfKlrnTxGldkfe6eOtVEREbgLmAibwiFJqpYj8ElislJoN/B14XEQ2AE1YXwzY+z0DrMKaQ/323kbuQN/yTrW92AD4lVIxERkLjANe39uTazQazYFIP8o7KKXmAHO69f08aTkA9BgCr5T6FfCrfrsYUg/ZXAB4RKQUeAP4KvBof16IRqPRHDCoWGptEJLqoC9KKR/wJeAhpdQlWAkDGo1Gc5ChDupBP9UauSIixwFfwcoeA0uf0mg0moMLxaAd0FMh1Sf9m7EycF+0JxdGAfMG7Kq6sboxSunRM/nCB/ezoMHHV44t5dmic1kx53kmn/9FvppTzez73sVrCqd883i2jJrJX2avomnjUqIhPwXjjuXLJ5YzvdCk6T8vsHneFj7vDBOKKfJcJqMzXJQcWUzh5FG4xh5FOH8UVR1h1jV2srq6jfYmP51tPoIdTUQCnUSD/p0rZjldmC6PNXnr8uLwZuB0uxKTt/FqWQ6naRutGQmjtfi60zAS5mrxCVynIbbPh9jbdyRm7ZigtRKzejNa64lUjdZSZV9P4gJ86agSZs4VnOlZPD/TxZ//uZzrLhnPjOf+wtf/70OC7U18+fKTmLD1bd55ZBH+aIxTppQw9Ppv8+zKOj75uJLqVZ8RDfnJKCmnbEwR5x5eTEWmIrR0ATUL11C7tpGqQAR/NEZUgcsQshwmJR6TzKEZZJVlkTm8CGfRUByFpUS9uQQMN+2hGB3hGM1+KzGrqSNEi52cFfCH7UncaJcWi+yYxI3a1bOSE7PixHpIwuorMUtP4u4OColGUmqDkVStld8F3hWRDBHJUEptBPaJw6ZGo9Hscw71J30ROUJEPgNWAqtE5BMR0Zq+RqM5+FAq9TYISVXT/wvwA6XUPAAROQX4K3D8wFyWRqPR7EcO4if9VAf99PiAD6CUmi8i6QN0TTvhb21m+b3n8rPMH/LdG6ZQ/vu/ccnXHid7+Hie/taxLLzkCyxtDXDl9KGUfO9Orpu7ls0ffwhAVtlYJk8v49KJJbDwWTbO+YzltZ00haJ4TWF0uouiSYUUHz0O7+gxqLIJVPtirGnoZOX2NmrrOmlr8hNsrSfc2UrY39Gj0Zppm605XF7bcM1t6fguI5Gg5XSbuBNGa44uSVlep5konGIYOwqomEY3Ld8uyCzd9PxdeXv3lJjV+747J3Z12Z7yv9rAM2TOXD4862b+8+w9vHjsKYzPdFPxjxf40dwNrJ/3Ioed8WV+f+4YFp3xbRY1B5iR7+Wo753PGk8Ff39rEfVrFuNvrsGdmUfJYRM5Z2opxw/Lxvz8A2o/WEzNkjo2dYZpCkWJKjAFsp0GhW6TvHwvWWWZZA4rJq10CI7i4cTS84ml59Puj9IZidHkCyc0/caOEK2+EL5AhFDQ1vFDMWIRKzErZmv4sUiIaHJyVjejtbie31tiltbu+4f+jNM/0Eh10N8oIj8DHrfXrwI2DswlaTQazf6k/zJyD0R2pzB6IfAC8DxQYPdpNBrNwYVSEIuk1gYhfdXI9QDfBCqA5cAtSqnwvrgwjUaj2R8Ih7a88xgQBt4DzgHGY8Xs71OGlpUwf9wxTM52w12PctpDi2nZuppf3/sj0v75M55/bxtTcjwc85tv8u+twrzXl+JrrKJg7DSGjhvFTSePZljrGja+9DprF1ezzR/GFBjmdTJieBZDpo4kfdIUzNKxtHgK+LymkxVVbayvsmL0/S1NBNubrGLoSXo+kDBai8foJxdDdzhNnG4HTrcD0yG47Jh8r8vRQ4z+jsIpVtEUIxGn35vRWrKe31cxdDh4jNbiHH/tHzn+6msY+fAPeL6+kz/852ec/eeFLJv7LtnDx/PQN4+l8bc389qiKko8DmZ89Sjk/O9y70ur2fTJCvzNNRgOF7mjJjNpUjHnjy+msHMr7R++w/aFG9lS3U5tcEfhFK9pUOByMNTrJKssi+yRRWQOL8ZRMhzJG0IkPZ+2UIy2UIzOUJQGX4imgBWj39QZpMUXJui34vMTun48Pj+FYuhxdDH0fUDs0B30JyiljgAQkb/TD7aeGo1Gc2AzeMMxU6EvTT8h5exuERURGSYi80RklYisFJHv2f15IvKmiKy3X3P34Lo1Go1mYIjbMByk3jt9DfqTRaTNbu3ApPiyiLT1cWwEaw5gAnAs8G27uvutwNtKqTHA2/a6RqPRHCAoJBZJqQ1G+vLT32NTNduLv9pebheR1VhFfS8ETrF3ewyYD/xkT8+j0Wg0/c4gfYpPhVTj9PcKESkHjgIWAsVJxVlqgOJejrkRuBGgNDuDNzoK+P3nLzH69tep+mQux1z5Vb6Xv40/3TkHlyGcd8upbDr8In7/h/eoX/MR6YXDGD9jIhccXcpJhYrGfzzB+lfXsqItSCimKPE4OCzHw9BppRRMn4wx6ijCOWVsbgiyrKaNpdtaaKnvpKOlk0BbPWFfWxejNTHMnYzWnJ6MhNGa0+3A5bZN1lwGpmngdZlkepw7TeJ6HGaiWtaOhCxrItbq69lora9J3DjxPkjdaG1XyV7J7K9JXACnN4O3z1J8d+J7fOe6I3ks+3QWPvVbAG7++beZvvk1HrnvXVrDUa46ZQQjbv4Js5bUMH/+Rpo3r8DhySC9aBgjjxjG5VOHcVhGlPD8N6lcsIztKxvY5o/QGrb+82c7TbIcBiUek+wRWeSMzCVzeBGu0hE4iocTySzEb3ho80dp9IXpCEVo9oepbwvS2BnqYrSWbLYWjUQSn6t4YlZ3o7WeqmVpo7UBRKlUSyEOSlKN099jRCQDK7b/ZqVUF0nIrgPZ44yJUmqWUmqqUmpqfrp3oC9To9FoElhftn23wciADvoi4sQa8J9QSr1gd9eKyBB7+xCgbiCvQaPRaHaPfi2M3iupBLWIyJEi8l87GGaZiFyWtO1REdkkIkvsdmQq5x2wQV8sreDvwGql1L1Jm5Irv18DvDxQ16DRaDS7jWKfDPqkFtTiA65WSh0OnA3cLyI5Sdt/pJQ60m5LUjnpQGr6M7Bq6S4XkfjF3A7cDTwjItcDW4BL+3qjqqpW7vzLDcx8oYXqz96idNq5vHnTsbw58XhWtwf5xoVjyf3hfXzl4Y/Z+OFbmC4v5dOO5YdnjmV6aSaRNx5i9VMLWVTbSWs4RrbTYGyGi9LpQxh6wiRcR5xAa0Yp9e1hlta28dmWZupqOmhv9hNoriHc2UYk6O+SmGU4XIhhJgzWnJ4M+9WDy+3A6TYTur7bbZmrZXoceF079Hyvy+xitOY0rMIpZpKWHzdZ68loLa7nA130fLr1Ja55l6Zsu9bzezo0VT1/oFjyyA3cW3oU55Zm4fjN49xx3YOk5Q9lwqnH8/+mOHnrhPtY2hrgvCGZTPn5jbwbHsqsVxZTs+J9APIrplBUXsLlM8o5aXgWsvRVqt7+kO0fV7OhI0R90IrOyHAYFLhM8lwmhSUZ5I7KIWvkENLLR+AcWk40s5iIN49WX4Rmf4QGX4iOUJSGzhCNHSEaO4J0+MKEglFCwQjhQJRIKEokFCZqf67iZmoJY7VIaCejNa3n7xuUUqjwPjEe6DOoRSm1Lmm5SkTqsCxxWvb0pAM26Cul3qf3JM6ZA3VejUaj2Tt2ayK3QEQWJ63PUkrNSvHYlIJa4ojIdMAFfJ7U/SsR+Tn2LwWlVLCvk+6T6B2NRqMZNCi1O7+SGpRSU3vbKCJvASU9bLqj6ymVEpFe04Dt+c/HgWuUSsST3ob1ZeECZmH9SvhlXxesB32NRqPpTj9F5iilTu9tm4jUisgQpVT1roJaRCQLeA24Qyn1UdJ7x38lBEXkH8APU7mmAQ/Z1Gg0msGF6lbEpve2l/QZ1CIiLuBF4J9Kqee6bYtHQQpwEbAilZMOiif9whwPD46+lg9/eDcnfu1r/N8lk1l9xYW8tLGZL4/L54gHH+A7r65l6X/mE/F3MPzYc/nmBROYWRSFJbNZ/uhcPlvdSFUgkqiWNfrIYspOnkja1FMIDZnA53V+NrX4WbS5mU3b22mp78TXWEugtX6nalmGw2UlZTmsxCyn15rEtRKzHDg9ZpfJXG9StSyvc8ckrsth4HYYeEzrdYer5o6ErPhrfALXNHa4a8aTsrpjSNdJ3O7JWt0Ts/qsprXn/3T2++/lG/TCkiknAHDGsjcYf9sb+BqquOOum/j2MWUsufR8XtnUzJQcDyff/WW2TriAXzz+CZsWfkC4s5W8UZOpOHoUMw4r5AtjC8jc+jHVb7zJ1gWbWFvvozYYIarAawoFLpPhaU4ys93kjsohp2Io2RUjcJaORuWVEc0sojkQpTUYpbYzRF1niM5QhOqWAPXtAVo6QoQCEUL+MOHu7prxFtvhttlbtSxIfcJWT+LuBfHonYGnx6AWEZkKfFMpdYPddxKQLyLX2sdda0fqPCEihVj/RZdg2eD3yaAY9DUajWafsY+id5RSjfQQ1KKUWgzcYC//C/hXL8eftifn1YO+RqPRdOHgtmHQg75Go9Ekc5B77wyKQT9SNpK7bn+ACedczNyLi6i8/zs8NHsdpxamcepTv+G+DU5efPINOmo3UzL5VK68YDzXTCrC/+9fsf3dpXzy/jbWdQQxBcrTXIwbm8ewk8eRfdzJRIYfxYbmIIurWtlU38mqLc001rTT0VCHv7mGUGcb0dAOozXD4bIqY7m8GA4nDm8GDk8GzvRs3F6nreU77MQsBxkeB5keBy6H2cVozesy8ZhGolqW0zRw26Zr8SpZydWyTFuXT66WFTdZg52rZSXr+XGSpfXBWi0rmbe2tnLP0keYfu8SKhf9h4u+83VuHVLFplt/yhNvbGSY18l5t5xK6Is/5kdPL2Pl/I/wNVaROWQ0I4+eyNdPHsWUoVmUtm2gae7LbHl7DWs2tbLNH8YfVbgMIddp6fkFw7LIKEoj97Ah5IwdhnP4WCguJ5pVQksYWgJRqtuD1HUGqW0L0BGI0NQZpLEjRNAfIegPd6mWFQ35E4lZ0XjFrOjOE4VxPT++Lc6uNHut5+89g9VXJxUGxaCv0Wg0+w79pK/RaDSHDEopVGSf2DDsF/Sgr9FoNMnsu5DN/cKgGPQ/31zDyK/OZOFtxzN3wknMq+lgcraHi566lSci4/m/v71N08alFIydxhcvPJLvzxhObPb9fPbnt9m2uYUVbZYdRXmai0mjcxh5xngKTj0VNfZ4NnUKC7c18+GGBiobfDRWd9BeV2/p+b6uer4YJobDhcPlxeFJx3C6EoVT4lq+y+vA7XHidJuk2Xp+hseJyzTsZUdCz3c7TCtO32HYZmtWXL5pkIjPNw1J6Plxw7Uuy/bfKFnPJ6kPdtbpUy2cciDr+QB3vXYHM+cKy199hhnXXMsTp6fzn+Nu4IO6TrKdJpfeOI3cH97HTS+t5qPXF9JWuY60/KGMnDaVa2dWcP5h+XibN9P2+lNseOVT1qyqZ7MvREckhimQ5zIZme5kSFkmBYflkVaUTd64EbjKx2GUjCSSNYTWqIMmf5TqjiA1HUGqWwNUtwboCISpawsS6AwTDIQJ+iM7CqiEgsTCoZ30/LjxWnLhFOiq53fX67V+PxBoeUej0WgOHRQJR9ODET3oazQaTRdUv3nvHIjoQV+j0Wi6o+UdjUajOURQipiO3tm/ODzpLL/3XOZPOp5XKtuYmOXm6ie+x8sFp/Oze9+mdsUC8iumcN6Xj+Pnp4/GNfchPrn/VT5Y1UBDKEIophid7uLoUTmMPnsCxWedAYefwqagiw+3tfDuunrWbWymsy1Ia20DvsbtBDuaifg7ukzimi4vTm8GDk96wmTNSspy4/I6cXsdCaO1jDRnYhI3066cFZ/ETXeaO03iuh3GjslbkV1O4go7V8pKnsTt3g87m6zB4J7EBbhwwzg+/OffmX75V3nj8lLePukSXqlso9BtctX1Uyi96y/c/Opa5jz/AU0bl1qTuMfM4PpzDuOywwtxf/YKnWuWse6FhaxdWse6jhCtYWsSt9DtoDzNSenQTAonFJA/sZz0knw8FRMwS8cSyR1GGx6aAhFrArc9SHVbgOqWAHV2cpavM0QwECbUbRI3GvRbyVlxs7WEyZo1iRs394slJWxBapO4emK3H1AKFdXyjkaj0RwSKIUe9DUajebQQWkbBo1Gozlk0E/6+5+Jw7KYP+4YXt3ayrcuGc+4Gy/lmbwzuP13b1C7YgEFY6fxpUtn8MszK/D8508s/v1LzF9WR1UggikwOt3F1DG5VHxhIsXnnAUTT2NjwNLz562pY93GZhqq2gi2t6Sk57vSs3GmZ2M4XAk935PuTCRlZaQ5yUlzJvT8DI+l6aei58eTs3al55uGHPJ6PsC8v/6d46++hrcuLeLNY7/Ey1taOb8si/EXT2Tor//O/7y8hteeXZDQ80cfdwI3njeeyycW4f30ZbY+/QKNa+tZ8Ul1j3r+8NJMio4opHDyKLLGjcHML8EsOyyh59f7IlS1B9neFqCyxU91S4DqVj9NbUHCwWhCzw/6w7vU8+MavtbzDwyUUkRDeiJXo9FoDhm0vKPRaDSHCgd59I4ujK7RaDTdUNFYSm1vEJE8EXlTRNbbr7m97BcVkSV2m53UP1JEForIBhF52i6i3ieD4km/adka3qCE7//PdLz/7x88uKKG3/7qeZo2LqVk8ql87Ypp3HbSCIL//hUf3juXdz9voj4YJc9lUux2cNT4fCrOn0zhWecQG38y69rh/S1NzF9Tx+ebmmmsbqejdhMRfwfB9uZei6Yk6/mutHQcTtMqnGKbrLm9DjK7xedneHZo+t1N1uJFU3oqgt6XyVpysfOeiqbE9f84B5ueD/DF732Tf0/38dxRX2ZevY9Ljyji5Kd+S8uw6Vz+xFLef3k+bZXryBwymrEnHMt3zjmML43Lh/f+zcZnXmHDnM/Z5gvzeadlsuYyrCLoFRkuho7IpviIQgomjSbzsLG4KiYRS8shklNGc9RBoy9CZVuA7e0BKpv9ltFai5+WdstkLRKOdjFZCwd8iaIpkZA/EZtvmaztXAS9Nz1fa/kDj1L7LHrnVuBtpdTdInKrvf6THvbzK6WO7KH/HuA+pdRTIvIwcD3w575Oqp/0NRqNphuxaCyltpdcCDxmLz8GXJTqgWI9uZ0GPLe7xw+KJ32NRqPZZ8QUsVAk1b0LRGRx0vospdSsFI8tVkpV28s1QHEv+3nsc0SAu5VSLwH5QItSKn6hlUBpKifVg75Go9Ekodit6J0GpdTU3jaKyFtASQ+b7uhyTqWUiKhe3maEUmq7iIwC3hGR5UBrqhfYHT3oazQaTTL9GL2jlDq9t20iUisiQ5RS1SIyBKjr5T22268bRWQ+cBTwPJAjIg77ab8M2J7KNQ2KQT8UU9z58BWsOeuHXPPzN6ldvZhAawOjTrqQ266ewpXDotT99mY+efgDFjT46IjEGOpxMH1oJnljchl93tHknH4B/uFTWVHvZ/7GRhasradqawtNVY1WQlZrAxE7cSZOfBLX6Um3qmOl2ZO4Xi9urxOHy8DtsSdyvU6y05xkepxkuB2JKlkZHgceh4nTFHsi15rMjVfK8iQbrRmCgT2Ra7BjWayJ1O6TuMkJWdBtcjd+D3s5gWvt2/fs7L6cwI3zj8wF3Dt9FlWBMN+4cCwT//IX7l4RZs7sj1jxxlv4m2vIr5jC4Scfya1nHcZJ+WEis+9n7ZPzWPdhJSvagrSGY4RiCq8pDPU4qchwUlSRR9ERxRRMqiDtsAk4yycQyS0j5smmwR+lwR+mss1KytrW5EtM4nZ2hgh0hgn4wkQjMcLBCKFgxErGSk7KshOykqtkxSdx48U79CTu/mUfhWzOBq4B7rZfX+6+gx3R41NKBUWkAJgB/Nb+ZTAPuBh4qrfje0JP5Go0Gk0yCmKxWEptL7kbOENE1gOn2+uIyFQR+Zu9z3hgsYgsBeZhafqr7G0/AX4gIhuwNP6/p3LSQfGkr9FoNPsKxb5JzlJKNQIze+hfDNxgL38IHNHL8RuB6bt7Xj3oazQaTTJKEQtr7539ypAJI3hw9LU8cPOjtGxegSe7kGmXXsYfrzyKiQ0fs+b7D/Dea5+zoi2AKcLELDeTJxRQccGRZI8dievYL1CXPpxFm1uZv76BTzY0UFfZRltNjaXnd0vIEsPEcLhwuK2ELCsZK9sumOJMJGRZyVkO3G5HwmAt22slZ3ldpqXn2wlZTlPsZKwdRmvJCVnJBmvJyVlC73p+TwlZcPAarHXnjsseZKjHya2/Pg/1jbu58MmlLJw9j876bYhhMuyYL3DOGWP4zonljOlYR8Mjj7P2+cWsWN2YSMgCyHYaDPM6GZ3roXBCAUWTh5M3cSTuiklI6RjCdkKWrzNCTUeIyrYg1e0Btjf5qWz2UdcWtLX8EEF/hJA/TDQaIxIKJ7T8SMhKzFLRaELPj0XCOyVkgdbz9zsHucvmgGn6IvKIiNSJyIqkvpTSjjUajWb/ofaJDcP+YiAnch8Fzu7WF087HgO8ba9rNBrNAYNS+ywjd78wYIO+UmoB0NSte4/TjjUajWbfoOxQ2r7bYGRfa/qpph0jIjcCNwK4sotYefsDOL0ZTLvsKk4/amjCYG1+N4O1abkeDjtzFOXnn4jruC8QzSljdTu8v6Z+J4O1YGsDoc7WROEK2LXBmttjFUuJF0E3TaNXgzWv0yTNaZmruU0D05BeDdZMEUxjh5YPqRmsddfpezJY25WWDz3r+Qe6lh/n/AmFnPzUb3k2PIZf/O/bbP5wLgDphcMYc/wxfPcL4xIGa+tsg7VPm/3UBiNElaXlp5tGF4O1/MNHkjVhHK6KSURzh+FPL6TeF6GuM0hrINKrwVrAFyIciBIKRggHrTj8VA3WtJZ/gBGDWOjg/Rvvt4ncPtKOsf0rZgGkl45Vg/M7VaPRDDYUatBKN6mwrwf9lNKONRqNZr+hQMV6fR4d9OzrjNx42jHsRtqwRqPR7EtiUZVSG4wM2JO+iDwJnIJlPVoJ3ImVZvyMiFwPbAEuHajzazQazZ6gDvI4/QEb9JVSV/Syaae0477wtzQz6sKZ3HL1FK4/zANrPmDlFd9lwTtbWN0exGUIU3I8HHFUMRXnTyHvjPMIVcxgaX2AzZs6mbeugSUbGmmoaqOtpgpf43ZCnW07VcgSw8TpzcDRzWDNk+6ykrCSzNUyPA7cDoPsNFcXgzWvy5rAjZurOc0dE7lOQ6y+bhWyupurQWoJWV2Sr4gft2N7MgdLQlYy5e+8zczHP2Xp67PorN9GTvlEJpx0NMeNLeSbxw6nrP4zan77/1j30hKWfd7CZl8If9QyVyt2O6jIcJGZ7aZoQgEFE4eRf0QFropJMKSCUE4ZjUFobAmxtTVATXuAtmCEyiY/Na1+alsCBHxhAp2hRIWsZHM1FYsmErJ2TOKGd1khC3qezO2+TTPAKIUapE/xqTAoMnI1Go1mn6EgqqN3NBqN5tBAAbGDeCJXD/oajUaTjJZ39j8lpcUsv/dcQk/cxYLr57Klup1PWwIAjM90c9T4fCrOn0zhWecQG38yq9rh/SU1zF9TR02jj4bt7bRUV/dormY4XBgOF05vBobD2au5mttjJWQlJ2O5TKNrsRTbXM3tsEzVkpOxTIMezdUSCVhJy5CauVpPyVjJ+3Tvh4NDy48z/WsP0la5jozicqZ8+Uq+fe44Lhmfj7N2LU3//BkfPb+YlSvrWddhmau5DGGox9ElGctblEvBpNG4Rh2OWTaWSO5wmqMOGlujVLYFuiRjdQTCVLcEupirhYN2C/i6JGMpO+lqV+Zqven3fa1rBh4dp6/RaDSHCFb0jn7S12g0mkMDPehrNBrNIYRSRMMHr6Q2KAb9In8974yZzoLaDlrDljY7OXvnuPxl9QHe/ayBeavrqNzSQlN1M+HO1l7j8rsXPTccrl3G5ed0i8l3OYxe4/K7Fz2Px933FJffPSYf2GVcfl9FUrpvSz6mO4NRy49jOFwcf/U1/PDscZw51CQ673HW/+5NGtY07hSXX57mpCLDRfGoHLvo+WjSx47DkV8CQyqI5JRRH4TGtghbWzuoaQ+wLclYra09SCQc6zUuP7noeSIWv4+4fG2sdmCiYJ9k24pIHvA0UA5sBi5VSjV32+dU4L6krnHA5Uqpl0TkUeBkoNXedq1Saklf59WF0TUajSYZtc+KqPRZX0QpNU8pdaRS6kjgNMAHvJG0y4/i21MZ8EEP+hqNRrMTKqpSanvJ7tYXuRh4XSnl25uT6kFfo9FokrAqZ+0Tw7WU64vYXA482a3vVyKyTETuExF3KicdFJq+RqPR7DN2byK3QEQWJ63PsmuBACAibwElPRx3R9dT7rq+iG1FfwQwN6n7NqwvCxdW7ZGfAL/s64IHxaC/vbKFt8w0xme6mTx1CHkV+Qw7fybm0WdT5Shk3vY25r26lmUbGmnY3kZ7XXVi8jYWCSUqY4lhYrq8CVM1V3o2Dk8G7swcXF4npmng9joSlbHSvE5y0pxkeJw9mqqZIonKWJ5uk7jdTdXiE7OJZXo3VYOdJ3Xh0DRV2xWL/34jpTWLqX7qp7z/4lKWb25NTN4C5LlMxmc6GVGYRvERhRRMHE7exDG4Rh2emLztiAn1vig1NVYi1rYWf8JUraEt2MVULRqN2YlYga5VsXowVQP6rIzV20StnsDdz+xeyGaDUmpqr2+l1Om9bROR3akvcinwolIqnPTe8V8JQRH5B/DDVC5YyzsajUaThIJ9NZG7O/VFrqCbtGN/USDW099FwIpUTjoonvQ1Go1mn6H2TcgmvdQXEZGpwDeVUjfY6+XAMODdbsc/ISKFWD/qlwDfTOWketDXaDSaLuwbwzWlVCM91BdRSi0Gbkha3wyU9rDfaXty3kEx6Bdmubnzd1eQddoFtA+ZTL0vwguVrbw9r55VGzfSsL2Njrrt+BqrCHW2Eg35E8eKYeLwZOBwexM6vjMtG1d6ZkK7jydhOZwmGUmGajleJ16XaRmqua2iKfEkLLfDxBR61PHjxmnxJCzTFtHiOr6ZpMnvylAtfkyX9V2YqSXv352DRcdPZu2Mk3l6Wzvb/GFCMSsJa6jHSZ7LYMSQTAoPL6BwUjk540fjqpiEKh5NJKeUKl+EJn+ErZvb6QhG2N4WSOj4dXZxlJA/TNAfIegPEwlHifg7ULHojiSsXRRH6a7hJy/rJKwDH6UgprQNg0aj0RwSKCCk/fQ1Go3m0CGqn/Q1Go3m0EABB7HJ5uAY9GPDR/Hg6GtZ8EY9NVvn4WsP0lG3HX9zTaIoSpy4aZrTk44zPRvT4epVw3d7nWSnOcm04/DTXOYuNXynYZuo2fq9IdKrht89Dh/6LnDeU1GUPSmIAgenht+dOeubGOpxcmphGsWH5VN0RAkFkypw5ed10fDr4xp+U4Dtm2vY3uynstlPXVsAfyDSq4Yfi4RSMlLrLQ6/+/Ku+jQHDkrpJ32NRqM5pNBP+hqNRnOIoFD6SV+j0WgOFazonf19FQOHHvQ1Go0mCa3pHwCs31LLXbc/sFPSlenyWqZp+UOtpKv0bFxp6V0mah1OE6fbSrqKm6dlui3jtAyPA6/TTEzYOuLGaYZlpBZPtuot6UrEmlw1JbXKV/F+6B/ztFQna633T3nXQcOvX/ohrlGHEysoJ5hRTKM/yvrOMK3xhKuVfiqb11LXFqCpLYi/I0TQHybkt6pehYPW5GyXylf2pG0sEkLFYntV+WpX/ZoDG63pazQazSGCFbJ58I76etDXaDSaJHScvkaj0RxCKKVtGPY7pstD6dEz8aS5cHsdGA4Dt8dKtMq0DdKyvS4y7QInGR4H6S4HHoeVQOV2WFp9d2O0ZK0+boqW0Od70Op36O89a/V9JVcl98fZG4O0g1Gn3x2uqDmalvVBAp0bCPhWEQ5ECQbCqJgiHPB1LXSSMEfbe61e6/QHP1re0Wg0mkMEBRzEEZt60NdoNJqu6OQsjUajOWTQE7kHABNH5PHBvefu78vQHGDMeXDW/r4EzUGIDtnUaDSaQ4iDPXrH6HuX/kdEzhaRtSKyQURu3R/XoNFoNL0RVam1vUFELhGRlSISs4uh97Zfj+OliIwUkYV2/9Mi4krlvPt80BcRE3gQOAeYAFwhIhP29XVoNBpNT8TlnVTaXrIC+BKwoLcd+hgv7wHuU0pVAM3A9amcdH886U8HNiilNiqlQsBTwIX74To0Go1mJ+ITuQP9pK+UWq2UWtvHbj2Ol2IlAJ0GPGfv9xhwUSrn3R+afimwLWm9Ejim+04iciNwo70aTPN6V+yDa9tXFAAN+/si+pGD7X7g4LunQ+l+RuzNGzcQmvsXthSkuLtHRBYnrc9SSvVnhEFv42U+0KKUiiT1l6byhgfsRK79h5sFICKLlVK9al6DDX0/Bz4H2z3p+0kdpdTZ/fVeIvIWUNLDpjuUUi/313l2h/0x6G8HhiWtl9l9Go1Gc1ChlDp9L9+it/GyEcgREYf9tJ/yOLo/NP1FwBh75tkFXA7M3g/XodFoNAc6PY6XSikFzAMutve7Bkjpl8M+H/Ttb6WbgLnAauAZpdTKPg472LJw9P0c+Bxs96Tv5wBDRL4oIpXAccBrIjLX7h8qInOgz/HyJ8APRGQDlsb/95TOqw7izDONRqPRdGW/JGdpNBqNZv+gB32NRqM5hDigB/3BatcgIo+ISJ2IrEjqyxORN0Vkvf2aa/eLiPyffY/LRGTK/rvynhGRYSIyT0RW2Wnj37P7B+U9iYhHRD4WkaX2/fzC7u8xrV1E3Pb6Bnt7+X69gV4QEVNEPhORV+31wX4/m0VkuYgsicfCD9bP3IHEATvoD3K7hkeB7rG+twJvK6XGAG/b62Dd3xi73Qj8eR9d4+4QAW5RSk0AjgW+bf9bDNZ7CgKnKaUmA0cCZ4vIsfSe1n490Gz332fvdyDyPazJvjiD/X4ATlVKHZkUkz9YP3MHDkqpA7JhzWjPTVq/Dbhtf1/Xblx/ObAiaX0tMMReHgKstZf/AlzR034HasMKDTvjYLgnIA34FCvLsQFw2P2Jzx9W5MRx9rLD3k/297V3u48yrEHwNOBVrEqcg/Z+7GvbDBR06xv0n7n93Q7YJ316Tj9OKc34AKVYKVVtL9cAxfbyoLpPWwo4CljIIL4nWwpZAtQBbwKf03tae+J+7O2tWCFyBxL3Az9mR6W/XaXpD4b7AcsG5w0R+cS2ZYFB/Jk7UDhgbRgOZpRSSkQGXaysiGQAzwM3K6XaJKky+2C7J6VUFDhSRHKAF4Fx+/eK9hwROQ+oU0p9IiKn7OfL6U9OUEptF5Ei4E0RWZO8cbB95g4UDuQn/YPNrqFWRIYA2K91dv+guE8RcWIN+E8opV6wuwf1PQEopVqwMhuPw05rtzclX3Pifuzt2Vhp8AcKM4ALRGQzlgvjacADDN77AUAptd1+rcP6Yp7OQfCZ298cyIP+wWbXMBsrVRq6pkzPBq62ow+OBVqTfr4eEIj1SP93YLVS6t6kTYPynkSk0H7CR0S8WPMTq+k9rT35Pi8G3lG2cHwgoJS6TSlVppQqx/p/8o5S6isM0vsBEJF0EcmMLwNnYvnPD8rP3AHF/p5U2FUDzgXWYemtd+zv69mN634SqAbCWNri9Via6dvAeuAtIM/eV7CilD4HlgNT9/f193A/J2Dpq8uAJXY7d7DeEzAJ+My+nxXAz+3+UcDHwAbgWcBt93vs9Q329lH7+x52cW+nAK8O9vuxr32p3VbG//8P1s/cgdS0DYNGo9EcQhzI8o5Go9Fo+hk96Gs0Gs0hhB70NRqN5hBCD/oajUZzCKEHfY1GozmE0IO+Zr8jIlHbSXGl7Xx5i4js8WdTRG5PWi6XJLdTjeZQRw/6mgMBv7KcFA/HSpQ6B7hzL97v9r530WgOTfSgrzmgUFbK/Y3ATXZ2pSkivxORRbZP+jcAROQUEVkgIq+JVXPhYRExRORuwGv/cnjCfltTRP5q/5J4w87C1WgOSfSgrzngUEptBEygCCubuVUpNQ2YBnxdREbau04HvoNVb2E08CWl1K3s+OXwFXu/McCD9i+JFuDL++xmNJoDDD3oaw50zsTyVFmCZeecjzWIA3yslNqoLMfMJ7HsInpik1Jqib38CVatA43mkERbK2sOOERkFBDFclAU4DtKqbnd9jkFyw8omd48RYJJy1FAyzuaQxb9pK85oBCRQuBh4E/KMoaaC3zLtnZGRMbarosA020XVgO4DHjf7g/H99doNF3RT/qaAwGvLd84serxPg7ELZz/hiXHfGpbPNcDF9nbFgF/AiqwbIRftPtnActE5FPgjoG/fI1m8KBdNjWDElve+aFS6rz9fCkazaBCyzsajUZzCKGf9DUajeYQQj/pazQazSGEHvQ1Go3mEEIP+hqNRnMIoQd9jUajOYTQg75Go9EcQvx/RXX4CWTX5MgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 512)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기   : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)  # (64,4,40,32)(64,4,32,40)\n",
    "#     print('matmul_qk.shape=',matmul_qk.shape)  # (64,4,40,40)\n",
    "\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "#     print('depth=',depth)\n",
    "    \n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "    \n",
    "    print('logits=', logits)\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)  #  57.7 += -1000000000\n",
    "        \n",
    "    print('logits=', logits)\n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "#     print('attention_weights.shape=', attention_weights.shape)\n",
    "    \n",
    "    print('attention_weights=', attention_weights)\n",
    "    print('value=', value)\n",
    "\n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value)  # (64,4,40,40)(64,4,40,32) => (64,4,40,32)\n",
    "#     print('output.shape=', output.shape)\n",
    "\n",
    "    print('output=', output)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_qk.shape= (1, 4)\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_qk.shape= (3, 4)\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 6.  6.]\n",
      "  [22. 22.]\n",
      "  [38. 38.]]\n",
      "\n",
      " [[54. 54.]\n",
      "  [70. 70.]\n",
      "  [86. 86.]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(24).reshape(2,3,4)\n",
    "b = np.ones((4,2))\n",
    "c = np.dot(a,b)   # (2,3,4)(4,2) => (2,3,2)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 3.  3.]\n",
      "   [12. 12.]]\n",
      "\n",
      "  [[21. 21.]\n",
      "   [30. 30.]]]\n",
      "\n",
      "\n",
      " [[[39. 39.]\n",
      "   [48. 48.]]\n",
      "\n",
      "  [[57. 57.]\n",
      "   [66. 66.]]]], shape=(2, 2, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(np.arange(24).reshape(2,2,2,3), dtype=tf.float32)\n",
    "b = tf.ones((2,2,2,3))\n",
    "\n",
    "c = tf.matmul(a, b, transpose_b=True)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads\n",
    "#         print(\"self.depth=\",self.depth)\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)  # (2,512)(512, 512) => (2, 512)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "#         print(\"self.query_dense.weights=\",self.query_dense.weights)\n",
    "\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))  # (64,40,128)=>(64,40,4,32)\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])   # (64,40,4,32)=>(64,4,40,32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        \n",
    "#         print(query.shape)\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "#         print(\"batch_size=\",batch_size)\n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)  # (64,40,128)(128,128) => (64,40,128)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "        \n",
    "#         print('query.shape=',query.shape)\n",
    "        \n",
    "#         print(\"wq.shape=\",self.query_dense.weights[0].shape)  # (128,128)\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        \n",
    "#         print(\"query.shape=\",query.shape)   # (64,4,40,32)\n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "#         print(\"scaled_attention.shape=\",scaled_attention.shape)  # (64,4,40,32)\n",
    "        \n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "#         print(\"scaled_attention.shape=\",scaled_attention.shape)   # (64,40,4,32)\n",
    "            \n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "#         print(\"concat_attention.shape=\",concat_attention.shape)   # (64,40,128)\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)  # (64,40,128)(128,128) => (64,40,128)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "[[1. 1.]\n",
      " [5. 5.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(4).reshape(2,2)\n",
    "print(a)\n",
    "b = np.ones((2,2))\n",
    "print(b)\n",
    "c = np.matmul(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1]\n",
      "  [2 3]]\n",
      "\n",
      " [[4 5]\n",
      "  [6 7]]]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "[[[ 1.  1.]\n",
      "  [ 5.  5.]]\n",
      "\n",
      " [[ 9.  9.]\n",
      "  [13. 13.]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(8).reshape(2,2,2)\n",
    "print(a)\n",
    "b = np.ones((2,2))\n",
    "print(b)\n",
    "c = np.matmul(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 3.  3.]\n",
      "   [12. 12.]]\n",
      "\n",
      "  [[21. 21.]\n",
      "   [30. 30.]]]\n",
      "\n",
      "\n",
      " [[[39. 39.]\n",
      "   [48. 48.]]\n",
      "\n",
      "  [[57. 57.]\n",
      "   [66. 66.]]]], shape=(2, 2, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(np.arange(24).reshape(2,2,2,3), dtype=tf.float32)\n",
    "b = tf.ones((2,2,2,3))\n",
    "\n",
    "c = tf.matmul(a, b, transpose_b=True)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.shape= (64, 40, 128)\n"
     ]
    }
   ],
   "source": [
    "mha = MultiHeadAttention(128,4)\n",
    "x_train = tf.ones((64,40,128)) # (N,T,D)\n",
    "x = { 'query':x_train,'key':x_train,'value':x_train, 'mask':None}\n",
    "outputs = mha(x)\n",
    "print(\"outputs.shape=\",outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)  # [[0,0,0,1,1]] (1,5)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]    # [[[[0,0,0,1,1]]]]   (1,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))  # (N,T) => (1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits= tf.Tensor(\n",
      "[[[[ 0.2865792   0.2865792   0.2865792   0.2865792   0.2865792 ]\n",
      "   [ 0.2865792   0.2865792   0.2865792   0.2865792   0.2865792 ]\n",
      "   [ 0.2865792   0.2865792   0.2865792   0.2865792   0.2865792 ]\n",
      "   [ 0.2865792   0.2865792   0.2865792   0.2865792   0.2865792 ]\n",
      "   [ 0.2865792   0.2865792   0.2865792   0.2865792   0.2865792 ]]\n",
      "\n",
      "  [[-0.16200161 -0.16200161 -0.16200161 -0.16200161 -0.16200161]\n",
      "   [-0.16200161 -0.16200161 -0.16200161 -0.16200161 -0.16200161]\n",
      "   [-0.16200161 -0.16200161 -0.16200161 -0.16200161 -0.16200161]\n",
      "   [-0.16200161 -0.16200161 -0.16200161 -0.16200161 -0.16200161]\n",
      "   [-0.16200161 -0.16200161 -0.16200161 -0.16200161 -0.16200161]]]], shape=(1, 2, 5, 5), dtype=float32)\n",
      "logits= tf.Tensor(\n",
      "[[[[ 0.2865792   0.2865792   0.2865792   0.2865792   0.2865792 ]\n",
      "   [ 0.2865792   0.2865792   0.2865792   0.2865792   0.2865792 ]\n",
      "   [ 0.2865792   0.2865792   0.2865792   0.2865792   0.2865792 ]\n",
      "   [ 0.2865792   0.2865792   0.2865792   0.2865792   0.2865792 ]\n",
      "   [ 0.2865792   0.2865792   0.2865792   0.2865792   0.2865792 ]]\n",
      "\n",
      "  [[-0.16200161 -0.16200161 -0.16200161 -0.16200161 -0.16200161]\n",
      "   [-0.16200161 -0.16200161 -0.16200161 -0.16200161 -0.16200161]\n",
      "   [-0.16200161 -0.16200161 -0.16200161 -0.16200161 -0.16200161]\n",
      "   [-0.16200161 -0.16200161 -0.16200161 -0.16200161 -0.16200161]\n",
      "   [-0.16200161 -0.16200161 -0.16200161 -0.16200161 -0.16200161]]]], shape=(1, 2, 5, 5), dtype=float32)\n",
      "attention_weights= tf.Tensor(\n",
      "[[[[0.2 0.2 0.2 0.2 0.2]\n",
      "   [0.2 0.2 0.2 0.2 0.2]\n",
      "   [0.2 0.2 0.2 0.2 0.2]\n",
      "   [0.2 0.2 0.2 0.2 0.2]\n",
      "   [0.2 0.2 0.2 0.2 0.2]]\n",
      "\n",
      "  [[0.2 0.2 0.2 0.2 0.2]\n",
      "   [0.2 0.2 0.2 0.2 0.2]\n",
      "   [0.2 0.2 0.2 0.2 0.2]\n",
      "   [0.2 0.2 0.2 0.2 0.2]\n",
      "   [0.2 0.2 0.2 0.2 0.2]]]], shape=(1, 2, 5, 5), dtype=float32)\n",
      "value= tf.Tensor(\n",
      "[[[[ 0.27459717 -1.505249    0.7844696  -1.0473633 ]\n",
      "   [ 0.27459717 -1.505249    0.7844696  -1.0473633 ]\n",
      "   [ 0.27459717 -1.505249    0.7844696  -1.0473633 ]\n",
      "   [ 0.27459717 -1.505249    0.7844696  -1.0473633 ]\n",
      "   [ 0.27459717 -1.505249    0.7844696  -1.0473633 ]]\n",
      "\n",
      "  [[-0.26574707  0.00488281  1.1559448  -1.1607056 ]\n",
      "   [-0.26574707  0.00488281  1.1559448  -1.1607056 ]\n",
      "   [-0.26574707  0.00488281  1.1559448  -1.1607056 ]\n",
      "   [-0.26574707  0.00488281  1.1559448  -1.1607056 ]\n",
      "   [-0.26574707  0.00488281  1.1559448  -1.1607056 ]]]], shape=(1, 2, 5, 4), dtype=float32)\n",
      "output= tf.Tensor(\n",
      "[[[[ 0.27459717 -1.505249    0.7844696  -1.0473633 ]\n",
      "   [ 0.27459717 -1.505249    0.7844696  -1.0473633 ]\n",
      "   [ 0.27459717 -1.505249    0.7844696  -1.0473633 ]\n",
      "   [ 0.27459717 -1.505249    0.7844696  -1.0473633 ]\n",
      "   [ 0.27459717 -1.505249    0.7844696  -1.0473633 ]]\n",
      "\n",
      "  [[-0.26574707  0.00488281  1.1559448  -1.1607056 ]\n",
      "   [-0.26574707  0.00488281  1.1559448  -1.1607056 ]\n",
      "   [-0.26574707  0.00488281  1.1559448  -1.1607056 ]\n",
      "   [-0.26574707  0.00488281  1.1559448  -1.1607056 ]\n",
      "   [-0.26574707  0.00488281  1.1559448  -1.1607056 ]]]], shape=(1, 2, 5, 4), dtype=float32)\n",
      "outputs.shape= (1, 5, 8)\n"
     ]
    }
   ],
   "source": [
    "mha = MultiHeadAttention(8,2)\n",
    "x_train = tf.ones((1,5,8))\n",
    "mask = create_padding_mask(tf.constant([[1, 21, 777, 33, 22]]))\n",
    "x = { 'query':x_train,'key':x_train,'value':x_train, 'mask':mask}\n",
    "outputs = mha(x)\n",
    "print(\"outputs.shape=\",outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': padding_mask # 패딩 마스크 사용\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)  #   # (64,40,128)+(64,40,128)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)  # (64,40,128)(128,512)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)                   # (64,40,512)(512,128)\n",
    "                                                                              # (64,40,128)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)                                    # (64,40,128)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")    # (64,40)\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)   # (64,40)=>(64,40,128)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings) # (64,40,128)+(64,40,128)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "      outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,       # (64,40,128)\n",
    "          dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "      )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 5\n",
    "look_ahead_mask = tf.ones((seq_len, seq_len))\n",
    "print(look_ahead_mask)\n",
    "look_ahead_mask = 1 - tf.linalg.band_part(look_ahead_mask, -1, 0)\n",
    "print(look_ahead_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    #look_ahead_mask = tf.ones((seq_len, seq_len))\n",
    "    #look_ahead_mask = tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0) # (5,5)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함  # (1,1,1,5)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask) # (5,5)>(1,1,1,5) => (1,1,5,5)>(1,1,5,5)\n",
    "#    return look_ahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[4, 1, 3, 0, 0]])))  # (1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "        })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "            'mask': padding_mask # 패딩 마스크\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                  d_model, num_heads, dropout,\n",
    "                  name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs) # (N,T,D)(D,V)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "# Text(0.5, 0, 'Train Step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 처음 설치 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 업그레이드 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --user --upgrade tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('챗봇 샘플의 개수 :', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"날씨가 좋넹.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"고민이 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"너무 화가나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"카페갈래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"게임하고싶당\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"게임하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
