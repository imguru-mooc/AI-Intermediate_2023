{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb291b62b1aa"
   },
   "source": [
    "# Training and evaluation with the built-in methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d4ac441b1fc"
   },
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:48.305955Z",
     "iopub.status.busy": "2021-04-07T17:58:48.305368Z",
     "iopub.status.idle": "2021-04-07T17:58:53.785129Z",
     "shell.execute_reply": "2021-04-07T17:58:53.785508Z"
    },
    "id": "0472bf67b2bf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c16fe7fd6a6c"
   },
   "source": [
    "## 시작하기\n",
    "\n",
    "이 안내서는 훈련 및 유효성 검증을 위해 내장 API를 사용할 때의 훈련, 평가 및 예측 (추론) 모델 (예 : `model.fit()` , `model.evaluate()` , `model.predict()` )에 대해 설명합니다.\n",
    "\n",
    "고유한 훈련 단계 함수를 지정하면서 `fit()`을 사용하려면 <a href=\"https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\" data-md-type=\"link\">\" `fit()`에서 이루어지는 작업 사용자 정의하기\"</a> 가이드를 참조하세요.\n",
    "\n",
    "고유한 훈련 및 평가 루프를 처음부터 작성하려면 [\"처음부터 훈련 루프 작성\"](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/) 안내서를 참조하십시오.\n",
    "\n",
    "일반적으로, 내장 루프를 사용하든 직접 작성하든 관계없이 모델 훈련 및 유효성 검사는 모든 종류의 Keras 모델(순차 모델, Functional API로 작성된 모델 및 모델 하위 클래스화를 통해 처음부터 작성된 모델)에서 완전히 동일하게 작동합니다.\n",
    "\n",
    "이 가이드는 분산 교육에 대해서는 다루지 않습니다. 분산 교육에 대해서는 [멀티 GPU 및 분산 교육 안내서를](https://keras.io/guides/distributed_training/) 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e270faa413e"
   },
   "source": [
    "## API 개요 : 첫 번째 엔드 투 엔드 예제\n",
    "\n",
    "데이터를 모델의 내장 훈련 루프로 전달할 때는 **NumPy 배열**(데이터가 작고 메모리에 맞는 경우) 또는 **`tf.data Dataset` 객체**를 사용해야 합니다. 다음 몇 단락에서는 옵티마이저, 손실 및 메트릭을 사용하는 방법을 보여주기 위해 MNIST 데이터세트를 NumPy 배열로 사용하겠습니다.\n",
    "\n",
    "다음 모델을 고려해 보겠습니다 (여기서는 Functional API를 사용하여 빌드하지만 Sequential 모델 또는 하위 클래스 모델 일 수도 있음)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:53.792832Z",
     "iopub.status.busy": "2021-04-07T17:58:53.792213Z",
     "iopub.status.idle": "2021-04-07T17:58:55.407575Z",
     "shell.execute_reply": "2021-04-07T17:58:55.408010Z"
    },
    "id": "170a6a18b2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " digits (InputLayer)         [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6d5724a90ab"
   },
   "source": [
    "일반적인 엔드 투 엔드 워크 플로는 다음과 같이 구성되어 있습니다.\n",
    "\n",
    "- 학습\n",
    "- 원래 교육 데이터에서 생성 된 홀드 아웃 세트에 대한 유효성 검사\n",
    "- 테스트 데이터에 대한 평가\n",
    "\n",
    "이 예에서는 MNIST 데이터를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.413652Z",
     "iopub.status.busy": "2021-04-07T17:58:55.413065Z",
     "iopub.status.idle": "2021-04-07T17:58:55.758213Z",
     "shell.execute_reply": "2021-04-07T17:58:55.757663Z"
    },
    "id": "8b55b3903edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (50000, 784)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "print(x_val.shape, x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77a84eb1985b"
   },
   "source": [
    "훈련 구성(최적화 프로그램, 손실, 메트릭)을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.769921Z",
     "iopub.status.busy": "2021-04-07T17:58:55.769317Z",
     "iopub.status.idle": "2021-04-07T17:58:55.788128Z",
     "shell.execute_reply": "2021-04-07T17:58:55.787601Z"
    },
    "id": "26a7f1819796"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef28150b1eaa"
   },
   "source": [
    "`fit()`를 호출하여 데이터를 \"batch_size\" 크기의 \"배치\"로 분할하고 지정된 수의 \"epoch\"에 대해 전체 데이터세트를 반복 처리하여 모델을 훈련시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.792862Z",
     "iopub.status.busy": "2021-04-07T17:58:55.792230Z",
     "iopub.status.idle": "2021-04-07T17:59:00.616809Z",
     "shell.execute_reply": "2021-04-07T17:59:00.617243Z"
    },
    "id": "0b92f67b105e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 5s 5ms/step - loss: 0.3429 - sparse_categorical_accuracy: 0.9017 - val_loss: 0.1758 - val_sparse_categorical_accuracy: 0.9504\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1624 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.1407 - val_sparse_categorical_accuracy: 0.9609\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a1b698c6e39"
   },
   "source": [
    "반환되는 \"이력\" 객체는 훈련 중 손실 값과 메트릭 값에 대한 레코드를 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.625752Z",
     "iopub.status.busy": "2021-04-07T17:59:00.625141Z",
     "iopub.status.idle": "2021-04-07T17:59:00.628091Z",
     "shell.execute_reply": "2021-04-07T17:59:00.628463Z"
    },
    "id": "a20b8f5b9fcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3428562879562378, 0.16241206228733063],\n",
       " 'sparse_categorical_accuracy': [0.9017199873924255, 0.9516599774360657],\n",
       " 'val_loss': [0.1757969856262207, 0.1406579315662384],\n",
       " 'val_sparse_categorical_accuracy': [0.9503999948501587, 0.9609000086784363]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6105b646df66"
   },
   "source": [
    "`evaluate()`를 통해 테스트 데이터에 대해 모델을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.632994Z",
     "iopub.status.busy": "2021-04-07T17:59:00.632410Z",
     "iopub.status.idle": "2021-04-07T17:59:00.894621Z",
     "shell.execute_reply": "2021-04-07T17:59:00.894161Z"
    },
    "id": "69f524a93f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1410 - sparse_categorical_accuracy: 0.9579\n",
      "test loss, test acc: [0.140953928232193, 0.9578999876976013]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape: (3, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.3586314e-06, 2.3652584e-07, 2.3941883e-04, 2.1841223e-03,\n",
       "        3.4241486e-07, 6.4110158e-05, 1.4226206e-09, 9.9738318e-01,\n",
       "        1.2632505e-05, 1.1453608e-04],\n",
       "       [1.7161759e-05, 1.4542656e-04, 9.9803442e-01, 1.7039211e-03,\n",
       "        2.9126759e-10, 3.1880903e-05, 2.5882633e-05, 2.0640492e-07,\n",
       "        4.1090861e-05, 4.2340429e-09],\n",
       "       [8.5066949e-07, 9.9655211e-01, 2.9527876e-04, 1.3202573e-04,\n",
       "        1.7591471e-04, 8.3414532e-05, 1.7761733e-04, 2.2790646e-03,\n",
       "        2.4407644e-04, 5.9704431e-05]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f19d074eb88c"
   },
   "source": [
    "이제이 워크 플로의 각 부분을 자세히 검토하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3669f026d14"
   },
   "source": [
    "## `compile()` 메소드 : 손실, 메트릭 및 최적화 프로그램 지정\n",
    "\n",
    "`fit()` 으로 모델을 학습하려면 손실 함수, 최적화 프로그램 및 선택적으로 모니터링 할 일부 메트릭을 지정해야합니다.\n",
    "\n",
    "이것을 `compile()` 메소드의 인수로 모델에 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.903471Z",
     "iopub.status.busy": "2021-04-07T17:59:00.902774Z",
     "iopub.status.idle": "2021-04-07T17:59:00.912104Z",
     "shell.execute_reply": "2021-04-07T17:59:00.911681Z"
    },
    "id": "eb7a8deb494c"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4061c977ac3"
   },
   "source": [
    "`metrics` 인수는 목록이어야합니다. 모델에는 여러 개의 메트릭이있을 수 있습니다.\n",
    "\n",
    "모델에 여러 개의 출력이있는 경우 각 출력에 대해 서로 다른 손실 및 메트릭을 지정하고 모델의 총 손실에 대한 각 출력의 기여도를 조정할 수 있습니다. 이에 대한 자세한 내용은 **\"다중 입력, 다중 출력 모델로 데이터 전달\"** 섹션에서 확인할 수 있습니다.\n",
    "\n",
    "기본 설정에 만족하면 대부분의 경우 최적화, 손실 및 메트릭을 문자열 식별자를 통해 바로 가기로 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.920513Z",
     "iopub.status.busy": "2021-04-07T17:59:00.919946Z",
     "iopub.status.idle": "2021-04-07T17:59:00.924629Z",
     "shell.execute_reply": "2021-04-07T17:59:00.924967Z"
    },
    "id": "6444839ff300"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5493ab963254"
   },
   "source": [
    "나중에 재사용하기 위해 모델 정의와 컴파일 단계를 함수에 넣겠습니다. 이 안내서의 여러 예에서 여러 번 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.930518Z",
     "iopub.status.busy": "2021-04-07T17:59:00.929926Z",
     "iopub.status.idle": "2021-04-07T17:59:00.932021Z",
     "shell.execute_reply": "2021-04-07T17:59:00.931520Z"
    },
    "id": "31c3e3c70f06"
   },
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21b19c0a6a85"
   },
   "source": [
    "### 많은 내장 옵티 마이저, 손실 및 메트릭을 사용할 수 있습니다\n",
    "\n",
    "일반적으로 고유한 손실, 메트릭 또는 최적화 프로그램을 처음부터 새로 만들 필요가 없는데, Keras API에 필요한 것들이 이미 들어 있을 개연성이 높기 때문입니다.\n",
    "\n",
    "옵티마이저\n",
    "\n",
    "- `SGD()` (모멘텀이 있거나 없음)\n",
    "- `RMSprop()`\n",
    "- `Adam()`\n",
    "- 기타\n",
    "\n",
    "손실:\n",
    "\n",
    "- `MeanSquaredError()`\n",
    "- `KLDivergence()`\n",
    "- `CosineSimilarity()`\n",
    "- 기타\n",
    "\n",
    "메트릭\n",
    "\n",
    "- `AUC()`\n",
    "- `Precision()`\n",
    "- `Recall()`\n",
    "- 기타"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7abc0339980"
   },
   "source": [
    "### 관례 손실\n",
    "\n",
    "Keras로 커스텀 손실을 제공하는 두 가지 방법이 있습니다. 첫 번째 예는 입력 `y_true` 및 `y_pred` 를 받아들이는 함수를 만듭니다. 다음 예는 실제 데이터와 예측 간의 평균 제곱 오차를 계산하는 손실 함수를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.938634Z",
     "iopub.status.busy": "2021-04-07T17:59:00.938085Z",
     "iopub.status.idle": "2021-04-07T17:59:02.545087Z",
     "shell.execute_reply": "2021-04-07T17:59:02.544610Z"
    },
    "id": "cc4edd47bb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc586ef1f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_mean_squared_error(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=custom_mean_squared_error)\n",
    "\n",
    "# We need to one-hot encode the labels to use MSE\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25b9fa7941ca"
   },
   "source": [
    "`y_true` 및 `y_pred` 이외의 매개 변수를 사용하는 손실 함수가 필요한 경우 `tf.keras.losses.Loss` 클래스를 서브 클래스 화하고 다음 두 메소드를 구현할 수 있습니다.\n",
    "\n",
    "- `__init__(self)` : 손실 함수 호출 중에 전달할 매개 변수를 승인합니다.\n",
    "- `call(self, y_true, y_pred)` : 목표 (y_true)와 모델 예측 (y_pred)을 사용하여 모델의 손실을 계산\n",
    "\n",
    "평균 제곱 오차를 사용하려고하지만 예측 값을 0.5에서 멀어지게하는 용어가 추가되었다고 가정 해 보겠습니다 (우리는 범주 형 목표가 원-핫 인코딩되고 0과 1 사이의 값을 취하는 것으로 가정). 이렇게하면 모델이 너무 자신감이없는 인센티브가 생겨 과적 합을 줄이는 데 도움이 될 수 있습니다 (시도 할 때까지 작동하는지 알 수 없음).\n",
    "\n",
    "방법은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:02.553096Z",
     "iopub.status.busy": "2021-04-07T17:59:02.552526Z",
     "iopub.status.idle": "2021-04-07T17:59:04.353462Z",
     "shell.execute_reply": "2021-04-07T17:59:04.353833Z"
    },
    "id": "b09463a8c568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc65775eb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
    "        return mse + reg * self.regularization_factor\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())  # loss(t, y)\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2141cc075a6"
   },
   "source": [
    "### 맞춤 측정 항목\n",
    "\n",
    "API의 일부가 아닌 메트릭이 필요한 경우 `tf.keras.metrics.Metric` 클래스를 서브 클래 싱하여 사용자 지정 메트릭을 쉽게 만들 수 있습니다. 4 가지 방법을 구현해야합니다.\n",
    "\n",
    "- `__init__(self)` . 여기서 메트릭에 대한 상태 변수를 만듭니다.\n",
    "- `update_state(self, y_true, y_pred, sample_weight=None)` 대상 y_true 및 모델 예측 y_pred를 사용하여 상태 변수를 업데이트합니다.\n",
    "- `result(self)` : 상태 변수를 사용하여 최종 결과를 계산합니다.\n",
    "- `reset_states(self)` : 메트릭의 상태를 다시 초기화합니다.\n",
    "\n",
    "경우에 따라 결과 계산이 매우 비싸고 주기적으로 만 수행되기 때문에 상태 업데이트와 결과 계산은 각각 `update_state()` 와 `result()` 에서 별도로 유지됩니다.\n",
    "\n",
    "다음은 `CategoricalTruePositives` 메트릭을 구현하는 방법을 보여주는 간단한 예제입니다.이 메트릭은 주어진 클래스에 속하는 것으로 올바르게 분류 된 샘플 수를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:04.363314Z",
     "iopub.status.busy": "2021-04-07T17:59:04.362654Z",
     "iopub.status.idle": "2021-04-07T17:59:09.979834Z",
     "shell.execute_reply": "2021-04-07T17:59:09.980190Z"
    },
    "id": "05d6a6e7022d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 4s 4ms/step - loss: 0.3386 - categorical_true_positives: 45194.0000\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1599 - categorical_true_positives: 47637.0000\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1180 - categorical_true_positives: 48233.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc65ed7fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
    "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\")\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "    def reset_state(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.true_positives.assign(0.0)\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[CategoricalTruePositives()],\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bca8e959cda"
   },
   "source": [
    "### 표준 서명에 맞지 않는 손실 및 메트릭 처리하기\n",
    "\n",
    "거의 대부분의 손실과 메트릭은 `y_true` 및 `y_pred`에서 계산할 수 있습니다(여기서 `y_pred`가 모델의 출력). 그러나 모두가 그런 것은 아닙니다. 예를 들어, 정규화 손실은 레이어의 활성화만 요구할 수 있으며(이 경우 대상이 없음) 이 활성화는 모델 출력이 아닐 수 있습니다.\n",
    "\n",
    "이러한 경우 사용자 정의 레이어의 호출 메서드 내에서 `self.add_loss(loss_value)`를 호출할 수 있습니다. 이러한 방식으로 추가된 손실은 훈련 중 \"주요\" 손실(`compile()`로 전달되는 손실)에 추가됩니다. 다음은 활동 정규화를 추가하는 간단한 예입니다. 참고로 활동 정규화는 모든 Keras 레이어에 내장되어 있으며 이 레이어는 구체적인 예를 제공하기 위한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:09.989008Z",
     "iopub.status.busy": "2021-04-07T17:59:09.988416Z",
     "iopub.status.idle": "2021-04-07T17:59:12.011691Z",
     "shell.execute_reply": "2021-04-07T17:59:12.011174Z"
    },
    "id": "b494d47437a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 4ms/step - loss: 2.4909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e21ed38b50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(tf.reduce_sum(inputs) * 0.1)\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs) # (None,784)(784,64) => (None,64)\n",
    "\n",
    "# Insert activity regularization as a layer\n",
    "x = ActivityRegularizationLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# The displayed loss will be much higher than before\n",
    "# due to the regularization component.\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaebb5829011"
   },
   "source": [
    "`add_metric()` 사용하여 메트릭 값 로깅에 대해 동일한 작업을 수행 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:12.021377Z",
     "iopub.status.busy": "2021-04-07T17:59:12.019956Z",
     "iopub.status.idle": "2021-04-07T17:59:14.167067Z",
     "shell.execute_reply": "2021-04-07T17:59:14.167421Z"
    },
    "id": "aa58091be092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3492 - std_of_activation: 0.9686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e21feb37f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MetricLoggingLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # The `aggregation` argument defines\n",
    "        # how to aggregate the per-batch values\n",
    "        # over each epoch:\n",
    "        # in this case we simply average them.\n",
    "        self.add_metric(\n",
    "            keras.backend.std(inputs), name=\"std_of_activation\", aggregation=\"mean\"\n",
    "        )\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert std logging as a layer.\n",
    "x = MetricLoggingLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3c18154d057"
   },
   "source": [
    "[Functional API](https://www.tensorflow.org/guide/keras/functional/) 에서 `model.add_loss(loss_tensor)` 또는 `model.add_metric(metric_tensor, name, aggregation)` 호출 할 수도 있습니다.\n",
    "\n",
    "다음은 간단한 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:14.176154Z",
     "iopub.status.busy": "2021-04-07T17:59:14.175268Z",
     "iopub.status.idle": "2021-04-07T17:59:16.355388Z",
     "shell.execute_reply": "2021-04-07T17:59:16.354905Z"
    },
    "id": "0e19afe78b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 4ms/step - loss: 2.4990 - std_of_activation: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e22112fc70>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
    "\n",
    "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b06d48035369"
   },
   "source": [
    "`add_loss()` 를 통해 손실을 전달하면 모델에는 이미 손실이 있으므로 손실 함수없이 `compile()` 을 호출 할 수 있습니다.\n",
    "\n",
    "다음 `LogisticEndpoint` 레이어를 생각해 보겠습니다. 이 레이어는 입력으로 targets 및 logits를 받아들이고 `add_loss()`를 통해 교차 엔트로피 손실을 추적합니다. 또한 `add_metric()`를 통해 분류 정확도도 추적합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.361776Z",
     "iopub.status.busy": "2021-04-07T17:59:16.361194Z",
     "iopub.status.idle": "2021-04-07T17:59:16.362990Z",
     "shell.execute_reply": "2021-04-07T17:59:16.363332Z"
    },
    "id": "d56d2c504258"
   },
   "outputs": [],
   "source": [
    "class LogisticEndpoint(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(LogisticEndpoint, self).__init__(name=name)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "    def call(self, targets, logits, sample_weights=None):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        loss = self.loss_fn(targets, logits, sample_weights)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Log accuracy as a metric and add it\n",
    "        # to the layer using `self.add_metric()`.\n",
    "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
    "        self.add_metric(acc, name=\"accuracy\")\n",
    "\n",
    "        # Return the inference-time prediction tensor (for `.predict()`).\n",
    "        return tf.nn.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0698f3c98cbe"
   },
   "source": [
    "다음과 같이 `loss` 인수없이 컴파일 된 두 개의 입력 (입력 데이터 및 대상)이있는 모델에서 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.372039Z",
     "iopub.status.busy": "2021-04-07T17:59:16.370993Z",
     "iopub.status.idle": "2021-04-07T17:59:16.746912Z",
     "shell.execute_reply": "2021-04-07T17:59:16.747257Z"
    },
    "id": "0f6842f2bbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9225 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e21ca67e80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = keras.Input(shape=(3,), name=\"inputs\")\n",
    "targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "logits = keras.layers.Dense(10)(inputs)\n",
    "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n",
    "\n",
    "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
    "model.compile(optimizer=\"adam\")  # No loss argument!\n",
    "\n",
    "data = {\n",
    "    \"inputs\": np.random.random((3, 3)),\n",
    "    \"targets\": np.random.random((3, 10)),\n",
    "}\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "328b021aa6b8"
   },
   "source": [
    "다중 입력 모델 교육에 대한 자세한 내용은 **다중 입력, 다중 출력 모델로 데이터 전달** 섹션을 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0536882b969c"
   },
   "source": [
    "### 유효성 검사 홀드아웃 세트를 자동으로 분리하기\n",
    "\n",
    "본 첫 번째 엔드 투 엔드 예제에서, 우리는 `validation_data` 인수를 사용하여 NumPy 배열의 튜플 `(x_val, y_val)` 을 모델에 전달하여 각 에포크의 끝에서 유효성 검증 손실 및 유효성 검증 메트릭을 평가합니다.\n",
    "\n",
    "또 다른 옵션: 인수 `validation_split`를 사용하여 유효성 검사 목적으로 훈련 데이터의 일부를 자동으로 예약할 수 있습니다. 인수 값은 유효성 검사를 위해 예약할 데이터 비율을 나타내므로 0보다 크고 1보다 작은 값으로 설정해야 합니다. 예를 들어, `validation_split=0.2`는 \"유효성 검사를 위해 데이터의 20%를 사용\"한다는 의미이고`validation_split=0.6`은 \"유효성 검사를 위해 데이터의 60%를 사용\"한다는 의미입니다.\n",
    "\n",
    "유효성을 계산하는 방법은 셔플 링 전에 맞춤 호출로 수신 한 배열의 마지막 x % 샘플을 가져 오는 것입니다.\n",
    "\n",
    "NumPy 데이터를 학습 할 때 `validation_split` 만 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.754009Z",
     "iopub.status.busy": "2021-04-07T17:59:16.753094Z",
     "iopub.status.idle": "2021-04-07T17:59:18.729991Z",
     "shell.execute_reply": "2021-04-07T17:59:18.729293Z"
    },
    "id": "232fd59c751b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 4ms/step - loss: 0.3713 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.2324 - val_sparse_categorical_accuracy: 0.9301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e222131f10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42969af7ce01"
   },
   "source": [
    "## tf.data 데이터 세트의 교육 및 평가\n",
    "\n",
    "앞서 몇 단락에 걸쳐 손실, 메트릭 및 옵티마이저를 처리하는 방법을 살펴보았으며, 데이터가 NumPy 배열로 전달될 때 fit에서 `validation_data` 및 `validation_split` 인수를 사용하는 방법도 알아보았습니다.\n",
    "\n",
    "이제 데이터가 `tf.data.Dataset` 객체의 형태로 제공되는 경우를 살펴 보겠습니다.\n",
    "\n",
    "`tf.data` API는 빠르고 확장 가능한 방식으로 데이터를 로드하고 사전 처리하기 위한 TensorFlow 2.0의 유틸리티 세트입니다.\n",
    "\n",
    "`Datasets` 생성에 대한 자세한 설명은 [tf.data 설명서](https://www.tensorflow.org/guide/data)를 참조하세요.\n",
    "\n",
    "`Dataset` 인스턴스를 메서드 `fit()`, `evaluate()` 및 `predict()`로 직접 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(64, 784), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
      "array([1., 7., 5., 2., 2., 3., 9., 0., 7., 2., 4., 6., 2., 1., 7., 7., 5.,\n",
      "       7., 5., 5., 0., 5., 7., 2., 7., 0., 3., 7., 4., 2., 8., 3., 0., 8.,\n",
      "       1., 4., 0., 7., 5., 8., 1., 3., 7., 8., 9., 9., 0., 2., 5., 5., 8.,\n",
      "       1., 4., 7., 0., 9., 9., 9., 3., 1., 7., 2., 1., 9.], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "for data in train_dataset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:18.737374Z",
     "iopub.status.busy": "2021-04-07T17:59:18.736671Z",
     "iopub.status.idle": "2021-04-07T17:59:25.389166Z",
     "shell.execute_reply": "2021-04-07T17:59:25.388563Z"
    },
    "id": "3bf4ded224f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3347 - sparse_categorical_accuracy: 0.9056\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1605 - sparse_categorical_accuracy: 0.9518\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1180 - sparse_categorical_accuracy: 0.9638\n",
      "Evaluate\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1294 - sparse_categorical_accuracy: 0.9626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.12938207387924194,\n",
       " 'sparse_categorical_accuracy': 0.9625999927520752}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# First, let's create a training Dataset instance.\n",
    "# For the sake of our example, we'll use the same MNIST data as before.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Now we get a test dataset.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# Since the dataset already takes care of batching,\n",
    "# we don't pass a `batch_size` argument.\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# You can also evaluate or predict on a dataset.\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "421d16914ce3"
   },
   "source": [
    "데이터세트는 각 epoch의 끝에서 재설정되므로 다음 epoch에서 재사용할 수 있습니다.\n",
    "\n",
    "이 데이터세트의 특정 배치 수에 대해서만 훈련을 실행하려면 다음 epoch로 이동하기 전에 이 데이터세트를 사용하여 모델이 실행해야 하는 훈련 단계의 수를 지정하는 `steps_per_epoch` 인수를 전달할 수 있습니다.\n",
    "\n",
    "이렇게 하면 각 epoch가 끝날 때 데이터세트가 재설정되지 않고 다음 배치를 계속 가져오게 됩니다. 무한 반복되는 데이터세트가 아니라면 결국 데이터세트의 데이터가 고갈됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:25.395575Z",
     "iopub.status.busy": "2021-04-07T17:59:25.394783Z",
     "iopub.status.idle": "2021-04-07T17:59:26.675941Z",
     "shell.execute_reply": "2021-04-07T17:59:26.675448Z"
    },
    "id": "273c5dff16b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 1s 4ms/step - loss: 0.7314 - sparse_categorical_accuracy: 0.8136\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3633 - sparse_categorical_accuracy: 0.8953\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3109 - sparse_categorical_accuracy: 0.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e22512fb50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Only use the 100 batches per epoch (that's 64 * 100 samples)\n",
    "model.fit(train_dataset, epochs=3 , steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2dcd180da7b"
   },
   "source": [
    "### 유효성 검사 데이터 집합 사용\n",
    "\n",
    "`fit()` 에서 `Dataset` 인스턴스를 `validation_data` 인수로 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:26.682749Z",
     "iopub.status.busy": "2021-04-07T17:59:26.681981Z",
     "iopub.status.idle": "2021-04-07T17:59:29.751000Z",
     "shell.execute_reply": "2021-04-07T17:59:29.751364Z"
    },
    "id": "bf4f3d78e69a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3402 - sparse_categorical_accuracy: 0.9038 - val_loss: 0.1751 - val_sparse_categorical_accuracy: 0.9510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e23d4d0610>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e7f0ebf5f1d"
   },
   "source": [
    "각 시대가 끝날 때 모델은 유효성 검사 데이터 집합을 반복하고 유효성 검사 손실 및 유효성 검사 메트릭을 계산합니다.\n",
    "\n",
    "이 데이터세트의 특정 배치 수에 대해서만 유효성 검사를 실행하려면 유효성 검사를 중단하고 다음 epoch로 넘어가기 전에 유효성 검사 데이터세트에서 모델이 실행해야 하는 유효성 검사 단계의 수를 지정하는 `validation_steps` 인수를 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:29.758316Z",
     "iopub.status.busy": "2021-04-07T17:59:29.757458Z",
     "iopub.status.idle": "2021-04-07T17:59:32.372341Z",
     "shell.execute_reply": "2021-04-07T17:59:32.372720Z"
    },
    "id": "f47342fed069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 4ms/step - loss: 0.3410 - sparse_categorical_accuracy: 0.9044 - val_loss: 0.3166 - val_sparse_categorical_accuracy: 0.9219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e225e02160>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=1,\n",
    "    # Only run validation using the first 10 batches of the dataset\n",
    "    # using the `validation_steps` argument\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67b4418e9f26"
   },
   "source": [
    "유효성 검사 데이터 세트는 사용 후마다 재설정되므로 항상 에포크에서 에포크까지 동일한 샘플을 평가하게됩니다.\n",
    "\n",
    "인수 `validation_split`(훈련 데이터로부터 홀드아웃 세트 생성)는 `Dataset` 객체로 훈련할 때는 지원되지 않는데, 이를 위해서는 데이터세트 샘플을 인덱싱할 수 있어야 하지만 `Dataset` API에서는 일반적으로 이것이 불가능하기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8160beb766a0"
   },
   "source": [
    "## 지원되는 다른 입력 형식\n",
    "\n",
    "NumPy 배열, 즉시 실행 텐서 및 TensorFlow `Datasets` 외에도 Pandas 데이터프레임을 사용하거나 데이터 및 레이블의 배치를 생성하는 Python 생성기에서 Keras 모델을 훈련할 수 있습니다.\n",
    "\n",
    "특히, `keras.utils.Sequence` 클래스는 멀티스레딩을 인식하고 셔플이 가능한 Python 데이터 생성기를 빌드하기 위한 간단한 인터페이스를 제공합니다.\n",
    "\n",
    "일반적으로 다음을 사용하는 것이 좋습니다.\n",
    "\n",
    "- 데이터가 작고 메모리에 맞는 경우 NumPy 입력 데이터\n",
    "- 큰 데이터세트가 있고 분산 훈련을 수행해야 하는 경우 `Dataset` 객체\n",
    "- 큰 데이터세트가 있고 TensorFlow에서 수행할 수 없는 많은 사용자 정의 Python 측 처리를 수행해야 하는 경우(예: 데이터 로드 또는 사전 처리를 위해 외부 라이브러리에 의존하는 경우) `Sequence` 객체\n",
    "\n",
    "## `keras.utils.Sequence` 객체를 입력으로 사용하기\n",
    "\n",
    "`keras.utils.Sequence`는 두 가지 중요한 속성을 가진 Python 생성기를 얻기 위해 하위 클래스화를 수행할 수 있는 유틸리티입니다.\n",
    "\n",
    "- 멀티 프로세싱과 잘 작동합니다.\n",
    "- 셔플할 수 있습니다(예: `fit()`에서 `shuffle=True`를 전달하는 경우).\n",
    "\n",
    "`Sequence` 는 두 가지 방법을 구현해야합니다.\n",
    "\n",
    "- `__getitem__`\n",
    "- `__len__`\n",
    "\n",
    "`__getitem__` 메소드는 완전한 배치를 리턴해야합니다. 신기원 사이의 데이터 세트를 수정하려면 `on_epoch_end` 구현할 수 있습니다.\n",
    "\n",
    "간단한 예를 들자면 다음과 같습니다.\n",
    "\n",
    "```python\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "# Here, `filenames` is list of path to the images\n",
    "# and `labels` are the associated labels.\n",
    "\n",
    "class CIFAR10Sequence(Sequence):\n",
    "    def __init__(self, filenames, labels, batch_size):\n",
    "        self.filenames, self.labels = filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([\n",
    "            resize(imread(filename), (200, 200))\n",
    "               for filename in batch_x]), np.array(batch_y)\n",
    "\n",
    "sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
    "model.fit(sequence, epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a28343b1967"
   },
   "source": [
    "## 샘플 가중치 및 클래스 가중치 사용\n",
    "\n",
    "기본 설정을 사용하면 샘플의 무게가 데이터 세트의 빈도에 따라 결정됩니다. 샘플 빈도와 관계없이 데이터에 가중치를 부여하는 방법에는 두 가지가 있습니다.\n",
    "\n",
    "- 클래스 가중치\n",
    "- 샘플 무게"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f234a9a75b6d"
   },
   "source": [
    "### 클래스 가중치\n",
    "\n",
    "이 가중치는 `Model.fit()`에 대한 `class_weight` 인수로 사전을 전달하여 설정합니다. 이 사전은 클래스 인덱스를 이 클래스에 속한 샘플에 사용해야 하는 가중치에 매핑합니다.\n",
    "\n",
    "이 방법은 샘플링을 다시 수행하지 않고 클래스의 균형을 맞추거나 특정 클래스에 더 중요한 모델을 훈련시키는 데 사용할 수 있습니다.\n",
    "\n",
    "예를 들어, 데이터에서 클래스 \"0\"이 클래스 \"1\"로 표시된 것의 절반인 경우 `Model.fit(..., class_weight={0: 1., 1: 0.5})`을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9929d26d91b8"
   },
   "source": [
    "다음은 클래스 #5(MNIST 데이터세트에서 숫자 \"5\")의 올바른 분류에 더 많은 중요성을 두도록 클래스 가중치 또는 샘플 가중치를 사용하는 NumPy 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:32.379985Z",
     "iopub.status.busy": "2021-04-07T17:59:32.379268Z",
     "iopub.status.idle": "2021-04-07T17:59:34.552093Z",
     "shell.execute_reply": "2021-04-07T17:59:34.552450Z"
    },
    "id": "f1844f2329a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with class weight\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3645 - sparse_categorical_accuracy: 0.9045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e23da64100>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,\n",
    "    1: 1.0,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    # Set weight \"2\" for class \"5\",\n",
    "    # making this class 2x more important\n",
    "    5: 2.0,\n",
    "    6: 1.0,\n",
    "    7: 1.0,\n",
    "    8: 1.0,\n",
    "    9: 1.0,\n",
    "}\n",
    "\n",
    "print(\"Fit with class weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, class_weight=class_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce27221fad08"
   },
   "source": [
    "### 샘플 무게\n",
    "\n",
    "세밀한 제어를 위해 또는 분류기를 작성하지 않는 경우 \"샘플 가중치\"를 사용할 수 있습니다.\n",
    "\n",
    "- NumPy 데이터에서 학습하는 경우 : `sample_weight` 인수를 `Model.fit()` .\n",
    "- `tf.data` 또는 다른 종류의 반복자에서 훈련 할 때 : Yield `(input_batch, label_batch, sample_weight_batch)` 튜플.\n",
    "\n",
    "\"샘플 가중치\"배열은 배치에서 각 샘플이 총 손실을 계산하는 데 필요한 가중치를 지정하는 숫자 배열입니다. 불균형 분류 문제 (거의 보이지 않는 클래스에 더 많은 가중치를 부여하는 아이디어)에 일반적으로 사용됩니다.\n",
    "\n",
    "사용 된 가중치가 1과 0 인 경우, 어레이는 손실 함수에 대한 *마스크* 로 사용될 수 있습니다 (전체 손실에 대한 특정 샘플의 기여를 완전히 버림)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:34.557087Z",
     "iopub.status.busy": "2021-04-07T17:59:34.556528Z",
     "iopub.status.idle": "2021-04-07T17:59:41.179312Z",
     "shell.execute_reply": "2021-04-07T17:59:41.178824Z"
    },
    "id": "f9819d647793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with sample weight\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3693 - sparse_categorical_accuracy: 0.9016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e242967ac0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "print(\"Fit with sample weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, sample_weight=sample_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eae5837c5f56"
   },
   "source": [
    "일치하는 `Dataset` 예는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:41.184161Z",
     "iopub.status.busy": "2021-04-07T17:59:41.183589Z",
     "iopub.status.idle": "2021-04-07T17:59:43.788537Z",
     "shell.execute_reply": "2021-04-07T17:59:43.788025Z"
    },
    "id": "c870f3f0c66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 4ms/step - loss: 0.3595 - sparse_categorical_accuracy: 0.9057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2534ff790>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "# Create a Dataset that includes sample weights\n",
    "# (3rd element in the return tuple).\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, sample_weight))\n",
    "\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3963bfa348b0"
   },
   "source": [
    "## 다중 입력, 다중 출력 모델로 데이터 전달\n",
    "\n",
    "이전 예에서는 단일 입력(형상 `(764,)`의 텐서)과 단일 출력(형상 `(10,)`의 예측 텐서)이 있는 모델을 고려했습니다. 그렇다면 입력 또는 출력이 여러 개인 모델은 어떨까요?\n",
    "\n",
    "shape `(32, 32, 3)` ( `(height, width, channels)` 입력과 shape `(None, 10)` 의 시계열 입력 `(timesteps, features)` 하십시오. 우리의 모델은이 입력들의 조합으로부터 계산 된 두 개의 출력을 가질 것입니다 : \"점수\"(모양 `(1,)` )와 5 개의 클래스 (모양 `(5,)` )에 대한 확률 분포."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:43.798671Z",
     "iopub.status.busy": "2021-04-07T17:59:43.797137Z",
     "iopub.status.idle": "2021-04-07T17:59:43.836889Z",
     "shell.execute_reply": "2021-04-07T17:59:43.837258Z"
    },
    "id": "5f958449a057"
   },
   "outputs": [],
   "source": [
    "image_input = keras.Input(shape=(32, 32, 3), name=\"img_input\")\n",
    "timeseries_input = keras.Input(shape=(None, 10), name=\"ts_input\")\n",
    "\n",
    "x1 = layers.Conv2D(3, 3)(image_input)  # (None,32,32,3)(3,3,3,3)\n",
    "x1 = layers.GlobalMaxPooling2D()(x1)   # (None,30,30,3)\n",
    "                                       # (None,3)\n",
    "\n",
    "x2 = layers.Conv1D(3, 3)(timeseries_input) # (None,None,10)(3,10,3)\n",
    "x2 = layers.GlobalMaxPooling1D()(x2)       # (None,None,3)\n",
    "                                           # (None,3)\n",
    "\n",
    "x = layers.concatenate([x1, x2])  # (None,3) (None,3)\n",
    "                                  # (None,6)\n",
    "\n",
    "score_output = layers.Dense(1, name=\"score_output\")(x)  # (None,6)(6,1)\n",
    "class_output = layers.Dense(5, name=\"class_output\")(x)  # (None,6)(6,5)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[image_input, timeseries_input], outputs=[score_output, class_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df3ed34fe78b"
   },
   "source": [
    "이 모델을 플로팅하여 여기서 수행중인 작업을 명확하게 확인할 수 있습니다 (플롯에 표시된 셰이프는 샘플 별 셰이프가 아니라 배치 셰이프 임)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:43.841632Z",
     "iopub.status.busy": "2021-04-07T17:59:43.840966Z",
     "iopub.status.idle": "2021-04-07T17:59:43.997553Z",
     "shell.execute_reply": "2021-04-07T17:59:43.997939Z"
    },
    "id": "ac8c1baca9e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d979e89b335"
   },
   "source": [
    "컴파일 타임에 손실 함수를 목록으로 전달하여 출력마다 다른 손실을 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.008729Z",
     "iopub.status.busy": "2021-04-07T17:59:44.008083Z",
     "iopub.status.idle": "2021-04-07T17:59:44.020566Z",
     "shell.execute_reply": "2021-04-07T17:59:44.020024Z"
    },
    "id": "9655c0084d70"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5fc73405283"
   },
   "source": [
    "모델에 단일 손실 함수만 전달하는 경우, 모든 출력에 동일한 손실 함수가 적용됩니다(여기서는 적합하지 않음).\n",
    "\n",
    "메트릭의 경우도 마찬가지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.031233Z",
     "iopub.status.busy": "2021-04-07T17:59:44.030430Z",
     "iopub.status.idle": "2021-04-07T17:59:44.054558Z",
     "shell.execute_reply": "2021-04-07T17:59:44.054914Z"
    },
    "id": "b4c0c6c564bc"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    "    metrics=[\n",
    "        [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        [keras.metrics.CategoricalAccuracy()],\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dd9fb0343cc"
   },
   "source": [
    "출력 레이어에 이름을 지정 했으므로 dict를 통해 출력 당 손실 및 메트릭을 지정할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.064527Z",
     "iopub.status.busy": "2021-04-07T17:59:44.063850Z",
     "iopub.status.idle": "2021-04-07T17:59:44.083742Z",
     "shell.execute_reply": "2021-04-07T17:59:44.083134Z"
    },
    "id": "42cb75110fc3"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfd95ac0dd8b"
   },
   "source": [
    "출력이 두 개 이상인 경우 명시적 이름과 사전을 사용하는 것이 좋습니다.\n",
    "\n",
    "`loss_weights` 인수를 사용하여 출력별 손실에 서로 다른 가중치를 부여할 수 있습니다(예를 들어, 클래스 손실에 2x의 중요도를 부여하여 이 예에서 \"score\" 손실에 우선권을 줄 수 있음)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.093695Z",
     "iopub.status.busy": "2021-04-07T17:59:44.093100Z",
     "iopub.status.idle": "2021-04-07T17:59:44.112359Z",
     "shell.execute_reply": "2021-04-07T17:59:44.112739Z"
    },
    "id": "23a71e5f5227"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    "    loss_weights={\"score_output\": 2.0, \"class_output\": 1.0},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "367f598029e7"
   },
   "source": [
    "이러한 출력이 예측 용이지만 훈련 용이 아닌 경우 특정 출력에 대한 손실을 계산하지 않도록 선택할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.121160Z",
     "iopub.status.busy": "2021-04-07T17:59:44.120554Z",
     "iopub.status.idle": "2021-04-07T17:59:44.130318Z",
     "shell.execute_reply": "2021-04-07T17:59:44.130734Z"
    },
    "id": "6d51aa372ef4"
   },
   "outputs": [],
   "source": [
    "# List loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[None, keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Or dict loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\"class_output\": keras.losses.CategoricalCrossentropy()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8314a8b3a7c7"
   },
   "source": [
    "적합하게 다중 입력 또는 다중 출력 모델에 데이터를 전달하는 것은 컴파일에서 손실 함수를 지정하는 것과 유사한 방식으로 작동합니다. **NumPy 배열 목록을** 전달할 수 있습니다 (손실 함수를 수신 한 출력에 1 : 1 매핑). **출력 이름을 NumPy 배열에 매핑합니다** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.135391Z",
     "iopub.status.busy": "2021-04-07T17:59:44.134811Z",
     "iopub.status.idle": "2021-04-07T17:59:46.741893Z",
     "shell.execute_reply": "2021-04-07T17:59:46.742292Z"
    },
    "id": "0539da84328b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 27ms/step - loss: 18.3764 - score_output_loss: 1.6382 - class_output_loss: 16.7383\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 18.0990 - score_output_loss: 1.1070 - class_output_loss: 16.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e262c60c70>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Generate dummy NumPy data\n",
    "img_data = np.random.random_sample(size=(100, 32, 32, 3))\n",
    "ts_data = np.random.random_sample(size=(100, 20, 10))\n",
    "score_targets = np.random.random_sample(size=(100, 1))\n",
    "class_targets = np.random.random_sample(size=(100, 5))\n",
    "\n",
    "# Fit on lists\n",
    "model.fit([img_data, ts_data], [score_targets, class_targets], batch_size=32, epochs=1)\n",
    "\n",
    "# Alternatively, fit on dicts\n",
    "model.fit(\n",
    "    {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "    {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e53eda8e1399"
   },
   "source": [
    "`Dataset` 사용 사례는 다음과 같습니다. NumPy 배열에서 수행 한 것과 유사하게 `Dataset` 은 튜플 튜플을 반환해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:46.752664Z",
     "iopub.status.busy": "2021-04-07T17:59:46.752034Z",
     "iopub.status.idle": "2021-04-07T17:59:47.185670Z",
     "shell.execute_reply": "2021-04-07T17:59:47.186035Z"
    },
    "id": "4df41a12ed2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 56ms/step - loss: 18.1705 - score_output_loss: 0.8967 - class_output_loss: 17.2738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e24294ccd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "        {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    )\n",
    ")\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38ebf30ce6ac"
   },
   "source": [
    "## 콜백 사용하기\n",
    "\n",
    "Keras의 콜백은 훈련 중 다른 시점(epoch의 시작, 배치의 끝, epoch의 끝 등)에서 호출되며 다음과 같은 동작을 구현하는 데 사용할 수 있는 객체입니다.\n",
    "\n",
    "- 훈련 중 서로 다른 시점에서 유효성 검사 수행(내장된 epoch당 유효성 검사에서 더욱 확장)\n",
    "- 정기적으로 또는 특정 정확도 임계값을 초과할 때 모델 검사점 설정\n",
    "- 훈련이 정체 된 것처럼 보일 때 모델의 학습 속도 변경\n",
    "- 훈련이 정체 된 것처럼 보일 때 최상위 레이어의 미세 조정\n",
    "- 교육이 종료되거나 특정 성능 임계 값을 초과 한 경우 전자 메일 또는 인스턴트 메시지 알림 보내기\n",
    "- 기타\n",
    "\n",
    "콜백은 `fit()` 에 대한 호출에 목록으로 전달 될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:47.193545Z",
     "iopub.status.busy": "2021-04-07T17:59:47.192522Z",
     "iopub.status.idle": "2021-04-07T17:59:57.855887Z",
     "shell.execute_reply": "2021-04-07T17:59:57.855277Z"
    },
    "id": "15036ddbee42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.3841 - sparse_categorical_accuracy: 0.8912 - val_loss: 0.2477 - val_sparse_categorical_accuracy: 0.9242\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1781 - sparse_categorical_accuracy: 0.9465 - val_loss: 0.1850 - val_sparse_categorical_accuracy: 0.9449\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9605 - val_loss: 0.1730 - val_sparse_categorical_accuracy: 0.9482\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1015 - sparse_categorical_accuracy: 0.9693 - val_loss: 0.1477 - val_sparse_categorical_accuracy: 0.9557\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0835 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.1414 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0698 - sparse_categorical_accuracy: 0.9784 - val_loss: 0.1377 - val_sparse_categorical_accuracy: 0.9617\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e262d09e50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,   # 0.01\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "303815509732"
   },
   "source": [
    "### 많은 내장 콜백을 사용할 수 있습니다\n",
    "\n",
    "- `ModelCheckpoint` : 주기적으로 모델을 저장합니다.\n",
    "- `EarlyStopping`: 훈련이 더 이상 유효성 검사 메트릭을 개선하지 못하는 경우 훈련을 중단합니다.\n",
    "- `TensorBoard` : 시각화 할 수 있습니다 정기적으로 쓰기 모델 로그 [TensorBoard](https://www.tensorflow.org/tensorboard) (섹션 \"시각화\"에서 자세한 내용).\n",
    "- `CSVLogger` : 손실 및 메트릭 데이터를 CSV 파일로 스트리밍합니다.\n",
    "- 기타\n",
    "\n",
    "전체 목록은 [콜백 설명서](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/) 를 참조하십시오.\n",
    "\n",
    "### 자신의 콜백 작성\n",
    "\n",
    "기본 클래스 `keras.callbacks.Callback` 을 확장하여 사용자 정의 콜백을 작성할 수 있습니다. 콜백은 클래스 속성 `self.model` 통해 연관된 모델에 액세스 할 수 있습니다.\n",
    "\n",
    "[사용자 정의 콜백을 작성하기 위한 전체 가이드](https://www.tensorflow.org/guide/keras/custom_callback/)를 꼭 읽어보세요. 다음은 훈련 중 배치별 손실 값 목록을 저장하는 간단한 예입니다.\n",
    "\n",
    "다음은 훈련 중 배치 별 손실 값 목록을 저장하는 간단한 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:57.860674Z",
     "iopub.status.busy": "2021-04-07T17:59:57.860106Z",
     "iopub.status.idle": "2021-04-07T17:59:57.862542Z",
     "shell.execute_reply": "2021-04-07T17:59:57.862070Z"
    },
    "id": "b265d36ce608"
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ee672524987"
   },
   "source": [
    "## 모델 검사점 설정하기\n",
    "\n",
    "상대적으로 큰 데이터세트에 대한 모델을 훈련시킬 때는 모델의 검사점을 빈번하게 저장하는 것이 중요합니다.\n",
    "\n",
    "이를 수행하는 가장 쉬운 방법은 `ModelCheckpoint` 콜백을 사용하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:57.870033Z",
     "iopub.status.busy": "2021-04-07T17:59:57.868836Z",
     "iopub.status.idle": "2021-04-07T18:00:02.043065Z",
     "shell.execute_reply": "2021-04-07T18:00:02.042601Z"
    },
    "id": "83614be57725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "620/625 [============================>.] - ETA: 0s - loss: 0.3681 - sparse_categorical_accuracy: 0.8970\n",
      "Epoch 1: val_loss improved from inf to 0.22054, saving model to mymodel_1\n",
      "INFO:tensorflow:Assets written to: mymodel_1\\assets\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3670 - sparse_categorical_accuracy: 0.8972 - val_loss: 0.2205 - val_sparse_categorical_accuracy: 0.9340\n",
      "Epoch 2/2\n",
      "620/625 [============================>.] - ETA: 0s - loss: 0.1754 - sparse_categorical_accuracy: 0.9479\n",
      "Epoch 2: val_loss improved from 0.22054 to 0.18651, saving model to mymodel_2\n",
      "INFO:tensorflow:Assets written to: mymodel_2\\assets\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1749 - sparse_categorical_accuracy: 0.9481 - val_loss: 0.1865 - val_sparse_categorical_accuracy: 0.9445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e27549aeb0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath=\"mymodel_{epoch}\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train, y_train, epochs=2, batch_size=64, callbacks=callbacks, validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f6afa36950c"
   },
   "source": [
    "`ModelCheckpoint` 콜백을 사용하여 내결함성을 구현할 수 있습니다. 훈련이 무작위로 중단 된 경우 모델의 마지막 저장된 상태에서 훈련을 다시 시작할 수있는 기능. 기본 예는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:02.050845Z",
     "iopub.status.busy": "2021-04-07T18:00:02.048933Z",
     "iopub.status.idle": "2021-04-07T18:00:11.144699Z",
     "shell.execute_reply": "2021-04-07T18:00:11.144180Z"
    },
    "id": "27ce92b2ad58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from ./ckpt/ckpt-loss=0.30\n",
      "  89/1563 [>.............................] - ETA: 6s - loss: 0.1845 - sparse_categorical_accuracy: 0.9445INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.18\\assets\n",
      " 196/1563 [==>...........................] - ETA: 7s - loss: 0.1642 - sparse_categorical_accuracy: 0.9488INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 289/1563 [====>.........................] - ETA: 7s - loss: 0.1579 - sparse_categorical_accuracy: 0.9497INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 388/1563 [======>.......................] - ETA: 7s - loss: 0.1579 - sparse_categorical_accuracy: 0.9507INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 489/1563 [========>.....................] - ETA: 6s - loss: 0.1558 - sparse_categorical_accuracy: 0.9517INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 589/1563 [==========>...................] - ETA: 6s - loss: 0.1558 - sparse_categorical_accuracy: 0.9518INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      " 689/1563 [============>.................] - ETA: 5s - loss: 0.1510 - sparse_categorical_accuracy: 0.9532INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      " 793/1563 [==============>...............] - ETA: 4s - loss: 0.1505 - sparse_categorical_accuracy: 0.9540INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      " 887/1563 [================>.............] - ETA: 4s - loss: 0.1485 - sparse_categorical_accuracy: 0.9548INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      " 989/1563 [=================>............] - ETA: 3s - loss: 0.1485 - sparse_categorical_accuracy: 0.9553INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1088/1563 [===================>..........] - ETA: 3s - loss: 0.1465 - sparse_categorical_accuracy: 0.9558INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1189/1563 [=====================>........] - ETA: 2s - loss: 0.1442 - sparse_categorical_accuracy: 0.9564INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.14\\assets\n",
      "1288/1563 [=======================>......] - ETA: 1s - loss: 0.1432 - sparse_categorical_accuracy: 0.9568INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.14\\assets\n",
      "1397/1563 [=========================>....] - ETA: 1s - loss: 0.1420 - sparse_categorical_accuracy: 0.9572INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.14\\assets\n",
      "1488/1563 [===========================>..] - ETA: 0s - loss: 0.1407 - sparse_categorical_accuracy: 0.9577INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.14\\assets\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1403 - sparse_categorical_accuracy: 0.9579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e29ca8e940>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Prepare a directory to store all the checkpoints.\n",
    "checkpoint_dir = \"./ckpt\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "\n",
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()\n",
    "\n",
    "\n",
    "model = make_or_restore_model()\n",
    "callbacks = [\n",
    "    # This callback saves a SavedModel every 100 batches.\n",
    "    # We include the training loss in the saved model name.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + \"/ckpt-loss={loss:.2f}\", save_freq=100\n",
    "    )\n",
    "]\n",
    "model.fit(x_train, y_train, epochs=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da3ab58d5235"
   },
   "source": [
    "또한 모델 저장 및 복원을 위해 자체 콜백을 작성하십시오.\n",
    "\n",
    "직렬화 및 저장에 대한 전체 안내서는 [모델 저장 및 직렬화 안내서를](https://www.tensorflow.org/guide/keras/save_and_serialize/) 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9342cc2ddba"
   },
   "source": [
    "## 학습 속도 일정 사용하기\n",
    "\n",
    "딥 러닝 모델을 훈련 할 때 일반적인 패턴은 훈련이 진행됨에 따라 점차적으로 학습을 줄이는 것입니다. 이것을 일반적으로 \"학습률 감소\"라고합니다.\n",
    "\n",
    "학습 붕괴 스케줄은 정적 인 (현재 에포크 또는 현재 배치 인덱스의 함수로서 미리 고정됨) 또는 동적 (모델의 현재 행동, 특히 검증 손실에 대응) 일 수있다.\n",
    "\n",
    "### 옵티마이저로 일정 전달하기\n",
    "\n",
    "옵티 마이저에서 schedule 객체를 `learning_rate` 인수로 전달하여 정적 학습 속도 감소 스케줄을 쉽게 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:11.150053Z",
     "iopub.status.busy": "2021-04-07T18:00:11.149381Z",
     "iopub.status.idle": "2021-04-07T18:00:11.151800Z",
     "shell.execute_reply": "2021-04-07T18:00:11.151244Z"
    },
    "id": "684f0ab6d3de"
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.1\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d742e44f535"
   },
   "source": [
    "`ExponentialDecay` , `PiecewiseConstantDecay` , `PolynomialDecay` 및 `InverseTimeDecay` 와 같은 몇 가지 기본 제공 일정을 사용할 수 있습니다.\n",
    "\n",
    "### 콜백을 사용하여 동적 학습 속도 일정 구현\n",
    "\n",
    "옵티마이저가 유효성 검사 메트릭에 액세스할 수 없으므로 이러한 일정 객체로는 동적 학습률 일정(예: 유효성 검사 손실이 더 이상 개선되지 않을 때 학습률 감소)을 달성할 수 없습니다.\n",
    "\n",
    "그러나 콜백은 유효성 검사 메트릭을 포함해 모든 메트릭에 액세스할 수 있습니다! 따라서 옵티마이저에서 현재 학습률을 수정하는 콜백을 사용하여 이 패턴을 달성할 수 있습니다. 실제로 이 부분이`ReduceLROnPlateau` 콜백으로 내장되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4a05f880175"
   },
   "source": [
    "## 훈련 중 손실 및 메트릭 시각화하기\n",
    "\n",
    "교육 중에 모델을 주시하는 가장 좋은 방법은 로컬에서 실행할 수있는 브라우저 기반 응용 프로그램 인 [TensorBoard](https://www.tensorflow.org/tensorboard) 를 사용하는 것입니다.\n",
    "\n",
    "- 교육 및 평가를위한 손실 및 지표의 라이브 플롯\n",
    "- (옵션) 레이어 활성화 히스토그램 시각화\n",
    "- (옵션) `Embedding` 레이어에서 학습한 포함된 공간의 3D 시각화\n",
    "\n",
    "pip와 함께 TensorFlow를 설치한 경우, 명령줄에서 TensorBoard를 시작할 수 있습니다.\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/full_path_to_your_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fcf386a1dad"
   },
   "source": [
    "### TensorBoard 콜백 사용하기\n",
    "\n",
    "TensorBoard를 Keras 모델 및 fit 메서드와 함께 사용하는 가장 쉬운 방법은 `TensorBoard` 콜백입니다.\n",
    "\n",
    "가장 간단한 경우로, 콜백에서 로그를 작성할 위치만 지정하면 바로 쓸 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:11.157400Z",
     "iopub.status.busy": "2021-04-07T18:00:11.156688Z",
     "iopub.status.idle": "2021-04-07T18:00:11.159760Z",
     "shell.execute_reply": "2021-04-07T18:00:11.159192Z"
    },
    "id": "f74247282ff6"
   },
   "outputs": [],
   "source": [
    "keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_logs\",\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\",\n",
    ")  # How often to write logs (default: once per epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50cd5f8631fd"
   },
   "source": [
    "자세한 내용 [`TensorBoard` 콜백 설명서](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/tensorboard/)를 참조하세요."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train_and_evaluate.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
